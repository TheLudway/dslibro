## Pruebas de asociación {#association-tests}

```{r, echo=FALSE}
set.seed(1984)
```

Las pruebas estadísticas que hemos estudiado hasta ahora no incluyen varios tipos de datos. Específicamente, no hemos discutido la inferencia para datos binarios, categóricos y ordinales. Para dar un ejemplo muy específico, consideren el siguiente estudio de caso.


Una publicación del 2014 de PNAS^[http://www.pnas.org/content/112/40/12349.abstract] analizó las tasas de éxito de las agencias de financiamiento en los Países Bajos y concluyó que:

> los resultados revelan un sesgo de género que favorece a los hombres solicitantes sobre las mujeres solicitantes en la priorización de sus evaluaciones de "calidad de investigador" (pero no de "calidad de propuesta"), así como en el uso del lenguaje en los materiales de instrucción y de evaluación.

La evidencia principal de esta conclusión se reduce a una comparación de los porcentajes. La Tabla S1 en el documento incluye la información que necesitamos. Aquí están las tres columnas que muestran los resultados generales:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(dslabs)
data("research_funding_rates")
research_funding_rates %>% select(discipline, applications_total,
                                  success_rates_total) %>% head()
```

Tenemos estos valores para cada género:
```{r}
names(research_funding_rates)
```

Podemos calcular el total de los que tuvieron éxito y el total de los que no lo tuvieron de la siguiente manera:

```{r}
totals <- research_funding_rates %>%
  select(-discipline) %>%
  summarize_all(sum) %>%
  summarize(yes_men = awards_men,
            no_men = applications_men - awards_men,
            yes_women = awards_women,
            no_women = applications_women - awards_women)
```

Entonces vemos que un mayor porcentaje de hombres que mujeres recibieron premios:

```{r}
totals %>% summarize(percent_men = yes_men/(yes_men+no_men),
                     percent_women = yes_women/(yes_women+no_women))
```

Pero, ¿esto se debe solo a la variabilidad aleatoria? Aquí aprenderemos a llevar a cabo inferencia estadística para este tipo de datos.


### Lady Tasting Tea


R.A. Fisher^[https://en.wikipedia.org/wiki/Ronald_Fisher] fue uno de los primeros en formalizar las pruebas de hipótesis. El "Lady Tasting Tea" es uno de los ejemplos más famosos.

La historia es la siguiente: una conocida de Fisher insistió que ella podía detectar si añadían leche antes o después de verter el té. Fisher se mostró escéptico. Diseñó un experimento para probar esta afirmación. Él le dio cuatro pares de tazas de té. Cada par incluía una taza con leche vertida primero y la otra después del té. El orden era aleatorio. La hipótesis nula aquí es que ella está adivinando. Fisher dedujo la distribución del número de selecciones correctas suponiendo que las elecciones fueran aleatorias e independientes.

Como ejemplo, supongamos que la amiga escogió 3 de 4 correctamente. ¿Creemos que ella tiene una habilidad especial? La pregunta básica que hacemos es: si ella realmente está adivinando, ¿cuáles son las posibilidades de que ella saque 3 o más correctas? Tal como lo hemos hecho antes, podemos calcular una probabilidad bajo la hipótesis nula de que ella está adivinando 4 con leche vertida primero y 4 después. Bajo esta hipótesis nula, podemos pensar en este ejemplo particular como sacar 4 cuentas de una urna con 4 cuentas azules (respuesta correcta) y 4 cuentas rojas (respuesta incorrecta). Recuerden, ella sabe que hay cuatro tasas con leche antes del té y cuatro con leche después.

Bajo la hipótesis nula de que ella simplemente está adivinando, cada cuenta tiene la misma posibilidad de ser elegida. Entonces podemos usar combinaciones para averiguar cada probabilidad. La probabilidad de elegir 3 es ${4 \choose 3} {4 \choose 1}/ {8 \choose 4} = 16/70$. La probabilidad de elegir bien las 4 veces es
${4 \choose 4} {4 \choose 0}/{8 \choose 4}= 1/70$.
Por lo tanto, la posibilidad de observar un 3 o algo más extremo,
bajo la hipótesis nula, es $\approx 0.24$. Este es el valor-p. El procedimiento que produjo este valor-p se llama la _prueba exacta de Fisher_ (_Fisher's exact test_ en inglés) y utiliza la _distribución hipergeométrica_.

### Tablas 2x2

Los datos del experimento generalmente se resumen en una tabla como esta:

```{r}
tab <- matrix(c(3,1,1,3),2,2)
rownames(tab)<-c("Poured Before","Poured After")
colnames(tab)<-c("Guessed before","Guessed after")
tab
```

que se conoce como una tabla 2x2. Para cada una de las cuatro combinaciones que se pueden obtener con un par de variables binarias, la tabla muestra los recuentos observados para cada ocurrencia.

La función `fisher.test` realiza los cálculos de inferencia anteriores:

```{r}
fisher.test(tab, alternative="greater")$p.value
```

### Prueba de chi-cuadrado

Tengan en cuenta que, en cierto sentido, nuestro ejemplo de tasas de financiamiento es parecido al de "Lady Tasting Tea". Sin embargo, en el ejemplo de "Lady Tasting Tea", el número de cuentas azules y rojas se fija experimentalmente y el número de respuestas dadas para cada categoría también. Esto se debe a que Fisher se aseguró de que se vertieran cuatro tazas con leche antes del té y cuatro tazas con leche después del té y la señora lo sabía, por lo que las respuestas también tendrían que incluir cuatro antes y cuatro después. Si este es el caso, la suma de las filas y la suma de las columnas son fijas. Esto define restricciones sobre las posibles formas en que podemos llenar la tabla 2x2 y también nos permite usar la distribución hipergeométrica. En general, este no es el caso. No obstante, hay otro enfoque, la prueba de chi-cuadrado, que se describe a continuación.


Imaginen que tenemos `r prettyNum(totals, ,big.mark=",")` solicitantes, algunos son hombres y otros son mujeres y algunos reciben financiamiento, mientras que otros no. Vimos que las tasas de éxito para hombres y mujeres fueron:

```{r}
totals %>% summarize(percent_men = yes_men/(yes_men+no_men),
                     percent_women = yes_women/(yes_women+no_women))
```

respectivamente. ¿Volveríamos a ver esto si asignamos fondos al azar usando como tasa la tasa general?

```{r}
rate <- totals %>%
  summarize(percent_total =
              (yes_men + yes_women)/
              (yes_men + no_men +yes_women + no_women)) %>%
  pull(percent_total)
rate
```

La prueba de chi-cuadrado responde a esta pregunta. El primer paso es crear la tabla de datos 2x2:

```{r}
two_by_two <- data.frame(awarded = c("no", "yes"),
                         men = c(totals$no_men, totals$yes_men),
                         women = c(totals$no_women, totals$yes_women))
two_by_two
```

La idea general de la prueba de chi-cuadrado es comparar esta tabla 2x2 con lo que esperamos ver, que sería:

```{r}
data.frame(awarded = c("no", "yes"),
           men = (totals$no_men + totals$yes_men) * c(1 - rate, rate),
           women = (totals$no_women + totals$yes_women) * c(1 - rate, rate))
```

Podemos ver que más hombres y menos mujeres de lo esperado recibieron fondos. Sin embargo, bajo la hipótesis nula, estas observaciones son variables aleatorias. La prueba de chi-cuadrado nos dice cuán probable es ver una desviación así de grande o más grande. Esta prueba utiliza un resultado asintótico, similar al CLT, relacionado con las sumas de resultados binarios independientes. La función `chisq.test` de R toma una tabla 2x2 y devuelve los resultados de la prueba:

```{r}
chisq_test <- two_by_two %>% select(-awarded) %>% chisq.test()
```

Vemos que el valor-p es 0.0509:

```{r}
chisq_test$p.value
```


### Riesgo relativo {#odds-ratio}

Un resumen estadístico informativo para tablas 2x2 es el _riesgo relativo_ (_odds ratio_ en inglés). Definan las dos variables como $X = 1$ si eres hombre y 0 de lo contrario, y $Y=1$ si recibe financiamiento y 0 de lo contrario. Las probabilidades de obtener fondos si eres hombre se definen así:

$$\mbox{Pr}(Y=1 \mid X=1)/ \mbox{Pr}(Y=0 \mid X=1)$$

y se pueden calcular así:

```{r}
odds_men <- with(two_by_two, (men[2]/sum(men))/ (men[1]/sum(men)))
odds_men
```

Y las probabilidades de recibir financiamiento si eres mujer son:


$$\mbox{Pr}(Y=1 \mid X=0)/ \mbox{Pr}(Y=0 \mid X=0)$$


y se pueden calcular así:
```{r}
odds_women <- with(two_by_two, (women[2]/sum(women))/ (women[1]/sum(women)))
odds_women
```

El riesgo relativo es la razón de estas dos probabilidades: ¿cuántas veces más grandes son las probabilidades para los hombres que para las mujeres?

```{r}
odds_men/ odds_women
```

A menudo vemos tablas de 2x2 escritas como:

```{r, echo=FALSE}
mat <- cbind(c(" a "," c "), c(" b "," d "))
colnames(mat) <- c("Men","Women")
rownames(mat) <- c("Awarded", "Not Awarded")
if(knitr::is_html_output()){
  knitr::kable(mat, "html", align = "c") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(mat, "latex", booktabs = TRUE, align = "c") %>%
    kableExtra::kable_styling(font_size = 8)
}
```

En este caso, el riesgo relativo es $\frac{a/c}{b/d}$
que es equivalente a $(ad)/ (bc)$.


### Intervalos de confianza para el riesgo relativo

Calcular intervalos de confianza para el riesgo relativo no es matemáticamente sencillo. A diferencia de otras estadísticas, para las cuales podemos derivar aproximaciones útiles de sus distribuciones, el riesgo relativo no es solo una razón, sino una razón de razones. Por lo tanto, no hay una forma sencilla de utilizar, por ejemplo, el CLT.

Sin embargo, la teoría estadística nos dice que cuando las cuatro entradas de la tabla 2x2 son lo suficientemente grandes, entonces el logaritmo del riesgo relativo es aproximadamente normal con error estándar: 

$$
\sqrt{1/a + 1/b + 1/c + 1/d}
$$

Esto implica que un intervalo de confianza de 95% para el logaritmo del riesgo relativo se puede formar por:

$$
\log\left(\frac{ad}{bc}\right) \pm 1.96 \sqrt{1/a + 1/b + 1/c + 1/d}
$$

Exponenciando estos dos números podemos construir un intervalo de confianza del riesgo relativo.

Usando R, podemos calcular este intervalo de confianza de la siguiente manera:
```{r}
log_or <- log(odds_men/ odds_women)
se <- two_by_two %>% select(-awarded) %>%
  summarize(se = sqrt(sum(1/men) + sum(1/women))) %>%
  pull(se)
ci <- log_or + c(-1,1) * qnorm(0.975) * se
```

Si queremos convertirlo de nuevo a la escala de riesgo relativo, podemos exponenciar:

```{r}
exp(ci)
```

Observen que 1 no está incluido en el intervalo de confianza, lo que significa que el valor-p es menor que 0.05. Podemos confirmar esto usando:

```{r}
2*(1 - pnorm(log_or, 0, se))
```

Este es un valor-p un poco diferente al de la prueba de chi-cuadrado. Esto se debe a que estamos utilizando una aproximación asintótica diferente a la distribución nula. Para obtener más información sobre la inferencia y la teoría asintótica del riesgo relativo, consulten el libro _Generalized Linear Models_ de McCullagh y Nelder.

### Corrección de recuento pequeño

Si cualquiera de las celdas de la tabla 2x2 es 0, el logaritmo del riesgo relativo es indefinido. Esto se debe a que si $a$, $b$, $c$ o $d$ es 0, el $\log(\frac{ad}{bc})$ es el logaritmo de 0 o tiene un 0 en el denominador. Para esta situación, es una práctica común evitar los 0 añadiendo 0.5 a cada celda. Esto se conoce como la _corrección de Haldane-Anscombe_ y se ha demostrado, tanto en la práctica como en la teoría, que funciona bien.


### Muestras grandes, valores-p pequeños

Como se mencionó anteriormente, informar solo valores-p no es una forma apropiada de informar los resultados del análisis de datos. En revistas científicas, por ejemplo, algunos estudios parecen enfatizar demasiado los valores-p. Algunos de estos estudios tienen muestras de gran tamaño e indican valores-p impresionantemente pequeños. Sin embargo, cuando uno mira de cerca los resultados, se da cuenta que los riesgos relativos son pequeños: apenas mayores que 1. En este caso, la diferencia puede que no sea _prácticamente significativa_ o _científicamente significativa_.

Tengan en cuenta que la relación entre el riesgo relativo y el valor-p no es una correspondencia uno-a-uno. La relacion depende del tamaño de la muestra. Por lo tanto, un valor-p muy pequeño no necesariamente significa un riesgo relativo muy grande. Observen lo que sucede con el valor-p si multiplicamos nuestra tabla 2x2 por 10, lo cual no cambia el riesgo relativo:

```{r}
two_by_two %>% select(-awarded) %>%
  mutate(men = men*10, women = women*10) %>%
  chisq.test() %>% .$p.value
```

## Ejercicios

1\. Una atleta famosa tiene una carrera impresionante, ganando 70% de los 500 partidos de su carrera. Sin embargo, critican a esta atleta porque en eventos importantes, como los Juegos Olímpicos, tiene un récord perdedor de 8 victorias y 9 derrotas. Realice una prueba de chi-cuadrado para determinar si este récord se debe simplemente al azar en vez de no competir bien bajo presión.


2\. ¿Por qué usamos la prueba de chi-cuadrado en lugar de la prueba exacta de Fisher en el ejercicio anterior?

a. Realmente no importa ya que dan exactamente el mismo valor-p.
b. La prueba exacta de Fisher y la de chi-cuadrado son nombres diferentes para la misma prueba.
c. Debido a que la suma de las filas y columnas de la tabla 2x2 no son fijas, la distribución hipergeométrica no es una suposición apropiada para la hipótesis nula. Por esta razón, la prueba exacta de Fisher rara vez es aplicable a datos observacionales.
d. Porque la prueba de chi-cuadrado se ejecuta más rápido.


3\. Calcule el riesgo relativo de "perder bajo presión" junto con un intervalo de confianza.


4\. Observe que el valor-p es mayor que 0.05, pero el intervalo de confianza de 95% no incluye 1. ¿Qué explica esto?

a. Cometimos un error en nuestro código.
b. Estas no son estadísticas t, por lo que no aplica la conexión entre el valor-p y los intervalos de confianza.
c. Se utilizan diferentes aproximaciones para el valor-p y el cálculo del intervalo de confianza. Si tuviéramos un tamaño de muestra más grande, la coincidencia sería mejor.
d. Deberíamos usar la prueba exacta de Fisher para obtener intervalos de confianza.


5\. Multiplique la tabla 2x2 por dos y vea si el valor-p y el intervalo de confianza coinciden mejor.





