## Pruebas de asociación {#association-tests}

```{r, echo=FALSE}
set.seed(1984)
```

Las pruebas estadísticas que hemos estudiado hasta ahora dejan de lado un
porción sustancial de los tipos de datos. Específicamente, no hemos discutido la inferencia para datos binarios, categóricos y ordinales. Para dar un
ejemplo muy específico, considere el siguiente estudio de caso.


Un documento de 2014 PNAS^[http://www.pnas.org/content/112/40/12349.abstract] analizó las tasas de éxito de las agencias de financiación en los Países Bajos y concluyó que su:

> los resultados revelan un sesgo de género que favorece a los postulantes masculinos sobre los postulantes femeninos en la priorización de sus evaluaciones de "calidad de investigador" (pero no de "calidad de propuesta"), así como en el uso del lenguaje en los materiales de instrucción y evaluación.

La evidencia principal de esta conclusión se reduce a una comparación de los porcentajes. La Tabla S1 en el documento incluye la información que necesitamos. Aquí están las tres columnas que muestran los resultados generales:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(dslabs)
data("research_funding_rates")
research_funding_rates %>% select(discipline, applications_total,
success_rates_total) %>% head()
```

Tenemos estos valores para cada género:
```{r}
names(research_funding_rates)
```

Podemos calcular los totales que tuvieron éxito y los totales que no fueron los siguientes:

```{r}
totals <- research_funding_rates %>%
select(-discipline) %>%
summarize_all(sum) %>%
summarize(yes_men = awards_men,
no_men = applications_men - awards_men,
yes_women = awards_women,
no_women = applications_women - awards_women)
```

Entonces vemos que un mayor porcentaje de hombres que mujeres recibieron premios:

```{r}
totals %>% summarize(percent_men = yes_men/(yes_men+no_men),
percent_women = yes_women/(yes_women+no_women))
```

Pero, ¿podría esto deberse solo a la variabilidad aleatoria?
Aquí aprendemos cómo realizar inferencia para este tipo de datos.


### Lady Tasting Tea


RA Fisher^[https://en.wikipedia.org/wiki/Ronald_Fisher] fue uno de los primeros en formalizar la prueba de hipótesis. El "Lady Tasting Tea" es uno de los ejemplos más famosos.

La historia es la siguiente: un conocido de Fisher afirmó que ella podría decir si se agregó leche antes o después de verter el té. Fisher se mostró escéptico. Diseñó un experimento para probar esta afirmación. Él le dio cuatro pares de
tazas de té: una con leche vertida primero y la otra después. El orden
fue aleatorizado La hipótesis nula aquí es que ella está adivinando. Fisher dedujo la distribución del número de selecciones correctas suponiendo que las elecciones fueron aleatorias e independientes.

Como ejemplo, supongamos que escogió 3 de 4 correctamente. Creemos
ella tiene una habilidad especial? La pregunta básica que hacemos es: si el probador realmente está adivinando, ¿qué
¿son las posibilidades de que ella obtenga 3 o más correctas? Tal como lo hemos hecho
antes, podemos calcular una probabilidad bajo la hipótesis nula de que ella
está adivinando 4 de cada uno. Bajo esta hipótesis nula, podemos
piense en este ejemplo particular como sacar 4 bolas de una urna
con 4 bolas azules (respuesta correcta) y 4 rojas (respuesta incorrecta). Recuerde, ella sabe que hay cuatro antes del té y cuatro después.

Bajo la hipótesis nula de que ella simplemente está adivinando, cada bola
tiene la misma posibilidad de ser elegido. Entonces podemos usar combinaciones para
averiguar cada probabilidad. La probabilidad de elegir 3 es
${4 \choose 3} {4 \choose 1}/ {8 \choose 4} = 16/70$. La probabilidad de
escoger los 4 correctos es
${4 \choose 4} {4 \choose 0}/{8 \choose 4}= 1/70$.
Por lo tanto, la posibilidad de observar un 3 o algo más extremo,
bajo la hipótesis nula, es $\approx 0.24$. Este es el valor p. los
el procedimiento que produjo este valor p se llama prueba exacta de pescador y
utiliza la * distribución hipergeométrica *.

### Tablas de dos en dos

Los datos del experimento generalmente se resumen en una tabla como esta:

```{r}
tab <- matrix(c(3,1,1,3),2,2)
rownames(tab)<-c("Poured Before","Poured After")
colnames(tab)<-c("Guessed before","Guessed after")
tab
```

Estos se conocen como una tabla de dos por dos. Para cada una de las cuatro combinaciones que se pueden obtener con un par de variables binarias, muestran los recuentos observados para cada ocurrencia.

La función `fisher.test` realiza los cálculos de inferencia anteriores:

```{r}
fisher.test(tab, alternative="greater")$p.value
```

### Prueba de chi-cuadrado

Tenga en cuenta que, en cierto modo, nuestro ejemplo de tasas de financiación es similar al Lady Tasting Tea. Sin embargo, en el ejemplo de Lady Tasting Tea, el número de cuentas azules y rojas se fija experimentalmente y el número de respuestas dadas para cada categoría también. Esto se debe a que Fisher se aseguró de que se viertan cuatro tazas con leche antes del té y cuatro tazas con leche y la señora lo sabía, por lo que las respuestas también tendrían que incluir cuatro antes y cuatro después. Si este es el caso, la suma de las filas y la suma de las columnas son fijas. Esto define restricciones sobre las posibles formas en que podemos llenar los dos
por dos tablas y también nos permite usar el hipergeométrico
distribución. En general, este no es el caso. No obstante, hay
otro enfoque, la prueba de Chi-cuadrado, que se describe a continuación.


Imagina que tenemos `r prettyNum(totals, ,big.mark=",")` solicitantes, algunos son hombres y otros son mujeres y algunos reciben financiación, mientras que otros no. Vimos que las tasas de éxito para hombres y mujeres fueron:

```{r}
totals %>% summarize(percent_men = yes_men/(yes_men+no_men),
percent_women = yes_women/(yes_women+no_women))
```

respectivamente. ¿Volveríamos a ver esto si asignamos fondos al azar a la tasa general?

```{r}
rate <- totals %>%
summarize(percent_total =
(yes_men + yes_women)/
(yes_men + no_men +yes_women + no_women)) %>%
pull(percent_total)
rate
```

La prueba de Chi-cuadrado responde a esta pregunta. El primer paso es crear la tabla de datos de dos por dos:

```{r}
two_by_two <- data.frame(awarded = c("no", "yes"),
men = c(totals$no_men, totals$yes_men),
women = c(totals$no_women, totals$yes_women))
two_by_two
```

La idea general de la prueba de Chi-cuadrado es comparar esta tabla de dos por dos con lo que espera ver, que sería:

```{r}
data.frame(awarded = c("no", "yes"),
men = (totals$no_men + totals$yes_men) * c(1 - rate, rate),
women = (totals$no_women + totals$yes_women) * c(1 - rate, rate))
```

Podemos ver que más hombres de lo esperado y menos mujeres de lo esperado recibieron fondos. Sin embargo, bajo la hipótesis nula, estas observaciones son variables aleatorias. La prueba de Chi-cuadrado nos dice qué tan probable es ver
una desviación tan grande o tan grande Esta prueba utiliza un resultado asintótico, similar al CLT, relacionado con las sumas de resultados binarios independientes.
La función R `chisq.test` toma una tabla de dos por dos y devuelve los resultados de la prueba:

```{r}
chisq_test <- two_by_two %>% select(-awarded) %>% chisq.test()
```

Vemos que el valor p es 0.0509:

```{r}
chisq_test$p.value
```


### La razón de posibilidades {#odds-ratio}

Un resumen estadístico informativo asociado con tablas de dos por dos es la razón de posibilidades. Defina las dos variables como $X = 1$ si eres hombre y 0 de lo contrario, y $Y=1$ si está financiado y 0 de lo contrario. Las probabilidades de obtener fondos si eres hombre se definen:

$$\mbox{Pr}(Y=1 \mid X=1)/ \mbox{Pr}(Y=0 \mid X=1)$$

y se puede calcular así:
```{r}
odds_men <- with(two_by_two, (men[2]/sum(men))/ (men[1]/sum(men)))
odds_men
```

Y las probabilidades de ser financiado si eres mujer son:


$$\mbox{Pr}(Y=1 \mid X=0)/ \mbox{Pr}(Y=0 \mid X=0)$$


y se puede calcular así:
```{r}
odds_women <- with(two_by_two, (women[2]/sum(women))/ (women[1]/sum(women)))
odds_women
```

La razón de probabilidades es la razón de estas dos probabilidades: ¿cuántas veces más grandes son las probabilidades para los hombres que para las mujeres?

```{r}
odds_men/ odds_women
```

A menudo vemos tablas de dos por dos escritas como

```{r, echo=FALSE}
mat <- cbind(c(" a "," c "), c(" b "," d "))
colnames(mat) <- c("Men","Women")
rownames(mat) <- c("Awarded", "Not Awarded")
if(knitr::is_html_output()){
knitr::kable(mat, "html", align = "c") %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
knitr::kable(mat, "latex", booktabs = TRUE, align = "c") %>%
kableExtra::kable_styling(font_size = 8)
}
```

En este caso, la razón de posibilidades es $\frac{a/c}{b/d}$
que es equivalente a $(ad)/ (bc)$


### Intervalos de confianza para la razón de posibilidades

Calcular intervalos de confianza para la razón de posibilidades no es matemáticamente sencillo. A diferencia de otras estadísticas, para las cuales podemos derivar aproximaciones útiles de sus distribuciones, la razón de posibilidades no es solo una
relación, pero una relación de razones. Por lo tanto, no hay una forma simple de
utilizando, por ejemplo, el CLT.

Sin embargo, la teoría estadística nos dice que cuando las cuatro entradas de la tabla dos por dos son lo suficientemente grandes, entonces el registro de la razón de probabilidades es aproximadamente normal con error estándar

$$
\sqrt{1/a + 1/b + 1/c + 1/d}
$$

Esto implica que un intervalo de confianza del 95% para la relación de probabilidad logarítmica puede estar formado por:

$$
\log\left(\frac{ad}{bc}\right) \pm 1.96 \sqrt{1/a + 1/b + 1/c + 1/d}
$$

Exponiendo estos dos números podemos construir un intervalo de confianza de la razón de posibilidades.

Usando R podemos calcular este intervalo de confianza de la siguiente manera:
```{r}
log_or <- log(odds_men/ odds_women)
se <- two_by_two %>% select(-awarded) %>%
summarize(se = sqrt(sum(1/men) + sum(1/women))) %>%
pull(se)
ci <- log_or + c(-1,1) * qnorm(0.975) * se
```

Si queremos convertirlo de nuevo a la escala de odds ratio, podemos exponer:

```{r}
exp(ci)
```

Tenga en cuenta que 1 no está incluido en el intervalo de confianza, lo que debe significar que el valor p es menor que 0.05. Podemos confirmar esto usando:

```{r}
2*(1 - pnorm(log_or, 0, se))
```

Este es un valor p ligeramente diferente al de la prueba de Chi-cuadrado. Esto se debe a que estamos utilizando una aproximación asintótica diferente a la distribución nula. Para obtener más información sobre la inferencia y la teoría asintótica de la razón de posibilidades, consulte el libro _Generalized Linear Models_ de
McCullagh y Nelder.

### Corrección de recuento pequeño

Tenga en cuenta que el odds ratio de registro no está definido si alguna de las celdas de la tabla dos por dos es 0. Esto se debe a que si $a$, $b$, $c$ o $d$ es 0, el $\log(\frac{ad}{bc})$ es el logaritmo de 0 o tiene un 0 en el denominador. Para esta situación, es una práctica común evitar los 0 agregando 0.5 a cada celda. Esto se conoce como la corrección de Haldane-Anscombe y se ha demostrado, tanto en la práctica como en la teoría, que funciona bien.


### Muestras grandes, valores p pequeños

Como se mencionó anteriormente, informar solo valores p no es apropiado
forma de informar los resultados del análisis de datos. En revistas científicas, por ejemplo,
algunos estudios parecen enfatizar demasiado los valores de p. Algunos de estos estudios tienen muestras de gran tamaño.
e informar valores p impresionantemente pequeños. Sin embargo, cuando uno mira de cerca
como resultado, nos damos cuenta de que los odds ratios son bastante modestos: apenas mayores
que 1. En este caso, la diferencia puede no ser * prácticamente significativa * o * científicamente significativa *.

Tenga en cuenta que la relación entre odds ratio y valor p no es uno a uno. Depende del tamaño de la muestra. Por lo tanto, un valor p muy pequeño no necesariamente significa una razón de posibilidades muy grande.
Observe lo que sucede con el valor p si multiplicamos nuestra tabla de dos por dos por 10, lo que no cambia la razón de probabilidades:

```{r}
two_by_two %>% select(-awarded) %>%
mutate(men = men*10, women = women*10) %>%
chisq.test() %>% .$p.value
```

## Ejercicios

1\. Una atleta famosa tiene una carrera impresionante, ganando el 70% de sus 500 partidos de carrera. Sin embargo, esta atleta es criticada porque en eventos importantes, como los Juegos Olímpicos, tiene un récord perdedor de 8 victorias y 9 derrotas. Realice una prueba de Chi-cuadrado para determinar si este registro perdedor puede deberse simplemente al azar en lugar de no funcionar bien bajo presión.



2\. ¿Por qué usamos la prueba de Chi-cuadrado en lugar de la prueba exacta de Fisher en el ejercicio anterior?

a. En realidad no importa, ya que dan exactamente el mismo valor p.
si. El exacto de Fisher y el Chi-cuadrado son nombres diferentes para la misma prueba.
c. Debido a que la suma de las filas y columnas de la tabla de dos por dos no son fijas, la distribución hipergeométrica no es una suposición apropiada para la hipótesis nula. Por esta razón, la prueba exacta de Fisher rara vez es aplicable con datos de observación.
re. Porque la prueba de Chi-cuadrado se ejecuta más rápido.


3\. Calcule la razón de posibilidades de "perder bajo presión" junto con un intervalo de confianza.


4\. Observe que el valor p es mayor que 0.05 pero el intervalo de confianza del 95% no incluye 1. ¿Qué explica esto?

a. Cometimos un error en nuestro código.
si. Estas no son pruebas t, por lo que no se aplica la conexión entre el valor p y los intervalos de confianza.
c. Se utilizan diferentes aproximaciones para el valor p y el cálculo del intervalo de confianza. Si tuviéramos un tamaño de muestra más grande, la coincidencia sería mejor.
re. Deberíamos usar la prueba exacta de Fisher para obtener intervalos de confianza.


5\. Multiplique la tabla dos por dos por 2 y vea si el valor p y la recuperación de confianza coinciden mejor.





