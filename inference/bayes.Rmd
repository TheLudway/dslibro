## Estadísticas bayesianas {#bayesian-statistics}

¿Qué significa que un pronosticador electoral nos diga que un candidato tiene un 90% probabilidad de ganar? En el contexto del modelo de urna, esto sería equivalente a afirmar que la probabilidad $p>0.5$ es 90%. Sin embargo, como discutimos anteriormente, en el modelo de urna $p$ es un parámetro fijo y no tiene sentido hablar de probabilidad. Con estadísticas bayesianas, modelamos $p$ como variable aleatoria y, por lo tanto, una declaración como "90% probabilidad de ganar" es coherente.

Los pronosticadores también usan modelos para describir la variabilidad en diferentes niveles. Por ejemplo, la variabilidad de muestreo, la variabilidad de encuestador a encuestador, la variabilidad diaria y la variabilidad de elección a elección. Uno de los enfoques más exitosos utilizados para esto son los modelos jerárquicos, que pueden explicarse en el contexto de las estadísticas bayesianas.

En este capítulo describimos brevemente las estadísticas bayesianas. Para una exploración más profunda de este tema, recomendamos uno de los siguientes libros de texto:

* Berger JO (1985). Statistical Decision Theory and Bayesian Analysis, 2nd edition. Springer-Verlag.

* Lee PM (1989). Bayesian Statistics: An Introduction. Oxford.


### Teorema de Bayes

Comenzamos describiendo el teorema de Bayes. Hacemos esto usando una hipotética prueba de fibrosis quística como ejemplo.
Supongamos que una prueba de fibrosis quística tiene una precisión de 99%. Vamos a utilizar la siguiente notación:

$$
\mbox{Prob}(+ \mid D=1)=0.99, \mbox{Prob}(- \mid D=0)=0.99
$$

con $+$ significando una prueba positiva y $D$ representando si realmente tiene la enfermedad (1) o no (0).

Supongamos que seleccionamos una persona al azar y dan positivo. ¿Cuál es la probabilidad de que tengan la enfermedad? Escribimos esto como $\mbox{Prob}(D=1 \mid +)$. La tasa de fibrosis quística es de 1 en 3,900, lo que implica que $\mbox{Prob}(D=1)=0.00025$. Para responder a esta pregunta, utilizaremos el teorema de Bayes, que en general nos dice que:

$$
\mbox{Pr}(A \mid B) = \frac{\mbox{Pr}(B \mid A)\mbox{Pr}(A)}{\mbox{Pr}(B)}
$$

Esta ecuación aplicada a nuestro problema se convierte en:

$$
\begin{aligned}
\mbox{Pr}(D=1 \mid +) & = \frac{ P(+ \mid D=1) \cdot P(D=1)} {\mbox{Pr}(+)} \\
& = \frac{\mbox{Pr}(+ \mid D=1)\cdot P(D=1)} {\mbox{Pr}(+ \mid D=1) \cdot P(D=1) + \mbox{Pr}(+ \mid D=0) \mbox{Pr}( D=0)}
\end{aligned}
$$

usando estos números obtenemos:

$$
\frac{0.99 \cdot 0.00025}{0.99 \cdot 0.00025 + 0.01 \cdot (.99975)} = 0.02
$$

Esto dice que a pesar de que la prueba tiene una precisión de 0.99, la probabilidad de tener la enfermedad dado una prueba positiva es solo 0.02. Aunque parezca contrario al sentido común, la razón de esto es porque tenemos que tener en cuenta la muy rara probabilidad de que una persona, elegida al azar, tenga la enfermedad. Para ilustrar esto, ejecutamos una simulación Monte Carlo.

## Simulación del teorema de Bayes

La siguiente simulación está destinada a ayudarles visualizar el teorema de Bayes. Comenzamos seleccionando aleatoriamente 100,000 personas de una población en la cual la enfermedad en cuestión tiene una prevalencia de 1 en 4,000.

```{r, echo=FALSE}
set.seed(3)
```

```{r}
prev <- 0.00025
N <- 100000
outcome <- sample(c("Disease","Healthy"), N, replace = TRUE,
prob = c(prev, 1 - prev))
```

Recuerden que hay muy pocas personas con la enfermedad:

```{r}
N_D <- sum(outcome == "Disease")
N_D
N_H <- sum(outcome == "Healthy")
N_H
```

Además, hay muchos sin la enfermedad, lo que hace más probable que veamos algunos falsos positivos dado que la prueba no es perfecta. Ahora cada persona se hace la prueba, que acierta 99% del tiempo:

```{r}
accuracy <- 0.99
test <- vector("character", N)
test[outcome == "Disease"] <- sample(c("+", "-"), N_D, replace = TRUE,
prob = c(accuracy, 1 - accuracy))
test[outcome == "Healthy"] <- sample(c("-", "+"), N_H, replace = TRUE,
prob = c(accuracy, 1 - accuracy))
```

Debido a que hay muchos más controles que casos, incluso con una tasa baja de falsos positivos obtenemos más controles que los casos en el grupo que dio positivo:


```{r}
table(outcome, test)
```

De esta tabla, vemos que la proporción de pruebas positivas que tienen la enfermedad es `r sum(test=="+" & outcome=="Disease")` de `r sum(test=="+")`. Podemos ejecutar esto una y otra vez para ver que, de hecho, la probabilidad converge a aproximadamente 0.022.


### Bayes en la práctica


José Iglesias es un jugador de béisbol profesional. En abril de 2013, cuando comenzaba su carrera, se desempeñaba bastante bien:

|Mes | At Bats | H | AVG |
|-------|---------|---|-----|
| abril | 20 | 9 | .450 |

La estadística del promedio de bateo (`AVG`) es una forma de medir éxito. En términos generales, nos dice la tasa de éxito al batear. Un `AVG` de .450 significa que José ha tenido éxito el 45% de las veces que ha bateado (`At Bats`) que es bastante alto, históricamente hablando. Tengan en cuenta que nadie ha terminado una temporada con un `AVG` de .400 o más desde que Ted Williams lo hizo en 1941. Para ilustrar la forma en que los modelos jerárquicos son eficaces, intentaremos predecir el promedio de bateo de José al final de la temporada. Recuerden que en una temporada típica, los jugadores tienen alrededor de 500 turnos al bate.

Con las técnicas que hemos aprendido hasta ahora, denominadas _técnicas frecuentistas_, lo mejor que podemos hacer es ofrecer un intervalo de confianza. Podemos pensar en los resultados de batear como un binomio con una tasa de éxito de $p$. Entonces, si la tasa de éxito es .450, el error estándar de solo 20 turnos al bate:

$$
\sqrt{\frac{.450 (1-.450)}{20}}=.111
$$

Esto significa que nuestro intervalo de confianza es $.450 - .222$ a $.450 + .222$ o $.228$ a $.672$.

Esta predicción tiene dos problemas. Primero, es muy grande, por lo que no es muy útil. Segundo, está centrada en .450, lo que implica que nuestra mejor conjetura es que este nuevo jugador romperá el récord de Ted Williams.

Sin embargo, para los fanáticos del béisbol, esta última afirmación no tiene sentido. Los fanáticos implícitamente emplean un modelo jerárquico que toma en cuenta la información de años de seguir el béisbol. Aquí mostramos cómo podemos cuantificar esta intuición.

Primero, exploremos la distribución de los promedios de bateo para todos los jugadores con más de 500 turnos al bate durante las tres temporadas anteriores:

```{r batting-averages-histogram, echo=FALSE, out.width="100%", fig.height=3, message=FALSE, warning=FALSE}
library(tidyverse)
library(Lahman)
filter(Batting, yearID %in% 2010:2012) %>%
mutate(AVG = H/AB) %>%
filter(AB > 500) %>%
ggplot(aes(AVG)) +
geom_histogram(color="black", binwidth = .01) +
facet_wrap( ~ yearID)
```

El jugador promedio tuvo un `AVG` de .275 y la desviación estándar de la población de jugadores fue 0.027. Entonces podemos ver que .450 sería una anomalía, ya que está a más de seis desviaciones estándar de la media.

Entonces, ¿tiene suerte José o es el mejor bateador de los últimos 50 años? Quizás sea una combinación de suerte y talento. ¿Pero cuánto de cada uno? Si nos convencemos de que tiene suerte, deberíamos cambiarlo a otro equipo que confíe en la observación de .450 y tal vez sobreestime su potencial.


## Modelos jerárquicos

El modelo jerárquico ofrece una descripción matemática de cómo llegamos a ver la observación de .450. Primero, elegimos un jugador al azar con una habilidad intrínseca resumida por, por ejemplo, $p$. Luego vemos 20 resultados aleatorios con probabilidad de éxito $p$.

Utilizamos un modelo para representar dos niveles de variabilidad en nuestros datos. Primero, a cada jugador se le asigna una habilidad natural para batear. Usaremos el símbolo $p$ para representar esta habilidad. Pueden pensar en $p$ como el promedio de bateo al que convergería si este jugador en particular bateara repetidas veces.

De acuerdo con los graficos que mostramos anteriormente, asumimos que $p$ tiene una distribución normal, con valor esperado .270 y error estándar 0.027.

Ahora el segundo nivel de variabilidad tiene que ver con la suerte al batear. Independientemente de lo bueno que sea el jugador, a veces tiene mala suerte y a veces tiene buena suerte. En cada turno al bate, este jugador tiene una probabilidad de éxito $p$. Si sumamos estos éxitos y fracasos, entonces el CLT nos dice que el promedio observado, llámelo $Y$, tiene una distribución normal con el valor esperado $p$ y error estándar $\sqrt{p(1-p)/N}$ con $N$ el número de turnos al bate.

Los libros de texto estadísticos escribirán el modelo así:
$$
\begin{aligned}
p &\sim N(\mu, \tau^2) \\
Y \mid p &\sim N(p, \sigma^2)
\end{aligned}
$$
Aquí el símbolo $\sim$ nos dice que la variable aleatoria a la izquierda del símbolo sigue la distribución a la derecha y $N(a,b^2)$ representa la distribución normal con media $a$ y desviación estándar $b$. El $\mid$  significa que estamos _condicionando en_ la variable aleatoria a la derecha del símbolo como si se conociera su valor. Nos referimos al modelo como jerárquico porque necesitamos saber $p$, el primer nivel, para modelar $Y$, el segundo nivel. En nuestro ejemplo, el primer nivel describe la aleatoriedad en la asignación de talento a un jugador y en el segundo se describe la aleatoriedad en el desempeño de este jugador una vez fijemos el parámetro de talento. En un marco bayesiano, el primer nivel se llama _distribución a priori_ y el segundo la _distribución muestral_. El análisis de datos que hemos realizado aquí sugiere que establezcamos $\mu = .270$, $\tau = 0.027$ y $\sigma^2 = p(1-p)/N$.

Ahora, usemos este modelo para los datos de José. Supongamos que queremos predecir su habilidad innata en la forma de su verdadero promedio de bateo $p$. Este sería el modelo jerárquico para nuestros datos:

$$
\begin{aligned}
p &\sim N(.275, .027^2) \\
Y \mid p &\sim N(p, .111^2)
\end{aligned}
$$

Ahora estamos listos para calcular una distribución a posteriori para resumir nuestra predicción de $p$. La versión continua de la regla de Bayes se puede usar aquí para derivar la _función de probabilidad a posteriori_, que es la distribución de $p$ suponiendo que observemos $Y=y$. En nuestro caso, podemos demostrar que cuando fijamos $Y=y$, $p$ sigue una distribución normal con el valor esperado:

$$
\begin{aligned}
\mbox{E}(p \mid Y=y) &= B \mu + (1-B) y\\
&= \mu + (1-B)(y-\mu)\\
\mbox{with } B &= \frac{\sigma^2}{\sigma^2+\tau^2}
\end{aligned}
$$

Este es un promedio ponderado del promedio de la población $\mu$ y los datos observados $y$. El peso depende de la SD de la población $\tau$ y de la SD de nuestros datos observados $\sigma$. Este promedio ponderado a veces se denomina _contracción_ (_shrinking_ en inglés) porque _contrae_ las estimaciones hacia la media de la distribución a priori. En el caso de José Iglesias tenemos:

$$
\begin{aligned}
\mbox{E}(p \mid Y=.450) &= B \times .275 + (1 - B) \times .450 \\
&= .275 + (1 - B)(.450 - .275) \\
B &=\frac{.111^2}{.111^2 + .027^2} = 0.944\\
\mbox{E}(p \mid Y=450) &\approx .285
\end{aligned}
$$

No mostramos la derivación aquí, pero el error estándar se puede demostrar que es:

$$
\mbox{SE}(p\mid y)^2 = \frac{1}{1/\sigma^2+1/\tau^2}
= \frac{1}{1/.111^2 + 1/.027^2} = 0.00069
$$
y, por lo tanto, la desviación estándar es $0.026$. Entonces comenzamos con un intervalo de confianza frecuentista de 95% que ignoraba los datos de otros jugadores y resumía solo los datos de José: .450 $\pm$ 0.220. Luego usamos un enfoque bayesiano que incorporaba datos de otros jugadores y otros años para obtener una probabilidad a posteriori. De hecho, esto se conoce como un enfoque empírico bayesiano porque utilizamos datos para construir la distribución a priori. Desde la distribución a posteriori, podemos calcular lo que se llama un _intervalo de confianza de Bayes_ o _intervalo de Bayes_ (_credible interval_ en inglés) de 95%. Para hacer esto, construimos una región, centrada en la media, con una probabilidad de 95% de ocurrir. En nuestro caso, esto resulta ser: .285 $\pm$ 0.052.

El intervalo de Bayes sugiere que si otro equipo está impresionado por el promedio observado de .450, deberíamos considerar cambiar a José, ya que pronosticamos que estará ligeramente por encima del promedio. Curiosamente, los Red Sox cambiaron a José a los Detroit Tigers en julio. Estos son los promedios de bateo de José Iglesias para los próximos cinco meses:

|Mes |At Bat |Hits |AVG |
|-----|------|-----|-----|
| abril | 20 | 9 | .450 |
| mayo | 26 | 11 | .423 |
| junio | 86 | 34 | .395 |
| julio | 83 | 17 | .205 |
| agosto | 85 | 25 | .294 |
| septiembre | 50 | 10 | .200 |
| Total sin abril | 330 | 97 | .293 |

Aunque ambos intervalos incluyeron el promedio final de bateo, el intervalo de Bayes ofreció una predicción mucho más precisa. En particular, predijo que no sería tan bueno durante el resto de la temporada.

## Ejercicios

1\. En 1999, en Inglaterra, Sally Clark^[https://en.wikipedia.org/wiki/Sally_Clark] fue declarada culpable del asesinato de dos de sus hijos. Ambos bebés fueron encontrados muertos por la mañana, uno en 1996 y otro en 1998. En ambos casos, Clark afirmó que la causa de la muerte fue el Síndrome de muerte súbita del lactante (SIDS o _Sudden Infant Death Syndrome_ en inglés). A ninguno de los niños le encontraron lesiones físicas, por lo que la principal evidencia en su contra fue el testimonio del profesor Sir Roy Meadow, quien testificó que las probabilidades de que dos niños de la misma madre murieran de SIDS eran de 1 en 73 millones. Llegó a esta cifra al encontrar que la tasa de SIDS era de 1 en 8,500 y luego calcular que la posibilidad de dos casos de SIDS era 8,500 $\times$ 8,500 $\approx$ 73 millones. ¿Con cuál de las siguientes declaraciones está de acuerdo?

a. Sir Meadow supuso que la probabilidad de que el segundo hijo fuera afectado por el SIDS era independiente de la del primer hijo afectado, ignorando así las posibles causas genéticas. Si la genética juega un papel, entonces: $\mbox{Pr}(\mbox{second case of SIDS} \mid \mbox{first case of SIDS}) < \mbox{P}r(\mbox{first case of SIDS})$.
b. Nada. La regla de multiplicación siempre se aplica de esta manera: $\mbox{Pr}(A \mbox{ and } B) =\mbox{Pr}(A)\mbox{Pr}(B)$
c. Sir Meadow es un experto y debemos confiar en sus cálculos.
d. Los números no mienten.


2\. Supongamos que definitivamente hay un componente genético para el SIDS y la probabilidad de $\mbox{Pr}(\mbox{second case of SIDS} \mid \mbox{first case of SIDS}) = 1/100$, es mucho mayor que 1 en 8,500. ¿Cuál es la probabilidad de que sus dos hijos mueran de SIDS?

3\. Muchos informes de prensa declararon que el experto afirmó que la probabilidad de que Sally Clark fuera inocente era 1 en 73 millones. Quizás el jurado y el juez también interpretaron el testimonio de esta manera. Esta probabilidad se puede escribir como la probabilidad de que _una madre sea una psicópata asesina de hijos, dado que encuentran a dos de sus hijos muertos sin lesiones físicas._ Según la regla de Bayes, ¿cuánta es esta probabilidad?

4\. Suponga que la probabilidad de que una psicópata asesina de hijos encuentre la manera de matar a sus hijos, sin dejar evidencia física, es:

$$
\mbox{Pr}(A \mid B) = 0.50
$$

con $A =$ dos de sus hijos los encuentran muertos sin lesiones físicas y $B =$ una madre es una psicópata asesina de hijos = 0.50. Suponga que la tasa de madres psicópatas que asesinan hijos es 1 en 1,000,000. Según el teorema de Bayes, ¿cuál es la probabilidad de $\mbox{Pr}(B \mid A)$?


5\. Después de que Sally Clark fue declarada culpable, la Royal Statistical Society emitió un comunicado diciendo que "no había base estadística" para el reclamo del experto. Expresaron preocupación por el "mal uso de las estadísticas en los tribunales". Sally Clark fue absuelta en junio de 2003. ¿Qué no consideró el experto Sir Roy Meadow?

a. Cometió un error aritmético.
b. Cometió dos errores. Primero, hizo un mal uso de la regla de multiplicación y, segundo, no tomó en cuenta lo raro que es que una madre asesine a sus hijos. Después de usar la regla de Bayes, encontramos una probabilidad más cercana a 0.5 que a 1 en 73 millones.
c. Confundió el numerador y el denominador de la regla de Bayes.
d. No usó R.

6\. Florida es uno de los estados más vigilados en las elecciones de EE. UU. porque tiene muchos votos electorales, y las elecciones generalmente son cerradas. Además, Florida tiende a ser un estado decisivo que puede votar por cualquiera de los dos partidos. Cree la siguiente tabla con las encuestas realizadas durante las últimas dos semanas:

```{r, eval=FALSE}
library(tidyverse)
library(dslabs)
data(polls_us_election_2016)
polls <- polls_us_election_2016 %>%
filter(state == "Florida" & enddate >= "2016-11-04" ) %>%
mutate(spread = rawpoll_clinton/100 - rawpoll_trump/100)
```

Tome la diferencia promedio de estas encuestas. El CLT nos dice que este promedio es aproximadamente normal. Calcule un promedio y provea una estimación del error estándar. Guarde sus resultados en un objeto llamado `results`.

7\. Ahora supone un modelo bayesiano con distribución a priori normal para la diferencia de la noche electoral de Florida $d$ con valor esperado $\mu$ y desviación estándar $\tau$. ¿Cuáles son las interpretaciones de $\mu$ y $\tau$?

a. $\mu$ y $\tau$ son números arbitrarios que nos permiten hacer declaraciones de probabilidad sobre $d$.
b. $\mu$ y $\tau$ resumen lo que predeciríamos para Florida antes de ver las encuestas. Basado en elecciones pasadas, fijaríamos $\mu$ cerca de 0 porque tanto republicanos como demócratas han ganado, y $\tau$ en aproximadamente $0.02$, porque estas elecciones tienden a ser cerradas.
c. $\mu$ y $\tau$ resumen lo que queremos que sea verdad. Por lo tanto, fijamos $\mu$ en $0.10$ y $\tau$ en $0.01$.
d. La desición de que distribución a priori usar no tiene ningún efecto en el análisis bayesiano.


8\. El CLT nos dice que nuestra estimación de la diferencia, $\hat{d}$, tiene distribución normal con valor esperado $d$ y desviación estándar $\sigma$ calculada en el problema 6. Use las fórmulas que mostramos para la distribución a posteriori para calcular el valor esperado de la distribución a posteriori si fijamos $\mu = 0$ y $\tau = 0.01$.


9\. Ahora calcule la desviación estándar de la distribución a posteriori.


10\. Usando el hecho de que la distribución a posteriori es normal, cree un intervalo que tenga un 95% de probabilidad de ocurrir centrado en el valor esperado a posteriori. Recuerden que estos los llamamos intervalos de Bayes.


11\. Según este análisis, ¿cuál fue la probabilidad de que Trump ganara Florida?

12\. Ahora use la función `sapply` para cambiar  la varianza de la probabilidad a priori de `seq(0.05, 0.05, len = 100)` y observe cómo cambia la probabilidad haciendo un gráfico.


