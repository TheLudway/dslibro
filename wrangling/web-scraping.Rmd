# Extracción de la web

```{r, echo=FALSE}
img_path <- "wrangling/img/"
```

Los datos que necesitamos para responder a una pregunta no siempre están en una hoja de cálculo lista para leer. Por ejemplo, el set de datos sobre asesinatos de EE.UU. que utilizamos en el Capítulo "Lo básico de R" proviene originalmente de esta página de Wikipedia:

```{r}
url <- paste0("https://en.wikipedia.org/w/index.php?title=",
              "Gun_violence_in_the_United_States_by_state",
              "&direction=prev&oldid=810166167")
```

Pueden ver la tabla de datos en la página web:

```{r, echo=FALSE}
knitr::include_graphics(file.path(img_path,"murders-data-wiki-page.png"))
```

(Página web cortesía de Wikipedia^[https://en.wikipedia.org/w/index.php?title=Gun_violence_in_the_United_States_by_state&amp;direction=prev&amp;oldid=810166167]. Licencia CC-BY-SA-3.0)^[https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License].

Desafortunadamente, no hay un enlace a un archivo de datos. Para crear el _data frame_ que se carga cuando escribimos `data(murders)`, tuvimos que hacer un poco de _extracción de la web_ (_web scraping_ o _web harvesting_ en inglés).

_Extracción de la web_ es el término que se usa para describir el proceso de extracción de datos de un sitio web. La razón por la que podemos hacer esto es porque la información utilizada por un navegador para representar páginas web se recibe como un archivo de texto de un servidor. El texto es un código escrito en lenguaje de marcado de hipertexto (_hyper text markup language_ o HTML por sus siglas en inglés). Todos los navegadores tienen una manera de mostrar el código HTML de una página, cada uno diferente. En Chrome, pueden usar Control-U en una PC y comando + alt + U en una Mac. Verán algo como esto:

```{r, echo=FALSE}
knitr::include_graphics(file.path(img_path,"html-code.png"))
```

## HTML

Debido a que este código es accesible, podemos descargar el archivo HTML, importarlo a R y luego escribir programas para extraer la información que necesitamos de la página. Sin embargo, al ver el código HTML, esto puede parecer una tarea desalentadora. Pero le mostraremos algunas herramientas convenientes para facilitar el proceso. Para tener una idea de cómo funciona, aquí hay unas líneas de código de la página de Wikipedia que proveen los datos de asesinatos en Estados Unidos:

```
<table class="wikitable sortable">
<tr>
<th>State</th>
<th><a href="/wiki/List_of_U.S._states_and_territories_by_population"
title="List of U.S. states and territories by population">Population</a><br/>
<small>(total inhabitants)</small><br/>
<small>(2015)</small> <sup id="cite_ref-1" class="reference">
<a href="#cite_note-1">[1]</a></sup></th>
<th>Murders and Nonnegligent
<p>Manslaughter<br/>
<small>(total deaths)</small><br/>
<small>(2015)</small> <sup id="cite_ref-2" class="reference">
<a href="#cite_note-2">[2]</a></sup></p>
</th>
<th>Murder and Nonnegligent
<p>Manslaughter Rate<br/>
<small>(per 100,000 inhabitants)</small><br/>
<small>(2015)</small></p>
</th>
</tr>
<tr>
<td><a href="/wiki/Alabama" title="Alabama">Alabama</a></td>
<td>4,853,875</td>
<td>348</td>
<td>7.2</td>
</tr>
<tr>
<td><a href="/wiki/Alaska" title="Alaska">Alaska</a></td>
<td>737,709</td>
<td>59</td>
<td>8.0</td>
</tr>
<tr>
```

Pueden ver los datos, excepto que los valores de datos están rodeados por un código HTML como `<td>`. También podemos ver un patrón de cómo se almacenan. Si conocen HTML, pueden escribir programas que aprovechan el conocimiento de estos patrones para extraer lo que queremos. Además, nos aprovechamos de _Cascading Style Sheets_ (CSS), un lenguaje ampliamente utilizado para hacer que las páginas web se vean "bonitas". Discutimos más sobre esto en la Sección \@ref(css-selectors).

Aunque ofrecemos herramientas que permiten extraer datos sin conocer HTML, como científicos de datos es bastante útil aprender algo de HTML y CSS. Esto no solo mejora sus habilidades de extracción, sino que puede ser útil si están creando una página web para exhibir su trabajo. Hay muchos cursos y tutoriales en línea para aprenderlos, como Codeacademy^[https://www.codecademy.com/learn/learn-html] y W3schools^[https://www.w3schools.com/].

## El paquete __rvest__

El __tidyverse__ provee un paquete de extracción de la web llamado __rvest__. El primer paso para usar este paquete es importar la página web a R. El paquete lo hace bastante fácil:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
h <- read_html(url)
```


Tengan en cuenta que la página entera de Wikipedia _Gun violence in the United States_ ahora está contenida en `h`. La clase de este objeto es:

```{r}
class(h)
```

El paquete __rvest__ es más general; maneja documentos XML. XML es un lenguaje de marcado general (ML siendo las iniciales de _markup language_) que se puede usar para representar cualquier tipo de datos. HTML es un tipo específico de XML desarrollado específicamente para representar páginas web. Aquí nos concentramos en documentos HTML.

Ahora, ¿cómo extraemos la tabla del objeto `h`? Si imprimimos `h`, realmente no vemos mucho:

```{r}
h
```

Podemos ver todo el código que define la página web descargada usando la función `html_text` así:

```{r, eval=FALSE}
html_text(h)
```

No mostramos el _output_ aquí porque incluye miles de caracteres, pero si lo miramos, podemos ver que los datos que buscamos se almacenan en una tabla HTML. Pueden ver esto en esta línea del código HTML anterior: `<table class="wikitable sortable">`. Las diferentes partes de un documento HTML, a menudo definidas con un mensaje entre `<` y `>`, se conocen como _nodos_ (_nodes_ en inglés). El paquete __rvest__ incluye funciones para extraer nodos de un documento HTML: `html_nodes` extrae todos los nodos de diferentes tipos y `html_node` extrae el primero. Para extraer las tablas del código HTML usamos:


```{r}
tab <- h |> html_nodes("table")
```

Ahora, en lugar de toda la página web, solo tenemos el código HTML para las tablas de la página:

```{r}
tab
```

La tabla que nos interesa es la primera:

```{r}
tab[[1]]
```


Esto claramente no es un set de datos _tidy_, ni siquiera un _data frame_. En el código anterior, podemos ver un patrón y es muy factible escribir código para extraer solo los datos. De hecho, __rvest__ incluye una función solo para convertir tablas HTML en _data frames_:


```{r}
tab <- tab[[1]] |> html_table()
class(tab)
```

Ahora estamos mucho más cerca de tener una tabla de datos utilizables:

```{r}
tab <- tab |> setNames(c("state", "population", "total", "murder_rate"))
head(tab)
```

Todavía tenemos que hacer un poco de _wrangling_. Por ejemplo, necesitamos eliminar las comas y convertir los caracteres en números. Antes de continuar con esto, aprenderemos un acercamiento más general para extraer información de sitios web.


## Selectores CSS {#css-selectors}

El aspecto por defecto de una página web hecha con el HTML más básico es poco atractivo. Las páginas estéticamente agradables que vemos hoy usan CSS para definir su aspecto y estilo. El hecho de que todas las páginas de una empresa tienen el mismo estilo generalmente resulta del uso del mismo archivo CSS para definir el estilo. La forma general en que funcionan estos archivos CSS es determinando cómo se verá cada uno de los elementos de una página web. El título, los encabezados, las listas detalladas, las tablas y los enlaces, por ejemplo, reciben cada uno su propio estilo, que incluye la fuente, el color, el tamaño y la distancia del margen. CSS hace esto aprovechando los patrones utilizados para definir estos elementos, denominados _selectores_. Un ejemplo de dicho patrón, que utilizamos anteriormente, es `table`, pero hay muchos más.

Si queremos obtener datos de una página web y conocemos un selector que es único para la parte de la página que contiene estos datos, podemos usar la función `html_nodes`. Sin embargo, saber qué selector puede ser bastante complicado.
De hecho, la complejidad de las páginas web ha aumentado a medida que se vuelven más sofisticadas. Para algunas de las más avanzadas, parece casi imposible encontrar los nodos que definen un dato en particular. Sin embargo, SelectorGadget lo hace posible.

SelectorGadget^[http://selectorgadget.com/] es un software que les permite determinar de manera interactiva qué selector CSS necesita para extraer componentes específicos de la página web. Si van a extraer datos que no son tablas de páginas HTML, les recomendamos que lo instalen. Chrome tiene una extensión que les permite encender el _gadget_ y luego, al hacer clic en la página, resalta partes y les muestra el selector que necesitan para extraer estas partes. Hay varias demostraciones de cómo hacer esto, incluyendo este artículo de __rvest__^[https://rvest.tidyverse.org/articles/selectorgadget.html] y otros tutoriales basados en esa vignette^[https://stat4701.github.io/edav/2015/04/02/rvest_tutorial/] ^[https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/].

## JSON

Compartir datos en Internet se ha vuelto cada vez más común. Desafortunadamente, los proveedores usan diferentes formatos, lo que añade dificultad para los científicos de datos reorganizar los datos en R. Sin embargo, hay algunos estándares que también se están volviendo más comunes. Actualmente, un formato que se está adoptando ampliamente es la Notación de Objetos JavaScript (_JavaScript Object Notation_ o JSON por sus siglas en inglés). Debido a que este formato es muy general, no se parece en nada a una hoja de cálculo. Este archivo JSON se parece más al código que usamos para definir una lista. Aquí un ejemplo de información almacenada en formato JSON:

```{r, echo=FALSE}
library(jsonlite)
example <- data.frame(name= c("Miguel", "Sofia", "Aya", "Cheng"), student_id = 1:4, exam_1 = c(85, 94, 87, 90), exam_2 = c(86, 93, 88, 91))
json <- toJSON(example, pretty = TRUE)
json
```

El archivo anterior representa un _data frame_. Para leerlo, podemos usar la función `fromJSON` del paquete __jsonlite__. Noten que los archivos JSON a menudo están disponibles a través de Internet. Varias organizaciones proveen una API JSON o un servicio web al que pueden conectarse directamente y obtener datos. Aquí un ejemplo:

```{r, eval = FALSE}
library(jsonlite)
citi_bike <- fromJSON("http://citibikenyc.com/stations/json")
```

Esto descarga una lista. El primer argumento les dice cuando lo descargaron:

```{r, eval = FALSE}
citi_bike$executionTime
```

y el segundo es una tabla de datos:

```{r, eval = FALSE}
citi_bike$stationBeanList |> as_tibble()
```


Pueden aprender mucho más examinando tutoriales y archivos de ayuda del paquete __jsonlite__. Este paquete está destinado a tareas relativamente sencillas, como convertir datos en tablas. Para mayor flexibilidad, recomendamos `rjson`.



## Ejercicios


1\. Visite la siguiente página web:

[https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm](https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm)

Observe que hay varias tablas. Digamos que estamos interesados en comparar las nóminas de los equipos a lo largo de los años. Los siguientes ejercicios nos lleva por lo pasos necesarios para hacer esto.

Comience aplicando lo que aprendió e importe el sitio web a un objeto llamado `h`.

2\. Tenga en cuenta que, aunque no es muy útil, podemos ver el contenido de la página escribiendo:

```{r, eval = FALSE}
html_text(h)
```

El siguiente paso es extraer las tablas. Para esto, podemos usar la función `html_nodes`. Aprendimos que las tablas en HTML están asociadas con el nodo `table`. Utilice la función `html_nodes` y el nodo `table` para extraer la primera tabla. Almacénela en un objeto `nodes`.



3\. La función `html_nodes` devuelve una lista de objetos de clase `xml_node`. Podemos ver el contenido de cada uno usando, por ejemplo, la función `html_text`. Puede ver el contenido de un componente elegido arbitrariamente así:

```{r, eval = FALSE}
html_text(nodes[[8]])
```

Si el contenido de este objeto es una tabla HTML, podemos usar la función `html_table` para convertirlo en un _data frame_. Utilice la función `html_table` para convertir la octava entrada de `nodes` en una tabla.


4\. Repita lo anterior para los primeros 4 componentes de `nodes`. ¿Cuáles de las siguientes son tablas de cálculo de nómina?

a. Todas.
b. 1
c. 2
d. 2-4


5\. Repita lo anterior para los 3 __últimos__ componentes de `nodes`. ¿Cuál de los siguientes es cierto?

a. La última entrada en `nodes` muestra el promedio de todos los equipos a lo largo del tiempo, no la nómina por equipo.
b. Las tres son tablas de cálculo de nómina por equipo.
c. Las tres son como la primera entrada, no una tabla de cálculo de nómina.
d. Todas las anteriores.

6\. Hemos aprendido que la primera y la última entrada de `nodes` no son tablas de cálculo de nómina. Redefina `nodes` para que estas dos se eliminen.


7\. Vimos en el análisis anterior que el primer nodo de la tabla realmente no es una tabla. Esto sucede a veces en HTML porque las tablas se usan para hacer que el texto se vea de cierta manera, en lugar de almacenar valores numéricos. Elimine el primer componente y luego use `sapply` y `html_table` para convertir cada nodo en `nodes` en una tabla. Tenga en cuenta que en este caso `sapply` devolverá una lista de tablas. También puede usar `lapply` para asegurar que se aplique una lista.



8\. Mire las tablas resultantes. ¿Son todas iguales? ¿Podríamos unirlas con `bind_rows`?


9\. Cree dos tablas utilizando las entradas 10 y 19. Llámelas `tab_1` y `tab_2`.


10\. Utilice una  función `full_join` para combinar estas dos tablas. Antes de hacer esto, corrija el problema del encabezado que falta y haga que los nombres coincidan.


11\. Después de unir las tablas, verá varias `NA`s. Esto se debe a que algunos equipos están en una tabla y no en la otra. Utilice la función `anti_join` para tener una mejor idea de por qué sucede esto.


12\. Vemos que uno de los problemas es que los Yankees figuran como _N.Y. Yankees_ y _NY Yankees_. En la siguiente sección, aprenderemos enfoques eficientes para solucionar problemas como este. Aquí podemos hacerlo "a mano" de la siguiente manera:


```{r, eval=FALSE}
tab_1 <- tab_1 |>
  mutate(Team = ifelse(Team == "N.Y. Yankees", "NY Yankees", Team))
```

Ahora una las tablas y muestre solo Oakland y los Yankees y las columnas de cálculo de nómina.

13\. __Avanzado__: Extraiga los títulos de las películas que ganaron el premio de _Best Picture_ de este sitio web: [https://m.imdb.com/chart/bestpicture/](https://m.imdb.com/chart/bestpicture/)






