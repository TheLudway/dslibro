# (PART) Machine Learning {-}

```{r, echo=FALSE}
img_path <- "ml/img/"
```

# Introducción al aprendizaje automático

Quizás las metodologías de ciencia de datos más populares provienen del campo del aprendizaje de máquinas. Las historias de éxito del aprendizaje automático incluyen lectores de códigos postales escritos a mano implementados por el servicio postal, tecnología de reconocimiento de voz como Siri de Apple, sistemas de recomendación de películas, detectores de spam y malware, predictores de precios de viviendas y automóviles sin conductor. Aunque hoy en día la Inteligencia Artificial y el aprendizaje automático se usan indistintamente, hacemos la siguiente distinción: mientras que los primeros algoritmos de inteligencia artificial, como los utilizados por las máquinas de ajedrez, implementaron la toma de decisiones basada en reglas programables derivadas de la teoría o los primeros principios, en la máquina las decisiones de aprendizaje se basan en algoritmos **construidos con datos**.

## Notación

En el aprendizaje automático, los datos se presentan en forma de:

1. el resultado que queremos predecir y
2. las _características_ que usaremos para predecir el resultado

Queremos construir un algoritmo que tome los valores de las características como entrada y devuelva una predicción para el resultado cuando no sabemos el resultado. El enfoque de aprendizaje automático consiste en entrenar un algoritmo utilizando un conjunto de datos para el que sí conocemos el resultado, y luego aplicar este algoritmo en el futuro para hacer una predicción cuando no sabemos el resultado.

Aquí usaremos $Y$ para denotar el resultado y $X_1, \dots, X_p$ para denotar características. Tenga en cuenta que las características a veces se denominan predictores o covariables. Consideramos que todos estos son sinónimos.

Los problemas de predicción se pueden dividir en resultados categóricos y continuos. Para resultados categóricos, $Y$ puede ser cualquiera de $K$ clases El número de clases puede variar mucho entre las aplicaciones.
Por ejemplo, en los datos del lector de dígitos, $K=10$ siendo las clases los dígitos 0, 1, 2, 3, 4, 5, 6, 7, 8 y 9. En el reconocimiento de voz, los resultados son todas las palabras o frases posibles que estamos tratando de detectar. La detección de spam tiene dos resultados: spam o no spam. En este libro, denotamos el $K$ categorías con índices $k=1,\dots,K$. Sin embargo, para datos binarios usaremos $k=0,1$ para conveniencias matemáticas que demostraremos más adelante.

La configuración general es la siguiente. Tenemos una serie de características y un resultado desconocido que queremos predecir:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(dslabs)
tmp <- tibble(outcome="?",
'feature 1' = "$X_1$",
'feature 2' = "$X_2$",
'feature 3' = "$X_3$",
'feature 4' = "$X_4$",
'feature 5' = "$X_5$")
if(knitr::is_html_output()){
knitr::kable(tmp, "html", align = "c") %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
knitr::kable(tmp, "latex", align="c", escape = FALSE, booktabs = TRUE) %>%
kableExtra::kable_styling(font_size = 8)
}
```

Para _construir un modelo_ que proporcione una predicción para cualquier conjunto de valores observados $X_1=x_1, X_2=x_2, \dots X_5=x_5$, recopilamos datos para los cuales conocemos el resultado:

```{r, echo=FALSE}
n <- 2
tmp <- tibble(outcome = paste0("$y_{", 1:n,"}$"),
'feature 1' = paste0("$x_{",1:n,",1}$"),
'feature 2' = paste0("$x_{",1:n,",2}$"),
'feature 3' = paste0("$x_{",1:n,",3}$"),
'feature 4' = paste0("$x_{",1:n,",4}$"),
'feature 5' = paste0("$x_{",1:n,",5}$"))
tmp_2 <- rbind(c("$\\vdots$", "$\\vdots$", "$\\vdots$", "$\\vdots$", "$\\vdots$", "$\\vdots$"),
c("$y_n$", "$x_{n,1}$","$x_{n,2}$","$x_{n,3}$","$x_{n,4}$","$x_{n,5}$"))
colnames(tmp_2) <- names(tmp)
tmp <- bind_rows(tmp, as_tibble(tmp_2))
if(knitr::is_html_output()){
knitr::kable(tmp, "html") %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
knitr::kable(tmp, "latex", escape = FALSE, booktabs = TRUE) %>%
kableExtra::kable_styling(font_size = 8)
}
```

Cuando el resultado es continuo, nos referimos a la tarea de aprendizaje automático como predicción, y el resultado principal del modelo es una función $f$ que produce automáticamente una predicción, denotada con $\hat{y}$, para cualquier conjunto de predictores: $\hat{y} = f(x_1, x_2, \dots, x_p)$. Usamos el término resultado real para denotar lo que terminamos observando. Entonces queremos la predicción $\hat{y}$ para que coincida con el resultado real $y$ tan bien como sea posible. Debido a que nuestro resultado es continuo, nuestras predicciones $\hat{y}$ no será exactamente correcto o incorrecto, sino que determinaremos un _error_ definido como la diferencia entre la predicción y el resultado real $y - \hat{y}$.

Cuando el resultado es categórico, nos referimos a la tarea de aprendizaje automático como _clasificación_, y el resultado principal del modelo será una _regla de decisión_ que prescribe cuál de las $K$ clases que debemos predecir. En este escenario, la mayoría de los modelos proporcionan funciones de los predictores para cada clase. $k$, $f_k(x_1, x_2, \dots, x_p)$, que se utilizan para tomar esta decisión. Cuando los datos son binarios, las reglas de decisión típicas se ven así: si $f_1(x_1, x_2, \dots, x_p) > C$, pronostique la categoría 1, si no la otra categoría, con $C$ un límite predeterminado. Debido a que los resultados son categóricos, nuestras predicciones serán correctas o incorrectas.

Tenga en cuenta que estos términos varían entre cursos, libros de texto y otras publicaciones. A menudo, la predicción se usa tanto para resultados categóricos como continuos, y el término _regresión_ puede usarse para el caso continuo. Aquí evitamos usar _regresión_para evitar confusiones con nuestro uso previo del término_ regresión lineal_. En la mayoría de los casos, estará claro si nuestros resultados son categóricos o continuos, por lo que evitaremos usar estos términos cuando sea posible.

## Un ejemplo

Consideremos el ejemplo del lector de código postal. El primer paso para manejar el correo recibido en la oficina de correos es ordenar las letras por código postal:

```{r, echo=FALSE, out.width="40%"}
knitr::include_graphics(file.path(img_path,"how-to-write-a-address-on-an-envelope-how-to-write-the-address-on-an-envelope-write-address-on-envelope-india-finishedenvelope-x69070.png"))
```

Originalmente, los humanos tenían que clasificarlos a mano. Para hacer esto, tuvieron que leer los códigos postales en cada letra. Hoy, gracias a los algoritmos de aprendizaje automático, una computadora puede leer códigos postales y luego un robot clasifica las letras. En esta parte del libro, aprenderemos cómo construir algoritmos que puedan leer un dígito.

El primer paso para construir un algoritmo es entender
¿cuáles son los resultados y características? A continuación hay tres imágenes de dígitos escritos. Estos ya han sido leídos por un humano y se les ha asignado un resultado. $Y$. Estos se consideran conocidos y sirven como conjunto de entrenamiento.

```{r digit-images-example, echo=FALSE, cache=TRUE}
mnist <- read_mnist()
tmp <- lapply( c(1,4,5), function(i){
expand.grid(Row=1:28, Column=1:28) %>%
mutate(id=i, label=mnist$train$label[i],
value = unlist(mnist$train$images[i,]))
})
tmp <- Reduce(rbind, tmp)
tmp %>% ggplot(aes(Row, Column, fill=value)) +
geom_raster(show.legend = FALSE) +
scale_y_reverse() +
scale_fill_gradient(low="white", high="black") +
facet_grid(.~label)
```

Las imágenes se convierten en $28 \times 28 = 784$ píxeles y, para cada píxel, obtenemos una intensidad de escala de grises entre 0 (blanco) y 255 (negro), que consideramos continua por ahora. La siguiente gráfica muestra las características individuales de cada imagen:

```{r example-images, echo=FALSE}
tmp %>% ggplot(aes(Row, Column, fill=value)) +
geom_point(pch=21) +
scale_y_reverse() +
scale_fill_gradient(low="white", high="black") +
facet_grid(.~label)
```

Para cada imagen digitalizada $i$, tenemos un resultado categórico $Y_i$ que puede ser uno de los 10 valores ( $0,1,2,3,4,5,6,7,8,9$) y características $X_{i,1}, \dots, X_{i,784}$. Usamos negrita $\mathbf{X}_i = (X_{i,1}, \dots, X_{i,784})$ para distinguir el vector de predictores de los predictores individuales. Cuando nos referimos a un conjunto arbitrario de características en lugar de una imagen específica en nuestro conjunto de datos, descartamos el índice $i$ y use $Y$ y $\mathbf{X} = (X_{1}, \dots, X_{784})$. Utilizamos variables en mayúsculas porque, en general, pensamos en los predictores como variables aleatorias. Usamos minúsculas, por ejemplo $\mathbf{X} = \mathbf{x}$, para denotar valores observados. Cuando codificamos nos quedamos en minúsculas.

La tarea de aprendizaje automático es construir un algoritmo que devuelva una predicción para cualquiera de los posibles valores de las características. Aquí, aprenderemos varios enfoques para construir estos algoritmos. Aunque en este punto puede parecer imposible lograr esto, comenzaremos con ejemplos simples y desarrollaremos nuestro conocimiento hasta que podamos atacar los más complejos. De hecho, comenzamos con un ejemplo artificialmente simple con un solo predictor y luego pasamos a un ejemplo un poco más realista con dos predictores. Una vez que comprendamos esto, atacaremos los desafíos de aprendizaje automático del mundo real que involucran muchos predictores.

## Ejercicios

1\. Para cada uno de los siguientes, determine si el resultado es continuo o categórico:

a. Lector de dígitos
si. Recomendaciones de películas
c. Filtro de spam
re. Hospitalizaciones
mi. Siri (reconocimiento de voz)


2\. ¿Cuántas funciones tenemos disponibles para la predicción en el conjunto de datos de dígitos?


3\. En el ejemplo del lector de dígitos, los resultados se almacenan aquí:

```{r, eval=FALSE}
library(dslabs)
y <- mnist$train$labels
```

¿Las siguientes operaciones tienen un significado práctico?
```{r, eval=FALSE}
y[5] + y[6]
y[5] > y[6]
```

Elige la mejor respuesta:

a. Sí porque $9 + 2 = 11$ y $9 > 2$.
si. No porque `y` no es un vector numérico.
c. No, porque 11 no es un dígito. Son dos dígitos.
re. No, porque estas son etiquetas que representan una categoría, no un número. UN `9` representa una clase, no el número 9.

