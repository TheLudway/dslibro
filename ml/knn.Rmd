## k vecinos más cercanos (kNN)

```{r, echo=FALSE, warning=FALSE, message=FALSE}
set.seed(2008)
library(tidyverse)
library(dslabs)
data("mnist_27")
# We use this function to plot the estimated conditional probabilities
plot_cond_prob <- function(p_hat=NULL){
  tmp <- mnist_27$true_p
  if(!is.null(p_hat)){
    tmp <- mutate(tmp, p=p_hat)
  }
  tmp %>% ggplot(aes(x_1, x_2, z=p, fill=p)) +
    geom_raster(show.legend = FALSE) +
    scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) +
    stat_contour(breaks=c(0.5),color="black")
}
```

Introdujimos el algoritmo kNN en la Sección \@ref(knn-cv-intro) y demostramos cómo usamos la validación cruzada para elegir $k$ en la Sección \@ref(caret-cv). Aquí revisamos rápidamente cómo ajustamos un modelo kNN usando el paquete __caret__. En la Sección \@ref(caret-cv) presentamos el siguiente código para que se ajuste a un modelo kNN:

```{r}
train_knn <- train(y ~ ., method = "knn",
                   data = mnist_27$train,
                   tuneGrid = data.frame(k = seq(9, 71, 2)))
```

Vimos que el parámetro que maximizaba la exactitud estimada era:

```{r}
train_knn$bestTune
```

Este modelo resulta en una exactitud mejor que la de regresión y la de regresión logística:

```{r}
confusionMatrix(predict(train_knn, mnist_27$test, type = "raw"),
                mnist_27$test$y)$overall["Accuracy"]
```

Un gráfico de la probabilidad condicional estimada muestra que el estimado de kNN es lo suficientemente flexible y captura la forma de la probabilidad condicional verdadera.

```{r best-knn-fit, echo=FALSE, out.width="100%"}
p1 <- plot_cond_prob() + ggtitle("True conditional probability")

p2 <- plot_cond_prob(predict(train_knn, newdata = mnist_27$true_p, type = "prob")[,2]) +
  ggtitle("kNN")

grid.arrange(p2, p1, nrow=1)
```

## Ejercicios

1\. Anteriormente utilizamos regresión logística para predecir el sexo basado en la altura. Use kNN para hacer lo mismo. Use el código descrito en este capítulo para seleccionar la medida $F_1$ y graficarla contra $k$. Compare con el $F_1$ de aproximadamente 0.6 que obtuvimos con regresión.

2\. Cargue el siguiente set de datos:

```{r, eval=FALSE}
data("tissue_gene_expression")
```

Este set de datos incluye una matriz `x`:

```{r, eval=FALSE}
dim(tissue_gene_expression$x)
```

con la expresión génica medida en 500 genes para 189 muestras biológicas que representan siete tejidos diferentes. El tipo de tejido se almacena en `y`:

```{r, eval=FALSE}
table(tissue_gene_expression$y)
```

Divida los datos en sets de entrenamiento y de evaluación. Luego use kNN para predecir el tipo de tejido y ver qué exactitud obtiene. Pruébelo para $k = 1, 3, \dots, 11$.

