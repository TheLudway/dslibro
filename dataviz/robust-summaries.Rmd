# Resúmenes robustos {#robust-summaries}



## Valores atípicos

Anteriormente describimos cómo los diagramas de caja muestran _valores atípicos_, pero no ofrecimos una definición precisa. Aquí discutimos los valores atípicos, los acercamientos que pueden ayudar a detectarlos y los resúmenes que toman en cuenta su presencia.

Los valores atípicos son muy comunes en la ciencia de datos. La recopilación de datos puede ser complejo y es común observar puntos de datos generados por error. Por ejemplo, un viejo dispositivo de monitoreo puede leer mediciones sin sentido antes de fallar por completo. El error humano también es una fuente de valores atípicos, en particular cuando la entrada de datos se realiza manualmente. Un individuo, por ejemplo, puede ingresar erróneamente su altura en centímetros en lugar de pulgadas o colocar el decimal en el lugar equivocado.

¿Cómo distinguimos un valor atípico de mediciones que son demasiado grandes o pequeños simplemente debido a la variabilidad esperada? Esta no siempre es una pregunta fácil de responder, pero intentaremos ofrecer alguna orientación. Comencemos con un caso sencillo.

Supongamos que un colega se encarga de recopilar datos demográficos para un grupo de varones. Los datos informan la altura en pies y se almacenan en el objeto:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(dslabs)
data(outlier_example)
str(outlier_example)
```

Nuestro colega utiliza el hecho de que las alturas suelen estar bien aproximadas por una distribución normal y resume los datos con el promedio y la desviación estándar:

```{r}
mean(outlier_example)
sd(outlier_example)
```

Entonces, escribe un informe sobre el hecho interesante de que este grupo de varones es mucho más alto de lo normal. ¡La altura promedio es más de seis pies de alto! Sin embargo, al usar su conocimientos de ciencia de datos, nota algo más que es inesperado: la desviación estándar es de más de 7 pies. Al sumar y restar dos desviaciones estándar, observa que el 95% de esta población parece tener alturas entre `r mean(outlier_example) + c(-2, 2)*sd(outlier_example)` pies, que no tiene sentido. Un gráfico rápido revela el problema:

<!--
```{r histogram-reveals-outliers}
qplot(outlier_example, bins = 30)
```
-->

```{r, eval=FALSE}
boxplot(outlier_example)
```

```{r, boxplot-reveals-outliers, echo=FALSE, out.width="50%"}
rafalib::mypar()
boxplot(outlier_example)
```

Parece que hay al menos un valor que no tiene sentido, ya que sabemos que una altura de `r max(outlier_example)` pies es imposible. El diagrama de caja detecta este punto como un valor atípico.

## Mediana

Cuando tenemos un valor atípico como este, el promedio puede llegar a ser muy grande. Matemáticamente, podemos hacer que el promedio sea tan grande como queramos simplemente cambiando un número: con `r length(outlier_example)` puntos de datos, podemos aumentar el promedio en cualquier cantidad $\Delta$ añadiendo $\Delta \times$ NA a un solo número. La mediana, definida como el valor para el cual la mitad de los valores son más pequeños y la otra mitad son más grandes, es robusta para tales valores atípicos. No importa cuán grande hagamos el punto más grande, la mediana sigue siendo la misma.

Con estos datos, la mediana es:

```{r}
median(outlier_example)
```
lo cual es sobre `r floor(median(outlier_example))` pies y `r round(12*(median(outlier_example) - floor(median(outlier_example))))` pulgadas.

La mediana es lo que los diagramas de caja muestran como una línea horizontal.

## El rango intercuartil (IQR)

La caja en un diagrama de caja se define por el primer y tercer cuartil. Estos están destinados a proveer una idea de la variabilidad en los datos: el 50% de los datos están dentro de este rango. La diferencia entre el 3er y 1er cuartil (o los percentiles 75 y 25) se conoce como el rango intercuartil, IQR por sus siglas en inglés. Como es el caso con la mediana, esta cantidad será robusta para los valores atípicos ya que los valores grandes no la afectan. Podemos hacer algunos cálculos para ver que para los datos que siguen la distribución normal, el IQR / 1.349 se aproxima a la desviación estándar de los datos si un valor atípico no hubiera estado presente. Podemos ver que esto funciona bien en nuestro ejemplo, ya que obtenemos una estimado de la desviación estándar de:

```{r}
IQR(outlier_example)/ 1.349
```

lo cual es sobre `r round(IQR(outlier_example)/1.349*12)` pulgadas.


## La definición de Tukey de un valor atípico

En R, los puntos que caen fuera de los bigotes del diagrama de caja se denominan _valores atípicos_ (_outliers_ en inglés). Tukey introdujo esta definición de valor atípico. El bigote superior termina en el percentil 75 más 1.5 $\times$ IQR. De manera similar, el bigote inferior termina en el percentil 25 menos 1.5 $\times$ IQR. Si definimos el primer y el tercer cuartil como $Q_1$ y $Q_3$, respectivamente, entonces un valor atípico es cualquier valor fuera del rango:

$$[Q_1 - 1.5 \times (Q_3 - Q1), Q_3 + 1.5 \times (Q_3 - Q1)].$$

Cuando los datos se distribuyen normalmente, las unidades estándar de estos valores son:

```{r}
q3 <- qnorm(0.75)
q1 <- qnorm(0.25)
iqr <- q3 - q1
r <- c(q1 - 1.5*iqr, q3 + 1.5*iqr)
r
```

Utilizando la función `pnorm`, vemos que `r round(pnorm(r[2]) - pnorm(r[1]),3)*100`% de los datos cae en este intervalo.

Tengan en cuenta que este no es un evento tan extremo: si tenemos 1000 puntos de datos que se distribuyen normalmente, esperamos ver unos 7 fuera de este rango. Pero estos no serían valores atípicos ya que esperamos verlos bajo la variación típica.

Si queremos que un valor atípico sea más raro, podemos aumentar el 1.5 a un número mayor. Tukey también usó 3 y los denominó _far out outliers_ o _valores atípicos extremos_. Con una distribución normal,
`r r <- c(q1 - 3*iqr , q3 + 3*iqr); round((pnorm(r[2]) - pnorm(r[1]))*100, 4)`%
de los datos caen en este intervalo. Esto se traduce en aproximadamente 2 en un millón de posibilidades de estar fuera del rango. En la función `geom_boxplot`, esto puede ser controlado por el argumento `outlier.size`, que por defecto es 1.5.

La medida de 180 pulgadas está más allá del rango de los datos de altura:

```{r}
max_height <- quantile(outlier_example, 0.75) + 3*IQR(outlier_example)
max_height
```

Si sacamos este valor, podemos ver que los datos se distribuyen normalmente como se esperaba:

```{r eval=FALSE}
x <- outlier_example[outlier_example < max_height]
qqnorm(x)
qqline(x)
```

```{r outlier-qqnorm, echo=FALSE}
rafalib::mypar()
x <- outlier_example[outlier_example < max_height]
qqnorm(x)
qqline(x)
```


## [fix] Desviación absoluta mediana

Otra forma de estimar de manera robusta la desviación estándar en presencia de valores atípicos es usar la desviación absoluta mediana o MAD (_median absolute deviation_) por sus siglas en inglés. Para calcular el MAD, primero calculamos la mediana y luego, para cada valor, calculamos la distancia entre ese valor y la mediana. El MAD se define como la mediana de estas distancias. Por razones técnicas no que no discutimos aquí, esta cantidad debe multiplicarse por 1.4826 para asegurar que se aproxima a la desviación estándar real. La función  `mad` ya incorpora esta corrección. Para los datos de altura, obtenemos una MAD de:

```{r}
mad(outlier_example)
```

lo cual es como `r round(mad(outlier_example)*12)` pulgadas.



## Ejercicios

Vamos a usar el paquete __HistData__. Si no lo han instalando, pueden hacerlo así:

```{r, eval=FALSE}
install.packages("HistData")
```

Carguen el set de datos de altura y crean un vector `x` con solo las alturas masculinas de los datos de Galton sobre las alturas de los padres y sus hijos de su investigación histórica sobre la herencia.

```{r, eval=FALSE}
library(HistData)
data(Galton)
x <- Galton$child
```

1\. Calcule el promedio y la mediana de estos datos.

2\. Calcule la mediana y el MAD de estos datos.


3\. Ahora supongamos que Galton cometió un error al ingresar el primer valor y olvidó usar el punto decimal. Puede imitar este error al escribir:

```{r, eval=FALSE}
x_with_error <- x
x_with_error[1] <- x_with_error[1]*10
```

¿Cuántas pulgadas crece el promedio después de este error?

4\. ¿Cuántas pulgadas crece la SD después de este error?

5\. ¿Cuántas pulgadas crece la mediana después de este error?

6\. ¿Cuántas pulgadas crece el MAD después de este error?

7\. ¿Cómo podría utilizar el análisis exploratorio de datos para detectar que se cometió un error?

a. Dado que es solo un valor entre muchos, no se puede detectar esto.
b. Veríamos un cambio obvio en la distribución.
c. Un diagrama de caja, histograma o diagrama q-q revelaría un valor atípico obvio.
d. Un diagrama de dispersión mostraría altos niveles de error de medición.


8\. ¿Cuánto puede crecer el promedio accidentalmente con errores como este? Escribe una función llamada `error_avg` que toma un valor `k` y devuelve el promedio del vector `x` después de que la primera entrada cambia a `k`. Muestre los resultados para `k=10000` y `k=-10000`.

## Estudio de caso: [fix] alturas de estudiantes autodeclarados

Las alturas que hemos estado viendo no son las alturas originales reportadas por los estudiantes. Las alturas informadas originales también se incluyen en el paquete __dslabs__ y se pueden cargar así:

```{r}
library(dslabs)
data("reported_heights")
```

La altura es un vector de caracteres, por lo que creamos una nueva columna con la versión numérica:

```{r}
reported_heights <- reported_heights %>%
mutate(original_heights = height, height = as.numeric(height))
```

Tengan en cuenta que recibimos una advertencia sobre las NAs. Esto se debe a que algunas de las alturas autoinformadas no eran números. Podemos ver por qué obtenemos estos:

```{r, warning=FALSE}
reported_heights %>% filter(is.na(height)) %>% head()
```

Algunos estudiantes informaron sus alturas usando pies y pulgadas en lugar de solo pulgadas. Otros usaron centímetros y otros solo estaban trolleando. Por ahora eliminaremos estas entradas:


```{r}
reported_heights <- filter(reported_heights, !is.na(height))
```

Si calculamos promedio y la desviación estándar, notamos que obtenemos resultados extraños. El promedio y la desviación estándar son diferentes de la mediana y del MAD:

```{r}
reported_heights %>%
group_by(sex) %>%
summarize(average = mean(height), sd = sd(height),
median = median(height), MAD = mad(height))
```

Esto sugiere que tenemos valores atípicos, lo que se confirma creando un diagrama de caja:

```{r height-outlier-ggplot, echo=FALSE}
reported_heights %>%
ggplot(aes(sex, height)) +
geom_boxplot()
```

Podemos ver algunos valores bastante extremos. Para ver cuáles son estos valores, podemos rápidamente mirar los valores más grandes utilizando la función `arrange`:

```{r}
reported_heights %>% arrange(desc(height)) %>% top_n(10, height)
```

Las primeras siete entradas parecen errores extraños. Sin embargo, los siguientes parecen haber sido ingresados como centímetros en lugar de pulgadas. Dado que 184 cm es equivalente a seis pies de alto, sospechamos que 184 en realidad significa 72 pulgadas.

Podemos revisar todas las respuestas sin sentido observando los datos que Tukey[fix] considera _far out_ o superextremos:

```{r}
whisker <- 3*IQR(reported_heights$height)
max_height <- quantile(reported_heights$height, .75) + whisker
min_height <- quantile(reported_heights$height, .25) - whisker
reported_heights %>%
filter(!between(height, min_height, max_height)) %>%
select(original_heights) %>%
head(n=10) %>% pull(original_heights)
```

Examinando estas alturas cuidadosamente, vemos dos errores comunes: entradas en centímetros, que resultan ser demasiado grandes, y entradas del tipo `x.y` con `x` y `y` representando pies y pulgadas, respectivamente, que resultan ser demasiado pequeños. Algunos de los valores aún más pequeños, como 1.6, podrían ser entradas en metros.

En la parte de _Data Wrangling_ de este libro, aprenderemos técnicas para corregir estos valores y convertirlos en pulgadas. Aquí pudimos detectar este problema mediante una cuidadosa exploración de los datos para descubrir problemas con ellos: el primer paso en la gran mayoría de los proyectos de ciencia de datos.
