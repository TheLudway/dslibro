<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 18 Modelos lineales | Introducción a la Ciencia de Datos</title>
  <meta name="description" content="Este libro presenta conceptos y destrezas que les ayudarán abordar los retos de situaciones actuales del análisis de datos. Cubre conceptos de probabilidad, inferencia estadística, regresión lineal y machine learning. Además, les permitirá desarrollar destrezas como la programación R, el wrangling de datos con dplyr, la visualización de datos con ggplot2, la organización de archivos con Shell de UNIX / Linux, el control de versiones con GitHub y la preparación de documentos reproducibles con R markdown." />
  <meta name="generator" content="bookdown 0.20.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 18 Modelos lineales | Introducción a la Ciencia de Datos" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este libro presenta conceptos y destrezas que les ayudarán abordar los retos de situaciones actuales del análisis de datos. Cubre conceptos de probabilidad, inferencia estadística, regresión lineal y machine learning. Además, les permitirá desarrollar destrezas como la programación R, el wrangling de datos con dplyr, la visualización de datos con ggplot2, la organización de archivos con Shell de UNIX / Linux, el control de versiones con GitHub y la preparación de documentos reproducibles con R markdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 18 Modelos lineales | Introducción a la Ciencia de Datos" />
  
  <meta name="twitter:description" content="Este libro presenta conceptos y destrezas que les ayudarán abordar los retos de situaciones actuales del análisis de datos. Cubre conceptos de probabilidad, inferencia estadística, regresión lineal y machine learning. Además, les permitirá desarrollar destrezas como la programación R, el wrangling de datos con dplyr, la visualización de datos con ggplot2, la organización de archivos con Shell de UNIX / Linux, el control de versiones con GitHub y la preparación de documentos reproducibles con R markdown." />
  

<meta name="author" content="Rafael A. Irizarry" />


<meta name="date" content="2020-09-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression.html"/>
<link rel="next" href="la-asociación-no-implica-causalidad.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introducción a la Ciencia de Datos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="" data-path="agradecimientos.html"><a href="agradecimientos.html"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i>Introducción</a><ul>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#los-casos-de-estudio"><i class="fa fa-check"></i>Los casos de estudio</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#quién-encontrará-útil-este-libro"><i class="fa fa-check"></i>¿Quién encontrará útil este libro?</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#que-cubre-este-libro"><i class="fa fa-check"></i>¿Que cubre este libro?</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#qué-no-cubre-este-libro"><i class="fa fa-check"></i>¿Qué no cubre este libro?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Comenzando con R y RStudio</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#por-qué-r"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué R?</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#la-consola-r"><i class="fa fa-check"></i><b>1.2</b> La consola R</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#scripts"><i class="fa fa-check"></i><b>1.3</b> <em>Scripts</em></a></li>
<li class="chapter" data-level="1.4" data-path="getting-started.html"><a href="getting-started.html#rstudio"><i class="fa fa-check"></i><b>1.4</b> RStudio</a><ul>
<li class="chapter" data-level="1.4.1" data-path="getting-started.html"><a href="getting-started.html#paneles"><i class="fa fa-check"></i><b>1.4.1</b> Paneles</a></li>
<li class="chapter" data-level="1.4.2" data-path="getting-started.html"><a href="getting-started.html#key-bindings"><i class="fa fa-check"></i><b>1.4.2</b> <em>Key bindings</em></a></li>
<li class="chapter" data-level="1.4.3" data-path="getting-started.html"><a href="getting-started.html#cómo-ejecutar-comandos-mientras-edita-scripts"><i class="fa fa-check"></i><b>1.4.3</b> Cómo ejecutar comandos mientras edita <em>scripts</em></a></li>
<li class="chapter" data-level="1.4.4" data-path="getting-started.html"><a href="getting-started.html#cómo-cambiar-las-opciones-globales"><i class="fa fa-check"></i><b>1.4.4</b> Cómo cambiar las opciones globales</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="getting-started.html"><a href="getting-started.html#instalación-de-paquetes-de-r"><i class="fa fa-check"></i><b>1.5</b> Instalación de paquetes de R</a></li>
</ul></li>
<li class="part"><span><b>I R</b></span></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> Lo básico de R</a><ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#caso-de-estudio-los-asesinatos-con-armas-en-ee.-uu."><i class="fa fa-check"></i><b>2.1</b> Caso de estudio: los asesinatos con armas en EE. UU.</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#lo-básico"><i class="fa fa-check"></i><b>2.2</b> Lo básico</a><ul>
<li class="chapter" data-level="2.2.1" data-path="r-basics.html"><a href="r-basics.html#objetos"><i class="fa fa-check"></i><b>2.2.1</b> Objetos</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-basics.html"><a href="r-basics.html#el-espacio-de-trabajo"><i class="fa fa-check"></i><b>2.2.2</b> El espacio de trabajo</a></li>
<li class="chapter" data-level="2.2.3" data-path="r-basics.html"><a href="r-basics.html#funciones"><i class="fa fa-check"></i><b>2.2.3</b> Funciones</a></li>
<li class="chapter" data-level="2.2.4" data-path="r-basics.html"><a href="r-basics.html#otros-objetos-predefinidos"><i class="fa fa-check"></i><b>2.2.4</b> Otros objetos predefinidos</a></li>
<li class="chapter" data-level="2.2.5" data-path="r-basics.html"><a href="r-basics.html#nombres-de-variables"><i class="fa fa-check"></i><b>2.2.5</b> Nombres de variables</a></li>
<li class="chapter" data-level="2.2.6" data-path="r-basics.html"><a href="r-basics.html#cómo-guardar-su-espacio-de-trabajo"><i class="fa fa-check"></i><b>2.2.6</b> Cómo guardar su espacio de trabajo</a></li>
<li class="chapter" data-level="2.2.7" data-path="r-basics.html"><a href="r-basics.html#scripts-motivantes"><i class="fa fa-check"></i><b>2.2.7</b> <em>Scripts</em> motivantes</a></li>
<li class="chapter" data-level="2.2.8" data-path="r-basics.html"><a href="r-basics.html#cómo-comentar-su-código"><i class="fa fa-check"></i><b>2.2.8</b> Cómo comentar su código</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#ejercicios"><i class="fa fa-check"></i><b>2.3</b> Ejercicios</a></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#tipos-de-datos"><i class="fa fa-check"></i><b>2.4</b> Tipos de datos</a><ul>
<li class="chapter" data-level="2.4.1" data-path="r-basics.html"><a href="r-basics.html#data-frames"><i class="fa fa-check"></i><b>2.4.1</b> <em>data frames</em></a></li>
<li class="chapter" data-level="2.4.2" data-path="r-basics.html"><a href="r-basics.html#cómo-examinar-un-objeto"><i class="fa fa-check"></i><b>2.4.2</b> Cómo examinar un objeto</a></li>
<li class="chapter" data-level="2.4.3" data-path="r-basics.html"><a href="r-basics.html#el-operador-de-acceso"><i class="fa fa-check"></i><b>2.4.3</b> El operador de acceso: <code>$</code></a></li>
<li class="chapter" data-level="2.4.4" data-path="r-basics.html"><a href="r-basics.html#vectores-numéricos-de-caracteres-y-lógicos"><i class="fa fa-check"></i><b>2.4.4</b> Vectores: numéricos, de caracteres y lógicos</a></li>
<li class="chapter" data-level="2.4.5" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>2.4.5</b> Factores</a></li>
<li class="chapter" data-level="2.4.6" data-path="r-basics.html"><a href="r-basics.html#listas"><i class="fa fa-check"></i><b>2.4.6</b> Listas</a></li>
<li class="chapter" data-level="2.4.7" data-path="r-basics.html"><a href="r-basics.html#matrices"><i class="fa fa-check"></i><b>2.4.7</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#ejercicios-1"><i class="fa fa-check"></i><b>2.5</b> Ejercicios</a></li>
<li class="chapter" data-level="2.6" data-path="r-basics.html"><a href="r-basics.html#vectors"><i class="fa fa-check"></i><b>2.6</b> Vectores</a><ul>
<li class="chapter" data-level="2.6.1" data-path="r-basics.html"><a href="r-basics.html#cómo-crear-vectores"><i class="fa fa-check"></i><b>2.6.1</b> Cómo crear vectores</a></li>
<li class="chapter" data-level="2.6.2" data-path="r-basics.html"><a href="r-basics.html#nombres"><i class="fa fa-check"></i><b>2.6.2</b> Nombres</a></li>
<li class="chapter" data-level="2.6.3" data-path="r-basics.html"><a href="r-basics.html#secuencias"><i class="fa fa-check"></i><b>2.6.3</b> Secuencias</a></li>
<li class="chapter" data-level="2.6.4" data-path="r-basics.html"><a href="r-basics.html#cómo-crear-un-subconjunto"><i class="fa fa-check"></i><b>2.6.4</b> Cómo crear un subconjunto</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="r-basics.html"><a href="r-basics.html#la-conversión-forzada"><i class="fa fa-check"></i><b>2.7</b> La conversión forzada</a><ul>
<li class="chapter" data-level="2.7.1" data-path="r-basics.html"><a href="r-basics.html#not-available-na"><i class="fa fa-check"></i><b>2.7.1</b> <em>Not available</em> (NA)</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="r-basics.html"><a href="r-basics.html#ejercicios-2"><i class="fa fa-check"></i><b>2.8</b> Ejercicios</a></li>
<li class="chapter" data-level="2.9" data-path="r-basics.html"><a href="r-basics.html#sorting"><i class="fa fa-check"></i><b>2.9</b> <em>Sorting</em></a><ul>
<li class="chapter" data-level="2.9.1" data-path="r-basics.html"><a href="r-basics.html#sort"><i class="fa fa-check"></i><b>2.9.1</b> <code>sort</code></a></li>
<li class="chapter" data-level="2.9.2" data-path="r-basics.html"><a href="r-basics.html#order"><i class="fa fa-check"></i><b>2.9.2</b> <code>order</code></a></li>
<li class="chapter" data-level="2.9.3" data-path="r-basics.html"><a href="r-basics.html#max-y-which.max"><i class="fa fa-check"></i><b>2.9.3</b> <code>max</code> y <code>which.max</code></a></li>
<li class="chapter" data-level="2.9.4" data-path="r-basics.html"><a href="r-basics.html#rank"><i class="fa fa-check"></i><b>2.9.4</b> <code>rank</code></a></li>
<li class="chapter" data-level="2.9.5" data-path="r-basics.html"><a href="r-basics.html#cuidado-con-el-reciclaje"><i class="fa fa-check"></i><b>2.9.5</b> Cuidado con el reciclaje</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="r-basics.html"><a href="r-basics.html#ejercicios-3"><i class="fa fa-check"></i><b>2.10</b> Ejercicios</a></li>
<li class="chapter" data-level="2.11" data-path="r-basics.html"><a href="r-basics.html#aritmética-de-vectores"><i class="fa fa-check"></i><b>2.11</b> Aritmética de vectores</a><ul>
<li class="chapter" data-level="2.11.1" data-path="r-basics.html"><a href="r-basics.html#rescaling-un-vector"><i class="fa fa-check"></i><b>2.11.1</b> <em>Rescaling</em> un vector</a></li>
<li class="chapter" data-level="2.11.2" data-path="r-basics.html"><a href="r-basics.html#dos-vectores"><i class="fa fa-check"></i><b>2.11.2</b> Dos vectores</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="r-basics.html"><a href="r-basics.html#ejercicios-4"><i class="fa fa-check"></i><b>2.12</b> Ejercicios</a></li>
<li class="chapter" data-level="2.13" data-path="r-basics.html"><a href="r-basics.html#indexación"><i class="fa fa-check"></i><b>2.13</b> Indexación</a><ul>
<li class="chapter" data-level="2.13.1" data-path="r-basics.html"><a href="r-basics.html#crear-subconjuntos-con-lógicos"><i class="fa fa-check"></i><b>2.13.1</b> Crear subconjuntos con lógicos</a></li>
<li class="chapter" data-level="2.13.2" data-path="r-basics.html"><a href="r-basics.html#operadores-lógicos"><i class="fa fa-check"></i><b>2.13.2</b> Operadores lógicos</a></li>
<li class="chapter" data-level="2.13.3" data-path="r-basics.html"><a href="r-basics.html#which"><i class="fa fa-check"></i><b>2.13.3</b> <code>which</code></a></li>
<li class="chapter" data-level="2.13.4" data-path="r-basics.html"><a href="r-basics.html#match"><i class="fa fa-check"></i><b>2.13.4</b> <code>match</code></a></li>
<li class="chapter" data-level="2.13.5" data-path="r-basics.html"><a href="r-basics.html#in"><i class="fa fa-check"></i><b>2.13.5</b> <code>%in%</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="r-basics.html"><a href="r-basics.html#ejercicios-5"><i class="fa fa-check"></i><b>2.14</b> Ejercicios</a></li>
<li class="chapter" data-level="2.15" data-path="r-basics.html"><a href="r-basics.html#gráficos-básicos"><i class="fa fa-check"></i><b>2.15</b> Gráficos básicos</a><ul>
<li class="chapter" data-level="2.15.1" data-path="r-basics.html"><a href="r-basics.html#plot"><i class="fa fa-check"></i><b>2.15.1</b> <code>plot</code></a></li>
<li class="chapter" data-level="2.15.2" data-path="r-basics.html"><a href="r-basics.html#hist"><i class="fa fa-check"></i><b>2.15.2</b> <code>hist</code></a></li>
<li class="chapter" data-level="2.15.3" data-path="r-basics.html"><a href="r-basics.html#boxplot"><i class="fa fa-check"></i><b>2.15.3</b> <code>boxplot</code></a></li>
<li class="chapter" data-level="2.15.4" data-path="r-basics.html"><a href="r-basics.html#image"><i class="fa fa-check"></i><b>2.15.4</b> <code>image</code></a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="r-basics.html"><a href="r-basics.html#ejercicios-6"><i class="fa fa-check"></i><b>2.16</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html"><i class="fa fa-check"></i><b>3</b> Conceptos básicos de programación</a><ul>
<li class="chapter" data-level="3.1" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#conditionals"><i class="fa fa-check"></i><b>3.1</b> Expresiones condicionales</a></li>
<li class="chapter" data-level="3.2" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#cómo-definir-funciones"><i class="fa fa-check"></i><b>3.2</b> Cómo definir funciones</a></li>
<li class="chapter" data-level="3.3" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#namespaces"><i class="fa fa-check"></i><b>3.3</b> <em>Namespaces</em></a></li>
<li class="chapter" data-level="3.4" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#bucles-for"><i class="fa fa-check"></i><b>3.4</b> Bucles-for</a></li>
<li class="chapter" data-level="3.5" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#vectorization"><i class="fa fa-check"></i><b>3.5</b> Vectorización y funcionales</a></li>
<li class="chapter" data-level="3.6" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#ejercicios-7"><i class="fa fa-check"></i><b>3.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>4</b> <em>tidyverse</em></a><ul>
<li class="chapter" data-level="4.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy-data"><i class="fa fa-check"></i><b>4.1</b> Data <em>tidy</em></a></li>
<li class="chapter" data-level="4.2" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-8"><i class="fa fa-check"></i><b>4.2</b> Ejercicios</a></li>
<li class="chapter" data-level="4.3" data-path="tidyverse.html"><a href="tidyverse.html#cómo-manipular-los-data-frames"><i class="fa fa-check"></i><b>4.3</b> Cómo manipular los <em>data frames</em></a><ul>
<li class="chapter" data-level="4.3.1" data-path="tidyverse.html"><a href="tidyverse.html#cómo-añadir-una-columna-con-mutate"><i class="fa fa-check"></i><b>4.3.1</b> Cómo añadir una columna con <code>mutate</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="tidyverse.html"><a href="tidyverse.html#cómo-crear-subconjuntos-con-filter"><i class="fa fa-check"></i><b>4.3.2</b> Cómo crear subconjuntos con <code>filter</code></a></li>
<li class="chapter" data-level="4.3.3" data-path="tidyverse.html"><a href="tidyverse.html#cómo-seleccionar-columnas-con-select"><i class="fa fa-check"></i><b>4.3.3</b> Cómo seleccionar columnas con <code>select</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-9"><i class="fa fa-check"></i><b>4.4</b> Ejercicios</a></li>
<li class="chapter" data-level="4.5" data-path="tidyverse.html"><a href="tidyverse.html#el-pipe"><i class="fa fa-check"></i><b>4.5</b> El <em>pipe</em>: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.6" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-10"><i class="fa fa-check"></i><b>4.6</b> Ejercicios</a></li>
<li class="chapter" data-level="4.7" data-path="tidyverse.html"><a href="tidyverse.html#cómo-resumir-datos"><i class="fa fa-check"></i><b>4.7</b> Cómo resumir datos</a><ul>
<li class="chapter" data-level="4.7.1" data-path="tidyverse.html"><a href="tidyverse.html#summarize"><i class="fa fa-check"></i><b>4.7.1</b> <code>summarize</code></a></li>
<li class="chapter" data-level="4.7.2" data-path="tidyverse.html"><a href="tidyverse.html#pull"><i class="fa fa-check"></i><b>4.7.2</b> <code>pull</code></a></li>
<li class="chapter" data-level="4.7.3" data-path="tidyverse.html"><a href="tidyverse.html#group-by"><i class="fa fa-check"></i><b>4.7.3</b> Cómo agrupar y luego resumir con <code>group_by</code></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="tidyverse.html"><a href="tidyverse.html#cómo-ordenar-los-data-frames"><i class="fa fa-check"></i><b>4.8</b> Cómo ordenar los <em>data frames</em></a><ul>
<li class="chapter" data-level="4.8.1" data-path="tidyverse.html"><a href="tidyverse.html#cómo-ordenar-anidadamente"><i class="fa fa-check"></i><b>4.8.1</b> Cómo ordenar anidadamente</a></li>
<li class="chapter" data-level="4.8.2" data-path="tidyverse.html"><a href="tidyverse.html#los-primeros-n"><i class="fa fa-check"></i><b>4.8.2</b> Los primeros <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-11"><i class="fa fa-check"></i><b>4.9</b> Ejercicios</a></li>
<li class="chapter" data-level="4.10" data-path="tidyverse.html"><a href="tidyverse.html#tibbles"><i class="fa fa-check"></i><b>4.10</b> <em>Tibbles</em></a><ul>
<li class="chapter" data-level="4.10.1" data-path="tidyverse.html"><a href="tidyverse.html#los-tibbles-se-ven-mejor"><i class="fa fa-check"></i><b>4.10.1</b> Los <em>tibbles</em> se ven mejor</a></li>
<li class="chapter" data-level="4.10.2" data-path="tidyverse.html"><a href="tidyverse.html#los-subconjuntos-de-tibbles-son-tibbles"><i class="fa fa-check"></i><b>4.10.2</b> Los subconjuntos de <em>tibbles</em> son <em>tibbles</em></a></li>
<li class="chapter" data-level="4.10.3" data-path="tidyverse.html"><a href="tidyverse.html#los-tibbles-pueden-tener-entradas-complejas"><i class="fa fa-check"></i><b>4.10.3</b> Los <em>tibbles</em> pueden tener entradas complejas</a></li>
<li class="chapter" data-level="4.10.4" data-path="tidyverse.html"><a href="tidyverse.html#los-tibbles-se-pueden-agrupar"><i class="fa fa-check"></i><b>4.10.4</b> Los <em>tibbles</em> se pueden agrupar</a></li>
<li class="chapter" data-level="4.10.5" data-path="tidyverse.html"><a href="tidyverse.html#cómo-crear-un-tibble-usando-tibble-en-lugar-de-data.frame"><i class="fa fa-check"></i><b>4.10.5</b> Cómo crear un <em>tibble</em> usando <code>tibble</code> en lugar de <code>data.frame</code></a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="tidyverse.html"><a href="tidyverse.html#el-operador-punto"><i class="fa fa-check"></i><b>4.11</b> El operador punto</a></li>
<li class="chapter" data-level="4.12" data-path="tidyverse.html"><a href="tidyverse.html#do"><i class="fa fa-check"></i><b>4.12</b> <code>do</code></a></li>
<li class="chapter" data-level="4.13" data-path="tidyverse.html"><a href="tidyverse.html#el-paquete-purrr"><i class="fa fa-check"></i><b>4.13</b> El paquete <strong>purrr</strong></a></li>
<li class="chapter" data-level="4.14" data-path="tidyverse.html"><a href="tidyverse.html#los-condicionales-de-tidyverse"><i class="fa fa-check"></i><b>4.14</b> Los condicionales de <em>tidyverse</em></a><ul>
<li class="chapter" data-level="4.14.1" data-path="tidyverse.html"><a href="tidyverse.html#case_when"><i class="fa fa-check"></i><b>4.14.1</b> <code>case_when</code></a></li>
<li class="chapter" data-level="4.14.2" data-path="tidyverse.html"><a href="tidyverse.html#between"><i class="fa fa-check"></i><b>4.14.2</b> <code>between</code></a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-12"><i class="fa fa-check"></i><b>4.15</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>5</b> Importando datos</a><ul>
<li class="chapter" data-level="5.1" data-path="importing-data.html"><a href="importing-data.html#las-rutas-y-el-directorio-de-trabajo"><i class="fa fa-check"></i><b>5.1</b> Las rutas y el directorio de trabajo</a><ul>
<li class="chapter" data-level="5.1.1" data-path="importing-data.html"><a href="importing-data.html#el-sistema-de-archivos"><i class="fa fa-check"></i><b>5.1.1</b> El sistema de archivos</a></li>
<li class="chapter" data-level="5.1.2" data-path="importing-data.html"><a href="importing-data.html#las-rutas-relativas-y-completas"><i class="fa fa-check"></i><b>5.1.2</b> Las rutas relativas y completas</a></li>
<li class="chapter" data-level="5.1.3" data-path="importing-data.html"><a href="importing-data.html#el-directorio-de-trabajo"><i class="fa fa-check"></i><b>5.1.3</b> El directorio de trabajo</a></li>
<li class="chapter" data-level="5.1.4" data-path="importing-data.html"><a href="importing-data.html#cómo-generar-los-nombres-de-ruta"><i class="fa fa-check"></i><b>5.1.4</b> Cómo generar los nombres de ruta</a></li>
<li class="chapter" data-level="5.1.5" data-path="importing-data.html"><a href="importing-data.html#cómo-copiar-los-archivos-usando-rutas"><i class="fa fa-check"></i><b>5.1.5</b> Cómo copiar los archivos usando rutas</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importing-data.html"><a href="importing-data.html#los-paquetes-readr-y-readxl"><i class="fa fa-check"></i><b>5.2</b> Los paquetes readr y readxl</a><ul>
<li class="chapter" data-level="5.2.1" data-path="importing-data.html"><a href="importing-data.html#readr"><i class="fa fa-check"></i><b>5.2.1</b> readr</a></li>
<li class="chapter" data-level="5.2.2" data-path="importing-data.html"><a href="importing-data.html#readxl"><i class="fa fa-check"></i><b>5.2.2</b> readxl</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="importing-data.html"><a href="importing-data.html#ejercicios-13"><i class="fa fa-check"></i><b>5.3</b> Ejercicios</a></li>
<li class="chapter" data-level="5.4" data-path="importing-data.html"><a href="importing-data.html#cómo-descargar-archivos"><i class="fa fa-check"></i><b>5.4</b> Cómo descargar archivos</a></li>
<li class="chapter" data-level="5.5" data-path="importing-data.html"><a href="importing-data.html#las-funciones-de-importación-de-base-r"><i class="fa fa-check"></i><b>5.5</b> Las funciones de importación de base R</a><ul>
<li class="chapter" data-level="5.5.1" data-path="importing-data.html"><a href="importing-data.html#scan"><i class="fa fa-check"></i><b>5.5.1</b> <code>scan</code></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="importing-data.html"><a href="importing-data.html#archivos-de-texto-versus-archivos-binarios"><i class="fa fa-check"></i><b>5.6</b> Archivos de texto versus archivos binarios</a></li>
<li class="chapter" data-level="5.7" data-path="importing-data.html"><a href="importing-data.html#unicode-versus-ascii"><i class="fa fa-check"></i><b>5.7</b> Unicode versus ASCII</a></li>
<li class="chapter" data-level="5.8" data-path="importing-data.html"><a href="importing-data.html#cómo-organizar-datos-con-hojas-de-cálculo"><i class="fa fa-check"></i><b>5.8</b> Cómo organizar datos con hojas de cálculo</a></li>
<li class="chapter" data-level="5.9" data-path="importing-data.html"><a href="importing-data.html#ejercicios-14"><i class="fa fa-check"></i><b>5.9</b> Ejercicios</a></li>
</ul></li>
<li class="part"><span><b>II Visualización de datos</b></span></li>
<li class="chapter" data-level="6" data-path="introducción-a-la-visualización-de-datos.html"><a href="introducción-a-la-visualización-de-datos.html"><i class="fa fa-check"></i><b>6</b> Introducción a la visualización de datos</a></li>
<li class="chapter" data-level="7" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i><b>7</b> ggplot2</a><ul>
<li class="chapter" data-level="7.1" data-path="ggplot2.html"><a href="ggplot2.html#los-componentes-de-un-gráfico"><i class="fa fa-check"></i><b>7.1</b> Los componentes de un gráfico</a></li>
<li class="chapter" data-level="7.2" data-path="ggplot2.html"><a href="ggplot2.html#objetos-ggplot"><i class="fa fa-check"></i><b>7.2</b> objetos <code>ggplot</code></a></li>
<li class="chapter" data-level="7.3" data-path="ggplot2.html"><a href="ggplot2.html#geometrías"><i class="fa fa-check"></i><b>7.3</b> Geometrías</a></li>
<li class="chapter" data-level="7.4" data-path="ggplot2.html"><a href="ggplot2.html#mapeos-estéticos"><i class="fa fa-check"></i><b>7.4</b> Mapeos estéticos</a></li>
<li class="chapter" data-level="7.5" data-path="ggplot2.html"><a href="ggplot2.html#capas"><i class="fa fa-check"></i><b>7.5</b> Capas</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ggplot2.html"><a href="ggplot2.html#cómo-probar-varios-argumentos"><i class="fa fa-check"></i><b>7.5.1</b> Cómo probar varios argumentos</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ggplot2.html"><a href="ggplot2.html#mapeos-estéticos-globales-versus-locales"><i class="fa fa-check"></i><b>7.6</b> Mapeos estéticos globales versus locales</a></li>
<li class="chapter" data-level="7.7" data-path="ggplot2.html"><a href="ggplot2.html#escalas"><i class="fa fa-check"></i><b>7.7</b> Escalas</a></li>
<li class="chapter" data-level="7.8" data-path="ggplot2.html"><a href="ggplot2.html#etiquetas-y-títulos"><i class="fa fa-check"></i><b>7.8</b> Etiquetas y títulos</a></li>
<li class="chapter" data-level="7.9" data-path="ggplot2.html"><a href="ggplot2.html#categorías-como-colores"><i class="fa fa-check"></i><b>7.9</b> Categorías como colores</a></li>
<li class="chapter" data-level="7.10" data-path="ggplot2.html"><a href="ggplot2.html#anotación-formas-y-ajustes"><i class="fa fa-check"></i><b>7.10</b> Anotación, formas y ajustes</a></li>
<li class="chapter" data-level="7.11" data-path="ggplot2.html"><a href="ggplot2.html#add-on-packages"><i class="fa fa-check"></i><b>7.11</b> Paquetes complementarios</a></li>
<li class="chapter" data-level="7.12" data-path="ggplot2.html"><a href="ggplot2.html#cómo-combinarlo-todo"><i class="fa fa-check"></i><b>7.12</b> Cómo combinarlo todo</a></li>
<li class="chapter" data-level="7.13" data-path="ggplot2.html"><a href="ggplot2.html#qplot"><i class="fa fa-check"></i><b>7.13</b> Gráficos rápidos con <code>qplot</code></a></li>
<li class="chapter" data-level="7.14" data-path="ggplot2.html"><a href="ggplot2.html#cuadrículas-de-gráficos"><i class="fa fa-check"></i><b>7.14</b> Cuadrículas de gráficos</a></li>
<li class="chapter" data-level="7.15" data-path="ggplot2.html"><a href="ggplot2.html#ejercicios-15"><i class="fa fa-check"></i><b>7.15</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>8</b> Cómo visualizar distribuciones de datos</a><ul>
<li class="chapter" data-level="8.1" data-path="distributions.html"><a href="distributions.html#tipos-de-variables"><i class="fa fa-check"></i><b>8.1</b> Tipos de variables</a></li>
<li class="chapter" data-level="8.2" data-path="distributions.html"><a href="distributions.html#estudio-de-caso-describiendo-alturas-de-estudiantes"><i class="fa fa-check"></i><b>8.2</b> Estudio de caso: describiendo alturas de estudiantes</a></li>
<li class="chapter" data-level="8.3" data-path="distributions.html"><a href="distributions.html#la-función-de-distribución"><i class="fa fa-check"></i><b>8.3</b> La función de distribución</a></li>
<li class="chapter" data-level="8.4" data-path="distributions.html"><a href="distributions.html#cdf-intro"><i class="fa fa-check"></i><b>8.4</b> Funciones de distribución acumulada</a></li>
<li class="chapter" data-level="8.5" data-path="distributions.html"><a href="distributions.html#histogramas"><i class="fa fa-check"></i><b>8.5</b> Histogramas</a></li>
<li class="chapter" data-level="8.6" data-path="distributions.html"><a href="distributions.html#densidad-suave"><i class="fa fa-check"></i><b>8.6</b> Densidad suave</a><ul>
<li class="chapter" data-level="8.6.1" data-path="distributions.html"><a href="distributions.html#cómo-interpretar-el-eje-y"><i class="fa fa-check"></i><b>8.6.1</b> Cómo interpretar el eje-y</a></li>
<li class="chapter" data-level="8.6.2" data-path="distributions.html"><a href="distributions.html#densidades-permiten-estratificación"><i class="fa fa-check"></i><b>8.6.2</b> Densidades permiten estratificación</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="distributions.html"><a href="distributions.html#ejercicios-16"><i class="fa fa-check"></i><b>8.7</b> Ejercicios</a></li>
<li class="chapter" data-level="8.8" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>8.8</b> La distribución normal</a></li>
<li class="chapter" data-level="8.9" data-path="distributions.html"><a href="distributions.html#unidades-estándar"><i class="fa fa-check"></i><b>8.9</b> Unidades estándar</a></li>
<li class="chapter" data-level="8.10" data-path="distributions.html"><a href="distributions.html#gráficos-q-q"><i class="fa fa-check"></i><b>8.10</b> Gráficos Q-Q</a></li>
<li class="chapter" data-level="8.11" data-path="distributions.html"><a href="distributions.html#percentiles"><i class="fa fa-check"></i><b>8.11</b> Percentiles</a></li>
<li class="chapter" data-level="8.12" data-path="distributions.html"><a href="distributions.html#diagramas-de-caja"><i class="fa fa-check"></i><b>8.12</b> Diagramas de caja</a></li>
<li class="chapter" data-level="8.13" data-path="distributions.html"><a href="distributions.html#stratification"><i class="fa fa-check"></i><b>8.13</b> Estratificación</a></li>
<li class="chapter" data-level="8.14" data-path="distributions.html"><a href="distributions.html#student-height-cont"><i class="fa fa-check"></i><b>8.14</b> Estudio de caso: descripción de alturas de estudiantes (continuación)</a></li>
<li class="chapter" data-level="8.15" data-path="distributions.html"><a href="distributions.html#ejercicios-17"><i class="fa fa-check"></i><b>8.15</b> Ejercicios</a></li>
<li class="chapter" data-level="8.16" data-path="distributions.html"><a href="distributions.html#other-geometries"><i class="fa fa-check"></i><b>8.16</b> Geometrías ggplot2</a><ul>
<li class="chapter" data-level="8.16.1" data-path="distributions.html"><a href="distributions.html#diagramas-de-barras"><i class="fa fa-check"></i><b>8.16.1</b> Diagramas de barras</a></li>
<li class="chapter" data-level="8.16.2" data-path="distributions.html"><a href="distributions.html#histogramas-1"><i class="fa fa-check"></i><b>8.16.2</b> Histogramas</a></li>
<li class="chapter" data-level="8.16.3" data-path="distributions.html"><a href="distributions.html#gráficos-de-densidad"><i class="fa fa-check"></i><b>8.16.3</b> Gráficos de densidad</a></li>
<li class="chapter" data-level="8.16.4" data-path="distributions.html"><a href="distributions.html#diagramas-de-caja-1"><i class="fa fa-check"></i><b>8.16.4</b> Diagramas de caja</a></li>
<li class="chapter" data-level="8.16.5" data-path="distributions.html"><a href="distributions.html#gráficos-q-q-1"><i class="fa fa-check"></i><b>8.16.5</b> Gráficos Q-Q</a></li>
<li class="chapter" data-level="8.16.6" data-path="distributions.html"><a href="distributions.html#imágenes"><i class="fa fa-check"></i><b>8.16.6</b> Imágenes</a></li>
<li class="chapter" data-level="8.16.7" data-path="distributions.html"><a href="distributions.html#gráficos-rápidos"><i class="fa fa-check"></i><b>8.16.7</b> Gráficos rápidos</a></li>
</ul></li>
<li class="chapter" data-level="8.17" data-path="distributions.html"><a href="distributions.html#ejercicios-18"><i class="fa fa-check"></i><b>8.17</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>9</b> Visualización de datos en la práctica</a><ul>
<li class="chapter" data-level="9.1" data-path="gapminder.html"><a href="gapminder.html#estudio-de-caso-nuevas-ideas-sobre-la-pobreza"><i class="fa fa-check"></i><b>9.1</b> Estudio de caso: nuevas ideas sobre la pobreza</a><ul>
<li class="chapter" data-level="9.1.1" data-path="gapminder.html"><a href="gapminder.html#la-prueba-de-hans-rosling"><i class="fa fa-check"></i><b>9.1.1</b> La prueba de Hans Rosling</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="gapminder.html"><a href="gapminder.html#diagrama-de-dispersión"><i class="fa fa-check"></i><b>9.2</b> Diagrama de dispersión</a></li>
<li class="chapter" data-level="9.3" data-path="gapminder.html"><a href="gapminder.html#separar-en-facetas"><i class="fa fa-check"></i><b>9.3</b> Separar en facetas</a><ul>
<li class="chapter" data-level="9.3.1" data-path="gapminder.html"><a href="gapminder.html#facet_wrap"><i class="fa fa-check"></i><b>9.3.1</b> <code>facet_wrap</code></a></li>
<li class="chapter" data-level="9.3.2" data-path="gapminder.html"><a href="gapminder.html#escalas-fijas-para-mejores-comparaciones"><i class="fa fa-check"></i><b>9.3.2</b> Escalas fijas para mejores comparaciones</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="gapminder.html"><a href="gapminder.html#gráficos-de-series-de-tiempo"><i class="fa fa-check"></i><b>9.4</b> Gráficos de series de tiempo</a><ul>
<li class="chapter" data-level="9.4.1" data-path="gapminder.html"><a href="gapminder.html#etiquetas-en-lugar-de-leyendas"><i class="fa fa-check"></i><b>9.4.1</b> Etiquetas en lugar de leyendas</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="gapminder.html"><a href="gapminder.html#transformaciones-de-datos"><i class="fa fa-check"></i><b>9.5</b> Transformaciones de datos</a><ul>
<li class="chapter" data-level="9.5.1" data-path="gapminder.html"><a href="gapminder.html#transformación-logarítmica"><i class="fa fa-check"></i><b>9.5.1</b> Transformación logarítmica</a></li>
<li class="chapter" data-level="9.5.2" data-path="gapminder.html"><a href="gapminder.html#qué-base"><i class="fa fa-check"></i><b>9.5.2</b> ¿Qué base?</a></li>
<li class="chapter" data-level="9.5.3" data-path="gapminder.html"><a href="gapminder.html#transformar-los-valores-o-la-escala"><i class="fa fa-check"></i><b>9.5.3</b> ¿Transformar los valores o la escala?</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="gapminder.html"><a href="gapminder.html#cómo-visualizar-distribuciones-multimodales"><i class="fa fa-check"></i><b>9.6</b> Cómo visualizar distribuciones multimodales</a></li>
<li class="chapter" data-level="9.7" data-path="gapminder.html"><a href="gapminder.html#cómo-comparar-múltiples-distribuciones-con-diagramas-de-caja-y-gráficos-ridge"><i class="fa fa-check"></i><b>9.7</b> Cómo comparar múltiples distribuciones con diagramas de caja y gráficos <em>ridge</em></a><ul>
<li class="chapter" data-level="9.7.1" data-path="gapminder.html"><a href="gapminder.html#diagrama-de-caja"><i class="fa fa-check"></i><b>9.7.1</b> Diagrama de caja</a></li>
<li class="chapter" data-level="9.7.2" data-path="gapminder.html"><a href="gapminder.html#gráficos-ridge"><i class="fa fa-check"></i><b>9.7.2</b> Gráficos <em>ridge</em></a></li>
<li class="chapter" data-level="9.7.3" data-path="gapminder.html"><a href="gapminder.html#ejemplo-distribuciones-de-ingresos-de-1970-versus-2010"><i class="fa fa-check"></i><b>9.7.3</b> Ejemplo: distribuciones de ingresos de 1970 versus 2010</a></li>
<li class="chapter" data-level="9.7.4" data-path="gapminder.html"><a href="gapminder.html#cómo-obtener-acceso-a-variables-calculadas"><i class="fa fa-check"></i><b>9.7.4</b> Cómo obtener acceso a variables calculadas</a></li>
<li class="chapter" data-level="9.7.5" data-path="gapminder.html"><a href="gapminder.html#densidades-ponderadas"><i class="fa fa-check"></i><b>9.7.5</b> Densidades ponderadas</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="gapminder.html"><a href="gapminder.html#la-falacia-ecológica-y-la-importancia-de-mostrar-los-datos"><i class="fa fa-check"></i><b>9.8</b> La falacia ecológica y la importancia de mostrar los datos</a><ul>
<li class="chapter" data-level="9.8.1" data-path="gapminder.html"><a href="gapminder.html#logit"><i class="fa fa-check"></i><b>9.8.1</b> Transformación logística</a></li>
<li class="chapter" data-level="9.8.2" data-path="gapminder.html"><a href="gapminder.html#mostrar-los-datos"><i class="fa fa-check"></i><b>9.8.2</b> Mostrar los datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html"><i class="fa fa-check"></i><b>10</b> Principios de visualización de datos</a><ul>
<li class="chapter" data-level="10.1" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#cómo-codificar-datos-utilizando-señales-visuales"><i class="fa fa-check"></i><b>10.1</b> Cómo codificar datos utilizando señales visuales</a></li>
<li class="chapter" data-level="10.2" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#sepa-cuándo-incluir-0"><i class="fa fa-check"></i><b>10.2</b> Sepa cuándo incluir 0</a></li>
<li class="chapter" data-level="10.3" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#no-distorsionar-cantidades"><i class="fa fa-check"></i><b>10.3</b> No distorsionar cantidades</a></li>
<li class="chapter" data-level="10.4" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#ordenar-categorías-por-un-valor-significativo"><i class="fa fa-check"></i><b>10.4</b> Ordenar categorías por un valor significativo</a></li>
<li class="chapter" data-level="10.5" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#mostrar-los-datos-1"><i class="fa fa-check"></i><b>10.5</b> Mostrar los datos</a></li>
<li class="chapter" data-level="10.6" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#cómo-facilitar-comparaciones"><i class="fa fa-check"></i><b>10.6</b> Cómo facilitar comparaciones</a><ul>
<li class="chapter" data-level="10.6.1" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#use-ejes-comunes"><i class="fa fa-check"></i><b>10.6.1</b> Use ejes comunes</a></li>
<li class="chapter" data-level="10.6.2" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#alinee-gráficos-verticalmente-para-ver-cambios-horizontales-y-horizontalmente-para-ver-cambios-verticales"><i class="fa fa-check"></i><b>10.6.2</b> Alinee gráficos verticalmente para ver cambios horizontales y horizontalmente para ver cambios verticales</a></li>
<li class="chapter" data-level="10.6.3" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#considere-transformaciones"><i class="fa fa-check"></i><b>10.6.3</b> Considere transformaciones</a></li>
<li class="chapter" data-level="10.6.4" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#señales-visuales-comparadas-deben-estar-adyacentes"><i class="fa fa-check"></i><b>10.6.4</b> Señales visuales comparadas deben estar adyacentes</a></li>
<li class="chapter" data-level="10.6.5" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#use-color"><i class="fa fa-check"></i><b>10.6.5</b> Use color</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#piense-en-los-daltónicos"><i class="fa fa-check"></i><b>10.7</b> Piense en los daltónicos</a></li>
<li class="chapter" data-level="10.8" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#gráficos-para-dos-variables"><i class="fa fa-check"></i><b>10.8</b> Gráficos para dos variables</a><ul>
<li class="chapter" data-level="10.8.1" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#slope-charts"><i class="fa fa-check"></i><b>10.8.1</b> Slope charts</a></li>
<li class="chapter" data-level="10.8.2" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#gráfico-bland-altman"><i class="fa fa-check"></i><b>10.8.2</b> Gráfico Bland-Altman</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#cómo-codificar-una-tercera-variable"><i class="fa fa-check"></i><b>10.9</b> Cómo codificar una tercera variable</a></li>
<li class="chapter" data-level="10.10" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#evite-los-gráficos-pseudo-tridimensionales"><i class="fa fa-check"></i><b>10.10</b> Evite los gráficos pseudo-tridimensionales</a></li>
<li class="chapter" data-level="10.11" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#evite-demasiados-dígitos-significativos"><i class="fa fa-check"></i><b>10.11</b> Evite demasiados dígitos significativos</a></li>
<li class="chapter" data-level="10.12" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#conozca-a-su-audiencia"><i class="fa fa-check"></i><b>10.12</b> Conozca a su audiencia</a></li>
<li class="chapter" data-level="10.13" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#ejercicios-19"><i class="fa fa-check"></i><b>10.13</b> Ejercicios</a></li>
<li class="chapter" data-level="10.14" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#vaccines"><i class="fa fa-check"></i><b>10.14</b> Estudio de caso: las vacunas y las enfermedades infecciosas</a></li>
<li class="chapter" data-level="10.15" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#ejercicios-20"><i class="fa fa-check"></i><b>10.15</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="robust-summaries.html"><a href="robust-summaries.html"><i class="fa fa-check"></i><b>11</b> Resúmenes robustos</a><ul>
<li class="chapter" data-level="11.1" data-path="robust-summaries.html"><a href="robust-summaries.html#valores-atípicos"><i class="fa fa-check"></i><b>11.1</b> Valores atípicos</a></li>
<li class="chapter" data-level="11.2" data-path="robust-summaries.html"><a href="robust-summaries.html#mediana"><i class="fa fa-check"></i><b>11.2</b> Mediana</a></li>
<li class="chapter" data-level="11.3" data-path="robust-summaries.html"><a href="robust-summaries.html#el-rango-intercuartil-iqr"><i class="fa fa-check"></i><b>11.3</b> El rango intercuartil (IQR)</a></li>
<li class="chapter" data-level="11.4" data-path="robust-summaries.html"><a href="robust-summaries.html#la-definición-de-tukey-de-un-valor-atípico"><i class="fa fa-check"></i><b>11.4</b> La definición de Tukey de un valor atípico</a></li>
<li class="chapter" data-level="11.5" data-path="robust-summaries.html"><a href="robust-summaries.html#desviación-absoluta-mediana"><i class="fa fa-check"></i><b>11.5</b> Desviación absoluta mediana</a></li>
<li class="chapter" data-level="11.6" data-path="robust-summaries.html"><a href="robust-summaries.html#ejercicios-21"><i class="fa fa-check"></i><b>11.6</b> Ejercicios</a></li>
<li class="chapter" data-level="11.7" data-path="robust-summaries.html"><a href="robust-summaries.html#estudio-de-caso-alturas-autoreportadas-de-estudiantes"><i class="fa fa-check"></i><b>11.7</b> Estudio de caso: alturas autoreportadas de estudiantes</a></li>
</ul></li>
<li class="part"><span><b>III Estadísticas con R</b></span></li>
<li class="chapter" data-level="12" data-path="introducción-a-las-estadísticas-con-r.html"><a href="introducción-a-las-estadísticas-con-r.html"><i class="fa fa-check"></i><b>12</b> Introducción a las estadísticas con R</a></li>
<li class="chapter" data-level="13" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>13</b> Probabilidad</a><ul>
<li class="chapter" data-level="13.1" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-discreta"><i class="fa fa-check"></i><b>13.1</b> Probabilidad discreta</a><ul>
<li class="chapter" data-level="13.1.1" data-path="probabilidad.html"><a href="probabilidad.html#frecuencia-relativa"><i class="fa fa-check"></i><b>13.1.1</b> Frecuencia relativa</a></li>
<li class="chapter" data-level="13.1.2" data-path="probabilidad.html"><a href="probabilidad.html#notación"><i class="fa fa-check"></i><b>13.1.2</b> Notación</a></li>
<li class="chapter" data-level="13.1.3" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>13.1.3</b> Distribuciones de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="probabilidad.html"><a href="probabilidad.html#simulaciones-monte-carlo-para-datos-categóricos"><i class="fa fa-check"></i><b>13.2</b> Simulaciones Monte Carlo para datos categóricos</a><ul>
<li class="chapter" data-level="13.2.1" data-path="probabilidad.html"><a href="probabilidad.html#fijar-la-semilla-aleatoria"><i class="fa fa-check"></i><b>13.2.1</b> Fijar la semilla aleatoria</a></li>
<li class="chapter" data-level="13.2.2" data-path="probabilidad.html"><a href="probabilidad.html#con-y-sin-reemplazo"><i class="fa fa-check"></i><b>13.2.2</b> Con y sin reemplazo</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="probabilidad.html"><a href="probabilidad.html#independencia"><i class="fa fa-check"></i><b>13.3</b> Independencia</a></li>
<li class="chapter" data-level="13.4" data-path="probabilidad.html"><a href="probabilidad.html#probabilidades-condicionales"><i class="fa fa-check"></i><b>13.4</b> Probabilidades condicionales</a></li>
<li class="chapter" data-level="13.5" data-path="probabilidad.html"><a href="probabilidad.html#reglas-de-la-adición-y-de-la-multiplicación"><i class="fa fa-check"></i><b>13.5</b> Reglas de la adición y de la multiplicación</a><ul>
<li class="chapter" data-level="13.5.1" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-multiplicación"><i class="fa fa-check"></i><b>13.5.1</b> Regla de la multiplicación</a></li>
<li class="chapter" data-level="13.5.2" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-multiplicación-bajo-independencia"><i class="fa fa-check"></i><b>13.5.2</b> Regla de la multiplicación bajo independencia</a></li>
<li class="chapter" data-level="13.5.3" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-adición"><i class="fa fa-check"></i><b>13.5.3</b> Regla de la adición</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="probabilidad.html"><a href="probabilidad.html#combinaciones-y-permutaciones"><i class="fa fa-check"></i><b>13.6</b> Combinaciones y permutaciones</a><ul>
<li class="chapter" data-level="13.6.1" data-path="probabilidad.html"><a href="probabilidad.html#ejemplo-monte-carlo"><i class="fa fa-check"></i><b>13.6.1</b> Ejemplo Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="probabilidad.html"><a href="probabilidad.html#ejemplos"><i class="fa fa-check"></i><b>13.7</b> Ejemplos</a><ul>
<li class="chapter" data-level="13.7.1" data-path="probabilidad.html"><a href="probabilidad.html#problema-monty-hall"><i class="fa fa-check"></i><b>13.7.1</b> Problema Monty Hall</a></li>
<li class="chapter" data-level="13.7.2" data-path="probabilidad.html"><a href="probabilidad.html#problema-de-cumpleaños"><i class="fa fa-check"></i><b>13.7.2</b> Problema de cumpleaños</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="probabilidad.html"><a href="probabilidad.html#infinito-en-la-práctica"><i class="fa fa-check"></i><b>13.8</b> Infinito en la práctica</a></li>
<li class="chapter" data-level="13.9" data-path="probabilidad.html"><a href="probabilidad.html#ejercicios-22"><i class="fa fa-check"></i><b>13.9</b> Ejercicios</a></li>
<li class="chapter" data-level="13.10" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-continua"><i class="fa fa-check"></i><b>13.10</b> Probabilidad continua</a></li>
<li class="chapter" data-level="13.11" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-teóricas-continuas"><i class="fa fa-check"></i><b>13.11</b> Distribuciones teóricas continuas</a><ul>
<li class="chapter" data-level="13.11.1" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-teóricas-como-aproximaciones"><i class="fa fa-check"></i><b>13.11.1</b> Distribuciones teóricas como aproximaciones</a></li>
<li class="chapter" data-level="13.11.2" data-path="probabilidad.html"><a href="probabilidad.html#la-densidad-de-probabilidad"><i class="fa fa-check"></i><b>13.11.2</b> La densidad de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="13.12" data-path="probabilidad.html"><a href="probabilidad.html#simulaciones-monte-carlo-para-variables-continuas"><i class="fa fa-check"></i><b>13.12</b> Simulaciones Monte Carlo para variables continuas</a></li>
<li class="chapter" data-level="13.13" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-continuas"><i class="fa fa-check"></i><b>13.13</b> Distribuciones continuas</a></li>
<li class="chapter" data-level="13.14" data-path="probabilidad.html"><a href="probabilidad.html#ejercicios-23"><i class="fa fa-check"></i><b>13.14</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>14</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="14.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-1"><i class="fa fa-check"></i><b>14.1</b> Variables aleatorias</a></li>
<li class="chapter" data-level="14.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#modelos-de-muestreo"><i class="fa fa-check"></i><b>14.2</b> Modelos de muestreo</a></li>
<li class="chapter" data-level="14.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#la-distribución-de-probabilidad-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>14.3</b> La distribución de probabilidad de una variable aleatoria</a></li>
<li class="chapter" data-level="14.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#distribuciones-versus-distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>14.4</b> Distribuciones versus distribuciones de probabilidad</a></li>
<li class="chapter" data-level="14.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#notación-para-variables-aleatorias"><i class="fa fa-check"></i><b>14.5</b> Notación para variables aleatorias</a></li>
<li class="chapter" data-level="14.6" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#el-valor-esperado-y-el-error-estándar"><i class="fa fa-check"></i><b>14.6</b> El valor esperado y el error estándar</a><ul>
<li class="chapter" data-level="14.6.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#población-sd-versus-la-muestra-sd"><i class="fa fa-check"></i><b>14.6.1</b> Población SD versus la muestra SD</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#teorema-del-límite-central"><i class="fa fa-check"></i><b>14.7</b> Teorema del límite central</a><ul>
<li class="chapter" data-level="14.7.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#cuán-grande-es-grande-en-el-teorema-del-límite-central"><i class="fa fa-check"></i><b>14.7.1</b> ¿Cuán grande es grande en el teorema del límite central?</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#propiedades-estadísticas-de-promedios"><i class="fa fa-check"></i><b>14.8</b> Propiedades estadísticas de promedios</a></li>
<li class="chapter" data-level="14.9" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#ley-de-los-grandes-números"><i class="fa fa-check"></i><b>14.9</b> Ley de los grandes números</a><ul>
<li class="chapter" data-level="14.9.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#malinterpretando-la-ley-de-promedios"><i class="fa fa-check"></i><b>14.9.1</b> Malinterpretando la ley de promedios</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#ejercicios-24"><i class="fa fa-check"></i><b>14.10</b> Ejercicios</a></li>
<li class="chapter" data-level="14.11" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#estudio-de-caso-the-big-short"><i class="fa fa-check"></i><b>14.11</b> Estudio de caso: The Big Short</a><ul>
<li class="chapter" data-level="14.11.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#tasas-de-interés-explicadas-con-modelo-de-oportunidad"><i class="fa fa-check"></i><b>14.11.1</b> Tasas de interés explicadas con modelo de oportunidad</a></li>
<li class="chapter" data-level="14.11.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#the-big-short"><i class="fa fa-check"></i><b>14.11.2</b> The Big Short</a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#ejercicios-25"><i class="fa fa-check"></i><b>14.12</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>15</b> Inferencia estadística</a><ul>
<li class="chapter" data-level="15.1" data-path="inference.html"><a href="inference.html#encuestas"><i class="fa fa-check"></i><b>15.1</b> Encuestas</a><ul>
<li class="chapter" data-level="15.1.1" data-path="inference.html"><a href="inference.html#el-modelo-de-muestreo-para-encuestas"><i class="fa fa-check"></i><b>15.1.1</b> El modelo de muestreo para encuestas</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="inference.html"><a href="inference.html#poblaciones-muestras-parámetros-y-estimaciones"><i class="fa fa-check"></i><b>15.2</b> Poblaciones, muestras, parámetros y estimaciones</a><ul>
<li class="chapter" data-level="15.2.1" data-path="inference.html"><a href="inference.html#el-promedio-de-la-muestra"><i class="fa fa-check"></i><b>15.2.1</b> El promedio de la muestra</a></li>
<li class="chapter" data-level="15.2.2" data-path="inference.html"><a href="inference.html#parámetros"><i class="fa fa-check"></i><b>15.2.2</b> Parámetros</a></li>
<li class="chapter" data-level="15.2.3" data-path="inference.html"><a href="inference.html#encuesta-versus-pronóstico"><i class="fa fa-check"></i><b>15.2.3</b> Encuesta versus pronóstico</a></li>
<li class="chapter" data-level="15.2.4" data-path="inference.html"><a href="inference.html#propiedades-de-nuestra-estimación-valor-esperado-y-error-estándar"><i class="fa fa-check"></i><b>15.2.4</b> Propiedades de nuestra estimación: valor esperado y error estándar</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="inference.html"><a href="inference.html#ejercicios-26"><i class="fa fa-check"></i><b>15.3</b> Ejercicios</a></li>
<li class="chapter" data-level="15.4" data-path="inference.html"><a href="inference.html#clt"><i class="fa fa-check"></i><b>15.4</b> Teorema del límite central en la práctica</a><ul>
<li class="chapter" data-level="15.4.1" data-path="inference.html"><a href="inference.html#una-simulación-monte-carlo"><i class="fa fa-check"></i><b>15.4.1</b> Una simulación Monte Carlo</a></li>
<li class="chapter" data-level="15.4.2" data-path="inference.html"><a href="inference.html#la-diferencia"><i class="fa fa-check"></i><b>15.4.2</b> La diferencia</a></li>
<li class="chapter" data-level="15.4.3" data-path="inference.html"><a href="inference.html#sesgo-por-qué-no-realizar-una-encuesta-bien-grande"><i class="fa fa-check"></i><b>15.4.3</b> Sesgo: ¿por qué no realizar una encuesta bien grande?</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="inference.html"><a href="inference.html#ejercicios-27"><i class="fa fa-check"></i><b>15.5</b> Ejercicios</a></li>
<li class="chapter" data-level="15.6" data-path="inference.html"><a href="inference.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>15.6</b> Intervalos de confianza</a><ul>
<li class="chapter" data-level="15.6.1" data-path="inference.html"><a href="inference.html#una-simulación-monte-carlo-1"><i class="fa fa-check"></i><b>15.6.1</b> Una simulación Monte Carlo</a></li>
<li class="chapter" data-level="15.6.2" data-path="inference.html"><a href="inference.html#el-idioma-correcto"><i class="fa fa-check"></i><b>15.6.2</b> El idioma correcto</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="inference.html"><a href="inference.html#ejercicios-28"><i class="fa fa-check"></i><b>15.7</b> Ejercicios</a></li>
<li class="chapter" data-level="15.8" data-path="inference.html"><a href="inference.html#poder"><i class="fa fa-check"></i><b>15.8</b> Poder</a></li>
<li class="chapter" data-level="15.9" data-path="inference.html"><a href="inference.html#valores-p"><i class="fa fa-check"></i><b>15.9</b> valores p</a></li>
<li class="chapter" data-level="15.10" data-path="inference.html"><a href="inference.html#association-tests"><i class="fa fa-check"></i><b>15.10</b> Pruebas de asociación</a><ul>
<li class="chapter" data-level="15.10.1" data-path="inference.html"><a href="inference.html#lady-tasting-tea"><i class="fa fa-check"></i><b>15.10.1</b> Lady Tasting Tea</a></li>
<li class="chapter" data-level="15.10.2" data-path="inference.html"><a href="inference.html#tablas-2x2"><i class="fa fa-check"></i><b>15.10.2</b> Tablas 2x2</a></li>
<li class="chapter" data-level="15.10.3" data-path="inference.html"><a href="inference.html#prueba-de-chi-cuadrado"><i class="fa fa-check"></i><b>15.10.3</b> Prueba de chi-cuadrado</a></li>
<li class="chapter" data-level="15.10.4" data-path="inference.html"><a href="inference.html#odds-ratio"><i class="fa fa-check"></i><b>15.10.4</b> Riesgo relativo</a></li>
<li class="chapter" data-level="15.10.5" data-path="inference.html"><a href="inference.html#intervalos-de-confianza-para-el-riesgo-relativo"><i class="fa fa-check"></i><b>15.10.5</b> Intervalos de confianza para el riesgo relativo</a></li>
<li class="chapter" data-level="15.10.6" data-path="inference.html"><a href="inference.html#corrección-de-recuento-pequeño"><i class="fa fa-check"></i><b>15.10.6</b> Corrección de recuento pequeño</a></li>
<li class="chapter" data-level="15.10.7" data-path="inference.html"><a href="inference.html#muestras-grandes-valores-p-pequeños"><i class="fa fa-check"></i><b>15.10.7</b> Muestras grandes, valores p pequeños</a></li>
</ul></li>
<li class="chapter" data-level="15.11" data-path="inference.html"><a href="inference.html#ejercicios-29"><i class="fa fa-check"></i><b>15.11</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>16</b> Modelos estadísticos</a><ul>
<li class="chapter" data-level="16.1" data-path="models.html"><a href="models.html#agregadores-de-encuestas"><i class="fa fa-check"></i><b>16.1</b> Agregadores de encuestas</a><ul>
<li class="chapter" data-level="16.1.1" data-path="models.html"><a href="models.html#datos-de-encuesta"><i class="fa fa-check"></i><b>16.1.1</b> Datos de encuesta</a></li>
<li class="chapter" data-level="16.1.2" data-path="models.html"><a href="models.html#sesgo-de-los-encuestadores"><i class="fa fa-check"></i><b>16.1.2</b> Sesgo de los encuestadores</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="models.html"><a href="models.html#data-driven-model"><i class="fa fa-check"></i><b>16.2</b> Modelos basados en datos</a></li>
<li class="chapter" data-level="16.3" data-path="models.html"><a href="models.html#ejercicios-30"><i class="fa fa-check"></i><b>16.3</b> Ejercicios</a></li>
<li class="chapter" data-level="16.4" data-path="models.html"><a href="models.html#bayesian-statistics"><i class="fa fa-check"></i><b>16.4</b> Estadísticas bayesianas</a><ul>
<li class="chapter" data-level="16.4.1" data-path="models.html"><a href="models.html#teorema-de-bayes"><i class="fa fa-check"></i><b>16.4.1</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="models.html"><a href="models.html#simulación-del-teorema-de-bayes"><i class="fa fa-check"></i><b>16.5</b> Simulación del teorema de Bayes</a><ul>
<li class="chapter" data-level="16.5.1" data-path="models.html"><a href="models.html#bayes-en-la-práctica"><i class="fa fa-check"></i><b>16.5.1</b> Bayes en la práctica</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="models.html"><a href="models.html#modelos-jerárquicos"><i class="fa fa-check"></i><b>16.6</b> Modelos jerárquicos</a></li>
<li class="chapter" data-level="16.7" data-path="models.html"><a href="models.html#ejercicios-31"><i class="fa fa-check"></i><b>16.7</b> Ejercicios</a></li>
<li class="chapter" data-level="16.8" data-path="models.html"><a href="models.html#election-forecasting"><i class="fa fa-check"></i><b>16.8</b> Estudio de caso: pronóstico de elecciones</a><ul>
<li class="chapter" data-level="16.8.1" data-path="models.html"><a href="models.html#bayesian-approach"><i class="fa fa-check"></i><b>16.8.1</b> Enfoque bayesiano</a></li>
<li class="chapter" data-level="16.8.2" data-path="models.html"><a href="models.html#el-sesgo-general"><i class="fa fa-check"></i><b>16.8.2</b> El sesgo general</a></li>
<li class="chapter" data-level="16.8.3" data-path="models.html"><a href="models.html#representaciones-matemáticas-de-modelos"><i class="fa fa-check"></i><b>16.8.3</b> Representaciones matemáticas de modelos</a></li>
<li class="chapter" data-level="16.8.4" data-path="models.html"><a href="models.html#prediciendo-el-colegio-electoral"><i class="fa fa-check"></i><b>16.8.4</b> Prediciendo el colegio electoral</a></li>
<li class="chapter" data-level="16.8.5" data-path="models.html"><a href="models.html#pronósticos"><i class="fa fa-check"></i><b>16.8.5</b> Pronósticos</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="models.html"><a href="models.html#ejercicios-32"><i class="fa fa-check"></i><b>16.9</b> Ejercicios</a></li>
<li class="chapter" data-level="16.10" data-path="models.html"><a href="models.html#t-dist"><i class="fa fa-check"></i><b>16.10</b> La distribución t</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>17</b> Regresión</a><ul>
<li class="chapter" data-level="17.1" data-path="regression.html"><a href="regression.html#estudio-de-caso-la-altura-es-hereditaria"><i class="fa fa-check"></i><b>17.1</b> Estudio de caso: ¿la altura es hereditaria?</a></li>
<li class="chapter" data-level="17.2" data-path="regression.html"><a href="regression.html#corr-coef"><i class="fa fa-check"></i><b>17.2</b> El coeficiente de correlación</a><ul>
<li class="chapter" data-level="17.2.1" data-path="regression.html"><a href="regression.html#la-correlación-de-muestra-es-una-variable-aleatoria"><i class="fa fa-check"></i><b>17.2.1</b> La correlación de muestra es una variable aleatoria</a></li>
<li class="chapter" data-level="17.2.2" data-path="regression.html"><a href="regression.html#la-correlación-no-siempre-es-un-resumen-útil"><i class="fa fa-check"></i><b>17.2.2</b> La correlación no siempre es un resumen útil</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="regression.html"><a href="regression.html#conditional-expectation"><i class="fa fa-check"></i><b>17.3</b> Valor esperado condicional</a></li>
<li class="chapter" data-level="17.4" data-path="regression.html"><a href="regression.html#la-línea-de-regresión"><i class="fa fa-check"></i><b>17.4</b> La línea de regresión</a><ul>
<li class="chapter" data-level="17.4.1" data-path="regression.html"><a href="regression.html#regresión-mejora-precisión"><i class="fa fa-check"></i><b>17.4.1</b> Regresión mejora precisión</a></li>
<li class="chapter" data-level="17.4.2" data-path="regression.html"><a href="regression.html#distribución-normal-de-dos-variables-avanzada"><i class="fa fa-check"></i><b>17.4.2</b> Distribución normal de dos variables (avanzada)</a></li>
<li class="chapter" data-level="17.4.3" data-path="regression.html"><a href="regression.html#varianza-explicada"><i class="fa fa-check"></i><b>17.4.3</b> Varianza explicada</a></li>
<li class="chapter" data-level="17.4.4" data-path="regression.html"><a href="regression.html#advertencia-hay-dos-líneas-de-regresión"><i class="fa fa-check"></i><b>17.4.4</b> Advertencia: hay dos líneas de regresión</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="regression.html"><a href="regression.html#ejercicios-33"><i class="fa fa-check"></i><b>17.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="modelos-lineales.html"><a href="modelos-lineales.html"><i class="fa fa-check"></i><b>18</b> Modelos lineales</a><ul>
<li class="chapter" data-level="18.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#estudio-de-caso-moneyball"><i class="fa fa-check"></i><b>18.1</b> Estudio de caso: Moneyball</a><ul>
<li class="chapter" data-level="18.1.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#sabermetrics"><i class="fa fa-check"></i><b>18.1.1</b> Sabermetrics</a></li>
<li class="chapter" data-level="18.1.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#conceptos-básicos-de-béisbol"><i class="fa fa-check"></i><b>18.1.2</b> Conceptos básicos de béisbol</a></li>
<li class="chapter" data-level="18.1.3" data-path="modelos-lineales.html"><a href="modelos-lineales.html#no-hay-premios-para-bb"><i class="fa fa-check"></i><b>18.1.3</b> No hay premios para BB</a></li>
<li class="chapter" data-level="18.1.4" data-path="modelos-lineales.html"><a href="modelos-lineales.html#base-por-bolas-o-bases-robadas"><i class="fa fa-check"></i><b>18.1.4</b> ¿Base por bolas o bases robadas?</a></li>
<li class="chapter" data-level="18.1.5" data-path="modelos-lineales.html"><a href="modelos-lineales.html#regresión-aplicada-a-las-estadísticas-de-béisbol"><i class="fa fa-check"></i><b>18.1.5</b> Regresión aplicada a las estadísticas de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#confusión"><i class="fa fa-check"></i><b>18.2</b> Confusión</a><ul>
<li class="chapter" data-level="18.2.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#entender-confusión-a-través-de-estratificación"><i class="fa fa-check"></i><b>18.2.1</b> Entender confusión a través de estratificación</a></li>
<li class="chapter" data-level="18.2.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#regresión-lineal-múltiple"><i class="fa fa-check"></i><b>18.2.2</b> Regresión lineal múltiple</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="modelos-lineales.html"><a href="modelos-lineales.html#lse"><i class="fa fa-check"></i><b>18.3</b> Estimaciones de mínimos cuadrados</a><ul>
<li class="chapter" data-level="18.3.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#interpretando-modelos-lineales"><i class="fa fa-check"></i><b>18.3.1</b> Interpretando modelos lineales</a></li>
<li class="chapter" data-level="18.3.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#estimaciones-de-mínimos-cuadrados-lse"><i class="fa fa-check"></i><b>18.3.2</b> Estimaciones de mínimos cuadrados (LSE)</a></li>
<li class="chapter" data-level="18.3.3" data-path="modelos-lineales.html"><a href="modelos-lineales.html#la-función-lm"><i class="fa fa-check"></i><b>18.3.3</b> La función <code>lm</code></a></li>
<li class="chapter" data-level="18.3.4" data-path="modelos-lineales.html"><a href="modelos-lineales.html#lse-son-variables-aleatorias"><i class="fa fa-check"></i><b>18.3.4</b> LSE son variables aleatorias</a></li>
<li class="chapter" data-level="18.3.5" data-path="modelos-lineales.html"><a href="modelos-lineales.html#valores-pronosticados-son-variables-aleatorias"><i class="fa fa-check"></i><b>18.3.5</b> Valores pronosticados son variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="modelos-lineales.html"><a href="modelos-lineales.html#ejercicios-34"><i class="fa fa-check"></i><b>18.4</b> Ejercicios</a></li>
<li class="chapter" data-level="18.5" data-path="modelos-lineales.html"><a href="modelos-lineales.html#regresión-lineal-en-el-tidyverse"><i class="fa fa-check"></i><b>18.5</b> Regresión lineal en el tidyverse</a><ul>
<li class="chapter" data-level="18.5.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#el-paquete-broom"><i class="fa fa-check"></i><b>18.5.1</b> El paquete broom</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="modelos-lineales.html"><a href="modelos-lineales.html#ejercicios-35"><i class="fa fa-check"></i><b>18.6</b> Ejercicios</a></li>
<li class="chapter" data-level="18.7" data-path="modelos-lineales.html"><a href="modelos-lineales.html#estudio-de-caso-moneyball-continuación"><i class="fa fa-check"></i><b>18.7</b> Estudio de caso: Moneyball (continuación)</a><ul>
<li class="chapter" data-level="18.7.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#añadiendo-información-sobre-salario-y-posición"><i class="fa fa-check"></i><b>18.7.1</b> Añadiendo información sobre salario y posición</a></li>
<li class="chapter" data-level="18.7.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#escoger-nueve-jugadores"><i class="fa fa-check"></i><b>18.7.2</b> Escoger nueve jugadores</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="modelos-lineales.html"><a href="modelos-lineales.html#la-falacia-de-la-regresión"><i class="fa fa-check"></i><b>18.8</b> La falacia de la regresión</a></li>
<li class="chapter" data-level="18.9" data-path="modelos-lineales.html"><a href="modelos-lineales.html#modelos-de-error-de-medición"><i class="fa fa-check"></i><b>18.9</b> Modelos de error de medición</a></li>
<li class="chapter" data-level="18.10" data-path="modelos-lineales.html"><a href="modelos-lineales.html#ejercicios-36"><i class="fa fa-check"></i><b>18.10</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html"><i class="fa fa-check"></i><b>19</b> La asociación no implica causalidad</a><ul>
<li class="chapter" data-level="19.1" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#correlación-espuria"><i class="fa fa-check"></i><b>19.1</b> Correlación espuria</a></li>
<li class="chapter" data-level="19.2" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#valores-atípicos-1"><i class="fa fa-check"></i><b>19.2</b> Valores atípicos</a></li>
<li class="chapter" data-level="19.3" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#fix-inversión-de-causa-y-efecto"><i class="fa fa-check"></i><b>19.3</b> [fix] Inversión de causa y efecto</a></li>
<li class="chapter" data-level="19.4" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#factores-de-confusión"><i class="fa fa-check"></i><b>19.4</b> Factores de confusión</a><ul>
<li class="chapter" data-level="19.4.1" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#ejemplo-admisiones-a-la-universidad-de-california-berkeley"><i class="fa fa-check"></i><b>19.4.1</b> Ejemplo: admisiones a la Universidad de California, Berkeley</a></li>
<li class="chapter" data-level="19.4.2" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#confusión-explicada-gráficamente"><i class="fa fa-check"></i><b>19.4.2</b> Confusión explicada gráficamente</a></li>
<li class="chapter" data-level="19.4.3" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#promedio-después-de-estratificar"><i class="fa fa-check"></i><b>19.4.3</b> Promedio después de estratificar</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#la-paradoja-de-simpson"><i class="fa fa-check"></i><b>19.5</b> La paradoja de Simpson</a></li>
<li class="chapter" data-level="19.6" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#ejercicios-37"><i class="fa fa-check"></i><b>19.6</b> Ejercicios</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción a la Ciencia de Datos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-lineales" class="section level1">
<h1><span class="header-section-number">Capítulo 18</span> Modelos lineales</h1>
<p>Desde el desarrollo original de Galton, la regresión se ha convertido en una de las herramientas más utilizadas en la ciencia de datos. Una razón por esto es que la regresión nos permite encontrar relaciones entre dos variables tomando en cuenta los efectos de otras variables que afectan a ambas. Esto ha sido particularmente popular en campos donde los experimentos aleatorios son difíciles de ejecutar, como la economía y la epidemiología.</p>
<p>Cuando no podemos asignar aleatoriamente a cada individuo a un grupo de tratamiento o control, la confusión (<em>confounding</em> en inglés) es particularmente frecuente. Por ejemplo, consideren estimar el efecto de comer comidas rápidas en la esperanza de vida utilizando datos recopilados de una muestra aleatoria de personas en una jurisdicción. Es más probable que los consumidores de comida rápida sean fumadores, bebedores y tengan ingresos más bajos. Por lo tanto, un modelo de regresión simple puede sobrestimar el efecto negativo de la comida rápida en la salud. Entonces, ¿cómo explicamos la confusión en la práctica? En este capítulo aprendemos cómo los modelos lineales pueden ayudar con estas situaciones y cómo pueden usarse para describir cómo una o más variables afectan el resultado.</p>
<div id="estudio-de-caso-moneyball" class="section level2">
<h2><span class="header-section-number">18.1</span> Estudio de caso: Moneyball</h2>
<p>El libro <em>Moneyball: El arte de ganar un juego injusto</em> de Michael Lewis se trata del equipo de béisbol los Atléticos de Oakland, también conocidos como los A’s, y su gerente general, la persona encargada de construir el equipo, Billy Beane.</p>
<p>Tradicionalmente, los equipos de béisbol usan <em>scouts</em>, o buscadores de talento, para ayudarlos a decidir qué jugadores contratar. Estos <em>scouts</em> evalúan a los jugadores viéndolos jugar. Por esta razón, tienden a favorecer a los jugadores atléticos con habilidades físicas observables y, por lo general, hay consenso entre los <em>scouts</em> sobre quiénes son los mejores jugadores. Como consecuencia, hay mucha demanda para estos jugadores lo cual aumenta sus salarios.</p>
<p>De 1989 a 1991, los A’s tuvieron una de las nóminas más altas del béisbol. Pudieron comprar los mejores jugadores y, durante ese tiempo, fueron uno de los mejores equipos. Sin embargo, en 1995 el dueño del equipo cambió y la nueva administración recortó drásticamente el presupuesto, dejando al entonces gerente general, Sandy Alderson, con una de las nóminas más bajas en el béisbol. Éste ya no podía permitirse el lujo de los jugadores más codiciados y, por lo tanto, comenzó a utilizar un enfoque estadístico para encontrar ineficiencias en el mercado. Alderson fue mentor de Billy Beane, quien lo sucedió en 1998 y aceptó por completo la ciencia de los datos, en vez de los <em>scouts</em>, como un método para encontrar jugadores de bajo costo que, según los datos, ayudarían al equipo a ganar. Hoy, esta estrategia ha sido adaptada por la mayoría de los equipos de béisbol. Como veremos, la regresión juega un papel importante en este enfoque.</p>
<p>Como motivación para este capítulo, fingiremos que es 2002 y trataremos de construir un equipo de béisbol con un presupuesto limitado, tal como lo hicieron los Atléticos. Para apreciar la dificultad del reto, tengan en cuenta que en 2002 la nómina de los Yankees de $125,928,583 era más del triple de la de los Atléticos de Oakland de $39,679,746.</p>
<p><img src="libro_files/figure-html/mlb-2002-payroll-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="sabermetrics" class="section level3">
<h3><span class="header-section-number">18.1.1</span> Sabermetrics</h3>
<p>Las estadísticas se han utilizado en el béisbol desde sus inicios. El set de datos que usaremos, que se incluye en la biblioteca <strong>Lahman</strong>, se remonta al siglo XIX. Por ejemplo, un resumen estadístico que describiremos pronto, el <em>promedio de bateo</em> (<em>batting average</em> en inglés), se ha utilizado durante décadas para resumir el éxito de un bateador. Otras estadísticas<a href="#fn66" class="footnote-ref" id="fnref66"><sup>66</sup></a> como cuadrangulares (HR o <em>homeruns</em> en inglés), carreras impulsadas (RBI o <em>runs batted in</em> en inglés) y bases robadas (SB o <em>stolen bases</em> en inglés) se indican para cada jugador en los resúmenes del juego que se incluyen en la sección de deportes de periódicos, con jugadores recompensados por números altos. Aunque resúmenes estadísticos como estos se utilizaron ampliamente en el béisbol, el análisis de datos en sí se ignoraba. Estas estadísticas se escogieron arbitrariamente sin pensar mucho en si realmente predecían algo o si estaban relacionadas con ayudar a un equipo a ganar.</p>
<p>Esto cambió con Bill James<a href="#fn67" class="footnote-ref" id="fnref67"><sup>67</sup></a>. A fines de la década de 1970, este fanático del béisbol y aspirante a escritor comenzó a publicar artículos que describían un análisis más profundo de los datos del béisbol. Denominó <em>sabermetrics</em><a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a> al enfoque de usar datos para pronosticar qué resultados mejor predicen si un equipo ganará. Hasta que Billy Beane convirtió a <em>sabermetrics</em> en el centro de su operación de béisbol, el mundo del béisbol por lo general ignoró el trabajo de Bill James. Actualmente, la popularidad de <em>sabermetrics</em> ya no se limita solo al béisbol; varios otros deportes también han comenzado a usar este enfoque.</p>
<p>En este capítulo, para simplificar el ejercicio, nos enfocaremos en carreras (R o <em>runs</em> en inglés) anotadas e ignoraremos los otros dos aspectos importantes del juego: lanzar y fildear. Veremos cómo el análisis de regresión puede ayudar a desarrollar estrategias para construir un equipo de béisbol competitivo con un presupuesto limitado. El acercamiento se puede dividir en dos análisis de datos separados. En el primero, determinamos qué estadísticas específicas del jugador predicen carreras. En el segundo, examinamos si los jugadores estaban infravalorados según lo que predice nuestro primer análisis.</p>
</div>
<div id="conceptos-básicos-de-béisbol" class="section level3">
<h3><span class="header-section-number">18.1.2</span> Conceptos básicos de béisbol</h3>
<p>Para ver cómo la regresión nos ayudará a encontrar jugadores infravalorados, no necesitamos comprender todos los detalles sobre el juego de béisbol, que tiene más de 100 reglas. Aquí, destilamos el deporte al conocimiento básico que uno necesita saber para atacar efectivamente el problema de la ciencia de datos.</p>
<p>El objetivo de un juego de béisbol es anotar más carreras (puntos) que el otro equipo. Cada equipo tiene 9 bateadores que tienen la oportunidad de darle a una pelota con un bate en un orden predeterminado. Después de que el noveno bateador haya tenido su turno, el primer bateador vuelve a batear, luego el segundo, y así sucesivamente. Cada vez que un bateador tiene la oportunidad de batear, lo llamamos una <em>turno al bate</em> (PA o <em>plate appearance</em> en inglés). En cada PA, el <em>pitcher</em>, o lanzador, del otro equipo lanza la pelota y el bateador intenta darle. El PA termina con un resultado binario: el bateador hace un <em>out</em> (falla) y regresa al banco o el bateador le da a la bola (éxito) y puede correr alrededor de las bases, y potencialmente anotar una carrera (llegar a las 4 bases). Cada equipo tiene nueve intentos, denominados <em>entradas</em> (<em>innings</em> en inglés), para anotar carreras y cada entrada termina después de tres <em>outs</em>.</p>
<p>Aquí pueden ver un video que muestra un éxito: <a href="https://www.youtube.com/watch?v=HL-XjMCPfio">https://www.youtube.com/watch?v=HL-XjMCPfiofont</a>. Y aquí hay uno que muestra una falla: <a href="https://www.youtube.com/watch?v=NeloljCx-1g">https://www.youtube.com/watch?v=NeloljCx-1gfont</a>. En estos videos, vemos cómo la suerte está involucrada en el proceso. Cuando está al bate, el bateador quiere darle a la pelota con fuerza. Si le da lo suficientemente fuerte, es un HR o cuadrangular, el mejor resultado posible ya que el bateador obtiene al menos una carrera automática. Pero a veces, debido al azar, el bateador le da a la pelota muy fuerte y un defensor la atrapa, lo que resulta en un <em>out</em>. Por el contrario, a veces el bateador le da a la pelota suavemente, pero cae justo en el lugar correcto. El hecho de que el azar afecta sugiere por qué los modelos de probabilidad son útiles.</p>
<p>Ahora hay varias formas de tener éxito. Entender esta distinción será importante para nuestro análisis. Cuando el bateador le da a la pelota, él quiere pisar cuantas más bases sea posible. Hay cuatro bases y la cuarta se llama <em>home</em> o <em>home plate</em>. Ahí es donde los bateadores comienzan bateando, por lo que las bases forman un ciclo.</p>
<p><img src="regression/img/Baseball_Diamond1.png" width="50%" style="display: block; margin: auto;" />
(Cortesía de Cburnett<a href="#fn69" class="footnote-ref" id="fnref69"><sup>69</sup></a>. Licencia CC BY-SA 3.0<a href="#fn70" class="footnote-ref" id="fnref70"><sup>70</sup></a>.)
<!--Source: [Wikipedia Commons](https://commons.wikimedia.org/wiki/File:Baseball_diamond_simplified.svg))--></p>
<p>Un bateador que <em>llega a todas las bases</em> y a <em>home</em>, anota una carrera.</p>
<p>Estamos simplificando un poco, pero hay cinco formas en que un bateador puede tener éxito, es decir, no hacer un <em>out</em>:</p>
<ul>
<li>Bases por bolas (BB): el lanzador no logra lanzar la pelota dentro de un área predefinida donde el bateador le puede dar (la zona de <em>strike</em>), por lo que el bateador puede ir a primera base.</li>
<li>Sencillo: el bateador le da a la bola y llega a primera base.</li>
<li>Doble (2B): el bateador le da a la bola y llega a segunda base.</li>
<li>Triple (3B): el bateador le da a la bola y llega a tercera base.</li>
<li>Cuadrangular (HR): el bateador le da a la bola, llega a <em>home</em> y anota una carrera.</li>
</ul>
<p>Aquí hay un ejemplo de un HR:
<a href="https://www.youtube.com/watch?v=xYxSZJ9GZ-w">https://www.youtube.com/watch?v=xYxSZJ9GZ-wfont</a>.
Si un bateador llega a una base, ese bateador aún tiene la posibilidad de llegar a <em>home</em> y anotar una carrera si el siguiente bateador batea con éxito. Mientras el bateador está <em>en base</em>, él también puede intentar robarse una base (SB o <em>stolen bases</em> en inglés). Si un bateador corre lo suficientemente rápido, el bateador puede intentar ir de una base a la siguiente sin que el otro equipo lo toque (<em>tag</em> en inglés). Aquí tenemos un ejemplo de una base robada: <a href="https://www.youtube.com/watch?v=JSE5kfxkzfk">https://www.youtube.com/watch?v=JSE5kfxkzfkfont</a>.</p>
<p>Todos estos eventos se registran durante la temporada y están disponibles para nosotros a través del paquete <strong>Lahman</strong>. Ahora comenzaremos a discutir cómo el análisis de datos puede ayudarnos a decidir cómo usar estas estadísticas para evaluar a los jugadores.</p>
</div>
<div id="no-hay-premios-para-bb" class="section level3">
<h3><span class="header-section-number">18.1.3</span> No hay premios para BB</h3>
<p>Históricamente, el <em>promedio de bateo</em> se ha considerado la estadística ofensiva más importante. Para definir este promedio, definimos un <em>hit</em> (H) y un <em>al bate</em> (AB o <em>at bat</em> en inglés). Sencillos, dobles, triples y cuadrangulares son éxitos. La quinta forma de tener éxito, BB, no es un éxito. Un AB es la cantidad de veces que un bateador logra un <em>hit</em> o un <em>out</em>; los BB se excluyen. El promedio de bateo es simplemente H/AB y se considera la medida principal de una tasa de éxito. Hoy esta tasa de éxito oscila entre el 20% y el 38%. Nos referimos al promedio de bateo en miles, por lo que, por ejemplo, si su índice de éxito es 28%, decimos que <em>está bateando 280</em>.</p>
<p><img src="regression/img/JumboTron.png" width="70%" style="display: block; margin: auto;" />
(Imagen cortesía de Keith Allison<a href="#fn71" class="footnote-ref" id="fnref71"><sup>71</sup></a>. Licencia CC BY-SA 2.0<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a>. )</p>
<p>Una de las primeras ideas importantes de Bill James es que el promedio de bateo ignora BB, pero un BB es un éxito. James propuso que se usara el <em>on-base percentage</em> (OBP), o porcentaje de veces que un bateador llega a una base, en lugar del promedio de bateo. Definió OBP como (H + BB)/(AB + BB), que es simplemente la proporción de turnos al bate que no resultan en un <em>out</em>, una medida muy intuitiva. Señaló que un jugador que obtiene muchos más BB que el jugador promedio podría no ser reconocido si su promedio de bateo no es alto. ¿Pero este jugador no está ayudando a producir carreras? Aún así, no se le otorga premio al jugador con más BB. Además, el béisbol no adoptó de inmediato el OBP como una estadística importante. En contraste, el total de bases robadas se considera importante y le otorgan un premio al jugador con la mayor cantidad<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a>. Pero los jugadores con altos totales de SB también hacen más <em>outs</em> ya que no siempre tienen éxito. ¿Un jugador con un alto total de SB ayuda a producir carreras? ¿Podemos usar la ciencia de datos para determinar si es mejor pagar por jugadores con totales altos de BB o de SB?</p>
</div>
<div id="base-por-bolas-o-bases-robadas" class="section level3">
<h3><span class="header-section-number">18.1.4</span> ¿Base por bolas o bases robadas?</h3>
<p>Uno de los desafíos en este análisis es que no es obvio cómo determinar si un jugador produce carreras porque mucho depende de sus compañeros de equipo. Llevamos un registro del número de carreras anotadas por un jugador. Sin embargo, recuerden que si un jugador X batea justo antes de alguien que logra muchos cuadrangulares, el bateador X marcará muchas carreras. Pero estas carreras no necesariamente suceden si contratamos al jugador X pero no a su compañero de equipo que batea cuadrangulares. Sin embargo, podemos examinar las estadísticas a nivel de equipo. ¿Cómo se comparan los equipos con muchos SB con los equipos con pocos? ¿Qué tal BB? !Tenemos datos! Vamos a examinar algunos.</p>
<p>Comencemos con una obvia: HR. ¿Los equipos que tienen más cuadrangulares anotan más carreras? Examinamos los datos de 1961 a 2001. La visualización de las opciones al explorar la relación entre dos variables, como HR y triunfos, es un diagrama de dispersión:</p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb665-1"><a href="modelos-lineales.html#cb665-1"></a><span class="kw">library</span>(Lahman)</span>
<span id="cb665-2"><a href="modelos-lineales.html#cb665-2"></a></span>
<span id="cb665-3"><a href="modelos-lineales.html#cb665-3"></a>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb665-4"><a href="modelos-lineales.html#cb665-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR_per_game =</span> HR<span class="op">/</span><span class="st"> </span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span><span class="st"> </span>G) <span class="op">%&gt;%</span></span>
<span id="cb665-5"><a href="modelos-lineales.html#cb665-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(HR_per_game, R_per_game)) <span class="op">+</span></span>
<span id="cb665-6"><a href="modelos-lineales.html#cb665-6"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/runs-vs-hrs-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El gráfico muestra una fuerte asociación: los equipos con más HR tienden a anotar más carreras. Ahora examinemos la relación entre bases robadas y carreras:</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="modelos-lineales.html#cb666-1"></a>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb666-2"><a href="modelos-lineales.html#cb666-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">SB_per_game =</span> SB<span class="op">/</span><span class="st"> </span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span><span class="st"> </span>G) <span class="op">%&gt;%</span></span>
<span id="cb666-3"><a href="modelos-lineales.html#cb666-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(SB_per_game, R_per_game)) <span class="op">+</span></span>
<span id="cb666-4"><a href="modelos-lineales.html#cb666-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/runs-vs-sb-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Aquí la relación no es tan clara. Finalmente, examinemos la relación entre BB y carreras:</p>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="modelos-lineales.html#cb667-1"></a>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb667-2"><a href="modelos-lineales.html#cb667-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BB_per_game =</span> BB<span class="op">/</span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb667-3"><a href="modelos-lineales.html#cb667-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(BB_per_game, R_per_game)) <span class="op">+</span></span>
<span id="cb667-4"><a href="modelos-lineales.html#cb667-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/runs-vs-bb-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Aquí nuevamente vemos una asociación clara. Pero, ¿esto significa que aumentar las BB de un equipo <strong>causa</strong> un aumento en las carreras? Una de las lecciones más importantes que aprenderemos en este libro es que <strong>la asociación no implica causalidad.</strong></p>
<p>De hecho, parece que los BB y HR también están asociados:</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="modelos-lineales.html#cb668-1"></a>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb668-2"><a href="modelos-lineales.html#cb668-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR_per_game =</span> HR<span class="op">/</span>G, <span class="dt">BB_per_game =</span> BB<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb668-3"><a href="modelos-lineales.html#cb668-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(HR_per_game, BB_per_game)) <span class="op">+</span></span>
<span id="cb668-4"><a href="modelos-lineales.html#cb668-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/bb-vs-hrs-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Sabemos que los HR causan carreras porque, como su nombre sugiere, cuando un jugador logra un “home run”, se le garantiza al menos una carrera. ¿Podría ser que los HR también causen BB y esto hace que parezca que los BB también causen carreras? Cuando esto sucede, decimos que hay <em>confusión</em>, un concepto importante sobre el que aprenderemos más a lo largo de este capítulo.</p>
<p>La regresión lineal nos ayudará a analizar todo esto y cuantificar las asociaciones para determinar qué jugadores reclutar. Específicamente, trataremos de predecir cosas como cuántas carreras más anotará un equipo si aumentamos el número de BB, pero mantenemos los HR fijos. La regresión nos ayudará a responder preguntas como esta.</p>
</div>
<div id="regresión-aplicada-a-las-estadísticas-de-béisbol" class="section level3">
<h3><span class="header-section-number">18.1.5</span> Regresión aplicada a las estadísticas de béisbol</h3>
<p>¿Podemos usar la regresión con estos datos? Primero, observen que los datos de HR y carreras parecen seguir una distribución normal de dos variables. Guardamos el gráfico en el objeto <code>p</code> ya que lo usaremos más tarde.</p>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="modelos-lineales.html#cb669-1"></a><span class="kw">library</span>(Lahman)</span>
<span id="cb669-2"><a href="modelos-lineales.html#cb669-2"></a>p &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb669-3"><a href="modelos-lineales.html#cb669-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR_per_game =</span> HR<span class="op">/</span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb669-4"><a href="modelos-lineales.html#cb669-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(HR_per_game, R_per_game)) <span class="op">+</span></span>
<span id="cb669-5"><a href="modelos-lineales.html#cb669-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb669-6"><a href="modelos-lineales.html#cb669-6"></a>p</span></code></pre></div>
<p><img src="libro_files/figure-html/hr-runs-bivariate-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Los gráficos Q-Q confirman que la aproximación normal es útil aquí:</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="modelos-lineales.html#cb670-1"></a>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb670-2"><a href="modelos-lineales.html#cb670-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">z_HR =</span> <span class="kw">round</span>((HR <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(HR))<span class="op">/</span><span class="kw">sd</span>(HR)),</span>
<span id="cb670-3"><a href="modelos-lineales.html#cb670-3"></a>         <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb670-4"><a href="modelos-lineales.html#cb670-4"></a><span class="st">  </span><span class="kw">filter</span>(z_HR <span class="op">%in%</span><span class="st"> </span><span class="dv">-2</span><span class="op">:</span><span class="dv">3</span>) <span class="op">%&gt;%</span></span>
<span id="cb670-5"><a href="modelos-lineales.html#cb670-5"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb670-6"><a href="modelos-lineales.html#cb670-6"></a><span class="st">  </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample=</span>R_per_game)) <span class="op">+</span></span>
<span id="cb670-7"><a href="modelos-lineales.html#cb670-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>z_HR)</span></code></pre></div>
<p><img src="libro_files/figure-html/hr-by-runs-qq-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Ahora estamos listos para usar la regresión lineal para predecir el número de carreras que anotará un equipo si sabemos cuántos cuadrangulares logrará el equipo. Lo único que necesitamos hacer es calcular los cinco resúmenes estadísticos:</p>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="modelos-lineales.html#cb671-1"></a>summary_stats &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span></span>
<span id="cb671-2"><a href="modelos-lineales.html#cb671-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb671-3"><a href="modelos-lineales.html#cb671-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR_per_game =</span> HR<span class="op">/</span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb671-4"><a href="modelos-lineales.html#cb671-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg_HR =</span> <span class="kw">mean</span>(HR_per_game),</span>
<span id="cb671-5"><a href="modelos-lineales.html#cb671-5"></a>            <span class="dt">s_HR =</span> <span class="kw">sd</span>(HR_per_game),</span>
<span id="cb671-6"><a href="modelos-lineales.html#cb671-6"></a>            <span class="dt">avg_R =</span> <span class="kw">mean</span>(R_per_game),</span>
<span id="cb671-7"><a href="modelos-lineales.html#cb671-7"></a>            <span class="dt">s_R =</span> <span class="kw">sd</span>(R_per_game),</span>
<span id="cb671-8"><a href="modelos-lineales.html#cb671-8"></a>            <span class="dt">r =</span> <span class="kw">cor</span>(HR_per_game, R_per_game))</span>
<span id="cb671-9"><a href="modelos-lineales.html#cb671-9"></a>summary_stats</span>
<span id="cb671-10"><a href="modelos-lineales.html#cb671-10"></a><span class="co">#&gt;   avg_HR  s_HR avg_R   s_R     r</span></span>
<span id="cb671-11"><a href="modelos-lineales.html#cb671-11"></a><span class="co">#&gt; 1  0.855 0.243  4.36 0.589 0.762</span></span></code></pre></div>
<p>y usar las fórmulas dadas arriba para crear las líneas de regresión:</p>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="modelos-lineales.html#cb672-1"></a>reg_line &lt;-<span class="st"> </span>summary_stats <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">slope =</span> r<span class="op">*</span>s_R<span class="op">/</span>s_HR,</span>
<span id="cb672-2"><a href="modelos-lineales.html#cb672-2"></a>                                        <span class="dt">intercept =</span> avg_R <span class="op">-</span><span class="st"> </span>slope<span class="op">*</span>avg_HR)</span>
<span id="cb672-3"><a href="modelos-lineales.html#cb672-3"></a></span>
<span id="cb672-4"><a href="modelos-lineales.html#cb672-4"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> reg_line<span class="op">$</span>intercept, <span class="dt">slope =</span> reg_line<span class="op">$</span>slope)</span></code></pre></div>
<p><img src="libro_files/figure-html/hr-versus-runs-regression-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Pronto aprenderemos las funciones de R, como <code>lm</code>, que facilitan el ajuste de las líneas de regresión. Otro ejemplo es la función <code>geom_smooth</code> de <strong>ggplot2</strong> que calcula y agrega una línea de regresión junto con intervalos de confianza al gráfico, de los cuales aprenderemos más adelante. Usamos el argumento <code>method = "lm"</code> que significa <em>modelo lineal</em> (<em>linear model</em> en inglés), el título de una próxima sección. Entonces podemos simplificar el código anterior así:</p>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="modelos-lineales.html#cb673-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</span>
<span id="cb673-2"><a href="modelos-lineales.html#cb673-2"></a><span class="co">#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</span></span></code></pre></div>
<p><img src="libro_files/figure-html/hr-versus-runs-regression-easy-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>En el ejemplo anterior, la pendiente es 1.845. Esto nos dice que los equipos que logran 1 HR más por juego que el equipo promedio, anotan más carreras por juego que el equipo promedio. Dado que la puntuación final más común es la diferencia de una carrera, esto ciertamente puede conducir a un gran aumento en victorias. No es sorprendente que los jugadores con muchos HR sean muy caros. Debido a que estamos trabajando con un presupuesto ajustado, necesitaremos encontrar otra forma de aumentar las victorias. Entonces, en la siguiente sección, trasladamos nuestra atención a BB.</p>

</div>
</div>
<div id="confusión" class="section level2">
<h2><span class="header-section-number">18.2</span> Confusión</h2>
<p>Anteriormente, notamos una fuerte relación entre carreras y BB. Si encontramos la línea de regresión para predecir carreras desde bases por bolas, obtendremos una pendiente de:</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="modelos-lineales.html#cb674-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb674-2"><a href="modelos-lineales.html#cb674-2"></a><span class="kw">library</span>(Lahman)</span>
<span id="cb674-3"><a href="modelos-lineales.html#cb674-3"></a>get_slope &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) <span class="kw">cor</span>(x, y) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y)<span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(x)</span>
<span id="cb674-4"><a href="modelos-lineales.html#cb674-4"></a></span>
<span id="cb674-5"><a href="modelos-lineales.html#cb674-5"></a>bb_slope &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span></span>
<span id="cb674-6"><a href="modelos-lineales.html#cb674-6"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb674-7"><a href="modelos-lineales.html#cb674-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BB_per_game =</span> BB<span class="op">/</span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb674-8"><a href="modelos-lineales.html#cb674-8"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(BB_per_game, R_per_game))</span>
<span id="cb674-9"><a href="modelos-lineales.html#cb674-9"></a></span>
<span id="cb674-10"><a href="modelos-lineales.html#cb674-10"></a>bb_slope</span>
<span id="cb674-11"><a href="modelos-lineales.html#cb674-11"></a><span class="co">#&gt;   slope</span></span>
<span id="cb674-12"><a href="modelos-lineales.html#cb674-12"></a><span class="co">#&gt; 1 0.735</span></span></code></pre></div>
<p>Entonces, ¿esto significa que si contratamos jugadores de bajo salario con muchos BB y así aumentamos por 2 el número de BB por juego, nuestro equipo marcará 1.5 más carreras por juego?</p>
<p>Nuevamente debemos recordar que la asociación no implica la causalidad. Los datos ofrecen evidencia sólida de que un equipo con dos BB más por juego que el equipo promedio, anota 1.5 carreras por juego. Pero esto no significa que los BB sean la causa.</p>
<p>Noten que si calculamos la pendiente de la línea de regresión para sencillos obtenemos:</p>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="modelos-lineales.html#cb675-1"></a>singles_slope &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span></span>
<span id="cb675-2"><a href="modelos-lineales.html#cb675-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb675-3"><a href="modelos-lineales.html#cb675-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Singles_per_game =</span> (H<span class="op">-</span>HR<span class="op">-</span>X2B<span class="op">-</span>X3B)<span class="op">/</span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb675-4"><a href="modelos-lineales.html#cb675-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(Singles_per_game, R_per_game))</span>
<span id="cb675-5"><a href="modelos-lineales.html#cb675-5"></a></span>
<span id="cb675-6"><a href="modelos-lineales.html#cb675-6"></a>singles_slope</span>
<span id="cb675-7"><a href="modelos-lineales.html#cb675-7"></a><span class="co">#&gt;   slope</span></span>
<span id="cb675-8"><a href="modelos-lineales.html#cb675-8"></a><span class="co">#&gt; 1 0.449</span></span></code></pre></div>
<p>que es un valor más bajo que el que obtenemos para BB.</p>
<p>Además, observen que un sencillo lleva a un jugador a primera base igual que un BB. Aquellos que saben de béisbol señalarán que con un sencillo, los corredores en base tienen una mejor oportunidad de anotar que con un BB. Entonces, ¿cómo puede un BB ser más predictivo de las carreras? La razón por la que esto sucede es por <em>confusión</em> (<em>counfounding</em> en inglés). Aquí mostramos la correlación entre HR, BB y sencillos:</p>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="modelos-lineales.html#cb676-1"></a>Teams <span class="op">%&gt;%</span></span>
<span id="cb676-2"><a href="modelos-lineales.html#cb676-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb676-3"><a href="modelos-lineales.html#cb676-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Singles =</span> (H<span class="op">-</span>HR<span class="op">-</span>X2B<span class="op">-</span>X3B)<span class="op">/</span>G, <span class="dt">BB =</span> BB<span class="op">/</span>G, <span class="dt">HR =</span> HR<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb676-4"><a href="modelos-lineales.html#cb676-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="kw">cor</span>(BB, HR), <span class="kw">cor</span>(Singles, HR), <span class="kw">cor</span>(BB, Singles))</span>
<span id="cb676-5"><a href="modelos-lineales.html#cb676-5"></a><span class="co">#&gt;   cor(BB, HR) cor(Singles, HR) cor(BB, Singles)</span></span>
<span id="cb676-6"><a href="modelos-lineales.html#cb676-6"></a><span class="co">#&gt; 1       0.404           -0.174           -0.056</span></span></code></pre></div>
<p>Resulta que los lanzadores, temerosos de los HR, a veces evitarán lanzar <em>strikes</em> a los bateadores de HR. Como resultado, los bateadores de HR tienden a tener más BB y un equipo con muchos bateadores de HR también tendrá más BB. Aunque puede parecer que BB causan carreras, en realidad son HR los que causan la mayoría de estas carreras. Decimos que BB están <em>confundidos</em> (<em>confounded</em> en inglés) con HR. Sin embargo, ¿es posible que las BB todavía ayuden? Para averiguar, tenemos que ajustar para el efecto de HR. La regresión también puede ayudar con esto.</p>
<div id="entender-confusión-a-través-de-estratificación" class="section level3">
<h3><span class="header-section-number">18.2.1</span> Entender confusión a través de estratificación</h3>
<p>Un primer acercamiento es mantener los HR fijos a un valor determinado y luego examinar la relación entre BB y las carreras. Como lo hicimos cuando estratificamos a los padres redondeando a la pulgada más cercana, aquí podemos estratificar HR por juego a los diez más cercanos. Filtramos los estratos con pocos puntos para evitar estimaciones muy variables:</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="modelos-lineales.html#cb677-1"></a>dat &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb677-2"><a href="modelos-lineales.html#cb677-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR_strata =</span> <span class="kw">round</span>(HR<span class="op">/</span>G, <span class="dv">1</span>),</span>
<span id="cb677-3"><a href="modelos-lineales.html#cb677-3"></a>         <span class="dt">BB_per_game =</span> BB<span class="op">/</span><span class="st"> </span>G,</span>
<span id="cb677-4"><a href="modelos-lineales.html#cb677-4"></a>         <span class="dt">R_per_game =</span> R<span class="op">/</span><span class="st"> </span>G) <span class="op">%&gt;%</span></span>
<span id="cb677-5"><a href="modelos-lineales.html#cb677-5"></a><span class="st">  </span><span class="kw">filter</span>(HR_strata <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.4</span> <span class="op">&amp;</span><span class="st"> </span>HR_strata <span class="op">&lt;=</span><span class="fl">1.2</span>)</span></code></pre></div>
<p>y luego hacemos un diagrama de dispersión para cada estrato:</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="modelos-lineales.html#cb678-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb678-2"><a href="modelos-lineales.html#cb678-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(BB_per_game, R_per_game)) <span class="op">+</span></span>
<span id="cb678-3"><a href="modelos-lineales.html#cb678-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb678-4"><a href="modelos-lineales.html#cb678-4"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span></span>
<span id="cb678-5"><a href="modelos-lineales.html#cb678-5"></a><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>HR_strata)</span>
<span id="cb678-6"><a href="modelos-lineales.html#cb678-6"></a><span class="co">#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</span></span></code></pre></div>
<p><img src="libro_files/figure-html/runs-vs-bb-by-hr-strata-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Recuerden que la pendiente de regresión para predecir carreras con BB era 0.7. Una vez que estratificamos por HR, estas pendientes se reducen sustancialmente:</p>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="modelos-lineales.html#cb679-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb679-2"><a href="modelos-lineales.html#cb679-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR_strata) <span class="op">%&gt;%</span></span>
<span id="cb679-3"><a href="modelos-lineales.html#cb679-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(BB_per_game, R_per_game))</span>
<span id="cb679-4"><a href="modelos-lineales.html#cb679-4"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span>
<span id="cb679-5"><a href="modelos-lineales.html#cb679-5"></a><span class="co">#&gt; # A tibble: 9 x 2</span></span>
<span id="cb679-6"><a href="modelos-lineales.html#cb679-6"></a><span class="co">#&gt;   HR_strata slope</span></span>
<span id="cb679-7"><a href="modelos-lineales.html#cb679-7"></a><span class="co">#&gt;       &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb679-8"><a href="modelos-lineales.html#cb679-8"></a><span class="co">#&gt; 1       0.4 0.734</span></span>
<span id="cb679-9"><a href="modelos-lineales.html#cb679-9"></a><span class="co">#&gt; 2       0.5 0.566</span></span>
<span id="cb679-10"><a href="modelos-lineales.html#cb679-10"></a><span class="co">#&gt; 3       0.6 0.412</span></span>
<span id="cb679-11"><a href="modelos-lineales.html#cb679-11"></a><span class="co">#&gt; 4       0.7 0.285</span></span>
<span id="cb679-12"><a href="modelos-lineales.html#cb679-12"></a><span class="co">#&gt; 5       0.8 0.365</span></span>
<span id="cb679-13"><a href="modelos-lineales.html#cb679-13"></a><span class="co">#&gt; # … with 4 more rows</span></span></code></pre></div>
<p>Las pendientes se reducen, pero no son 0, lo que indica que las BB son útiles para producir carreras, pero no tanto como se pensaba anteriormente. De hecho, los valores anteriores están más cerca de la pendiente que obtuvimos de sencillos, 0.45, que es más consistente con nuestra intuición. Dado que tanto los sencillos como los BB nos llevan a primera base, deberían tener aproximadamente el mismo poder predictivo.</p>
<p>Aunque nuestra comprensión de la aplicación nos dice que los HR causan BB pero no al revés, aún podemos verificar si la estratificación por BB hace que el efecto de HR disminuya. Para hacer esto, usamos el mismo código, excepto que intercambiamos HR y BB para obtener este gráfico:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="libro_files/figure-html/runs-vs-hr-by-bb-strata-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>En este caso, las pendientes no cambian mucho del original:</p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb681-1"><a href="modelos-lineales.html#cb681-1"></a>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(BB_strata) <span class="op">%&gt;%</span></span>
<span id="cb681-2"><a href="modelos-lineales.html#cb681-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(HR_per_game, R_per_game))</span>
<span id="cb681-3"><a href="modelos-lineales.html#cb681-3"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span>
<span id="cb681-4"><a href="modelos-lineales.html#cb681-4"></a><span class="co">#&gt; # A tibble: 12 x 2</span></span>
<span id="cb681-5"><a href="modelos-lineales.html#cb681-5"></a><span class="co">#&gt;   BB_strata slope</span></span>
<span id="cb681-6"><a href="modelos-lineales.html#cb681-6"></a><span class="co">#&gt;       &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb681-7"><a href="modelos-lineales.html#cb681-7"></a><span class="co">#&gt; 1       2.8  1.52</span></span>
<span id="cb681-8"><a href="modelos-lineales.html#cb681-8"></a><span class="co">#&gt; 2       2.9  1.57</span></span>
<span id="cb681-9"><a href="modelos-lineales.html#cb681-9"></a><span class="co">#&gt; 3       3    1.52</span></span>
<span id="cb681-10"><a href="modelos-lineales.html#cb681-10"></a><span class="co">#&gt; 4       3.1  1.49</span></span>
<span id="cb681-11"><a href="modelos-lineales.html#cb681-11"></a><span class="co">#&gt; 5       3.2  1.58</span></span>
<span id="cb681-12"><a href="modelos-lineales.html#cb681-12"></a><span class="co">#&gt; # … with 7 more rows</span></span></code></pre></div>
<p>Se reducen un poco, lo que es consistente con el hecho de que BB sí conducen a algunas carreras.</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="modelos-lineales.html#cb682-1"></a>hr_slope &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span></span>
<span id="cb682-2"><a href="modelos-lineales.html#cb682-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span> ) <span class="op">%&gt;%</span></span>
<span id="cb682-3"><a href="modelos-lineales.html#cb682-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR_per_game =</span> HR<span class="op">/</span>G, <span class="dt">R_per_game =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb682-4"><a href="modelos-lineales.html#cb682-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(HR_per_game, R_per_game))</span>
<span id="cb682-5"><a href="modelos-lineales.html#cb682-5"></a></span>
<span id="cb682-6"><a href="modelos-lineales.html#cb682-6"></a>hr_slope</span>
<span id="cb682-7"><a href="modelos-lineales.html#cb682-7"></a><span class="co">#&gt;   slope</span></span>
<span id="cb682-8"><a href="modelos-lineales.html#cb682-8"></a><span class="co">#&gt; 1  1.84</span></span></code></pre></div>
<p>De todos modos, parece que si estratificamos por HR, tenemos una distribución normal de dos variables para carreras versus BB. Del mismo modo, si estratificamos por BB, tenemos una distribución normal de dos variables aproximada para HR versus carreras.</p>
</div>
<div id="regresión-lineal-múltiple" class="section level3">
<h3><span class="header-section-number">18.2.2</span> Regresión lineal múltiple</h3>
<p>Es un poco complejo calcular líneas de regresión para cada estrato. Básicamente, estamos ajustando modelos como este:</p>
<p><span class="math display">\[
\mbox{E}[R \mid BB = x_1, \, HR = x_2] = \beta_0 + \beta_1(x_2) x_1 + \beta_2(x_1) x_2
\]</span></p>
<p>con las pendientes para <span class="math inline">\(x_1\)</span> cambiando para diferentes valores de <span class="math inline">\(x_2\)</span> y viceversa. ¿Pero hay un acercamiento más fácil?</p>
<p>Si tomamos en cuenta la variabilidad aleatoria, las pendientes en los estratos no parecen cambiar mucho. Si estas pendientes son iguales, esto implica que <span class="math inline">\(\beta_1(x_2)\)</span> y <span class="math inline">\(\beta_2(x_1)\)</span> son constantes. Esto a su vez implica que la expectativa de carreras condicionadas en HR y BB se puede escribir así:</p>
<p><span class="math display">\[
\mbox{E}[R \mid BB = x_1, \, HR = x_2] = \beta_0 + \beta_1 x_1 + \beta_2 x_2
\]</span></p>
<p>Este modelo sugiere que si el número de HR se fija en <span class="math inline">\(x_2\)</span>, observamos una relación lineal entre carreras y BB con un intercepto de <span class="math inline">\(\beta_0 + \beta_2 x_2\)</span>. Nuestro análisis exploratorio de datos sugirió esto. El modelo también sugiere que a medida que aumenta el número de HR, el crecimiento del intercepto también es lineal y está determinado por <span class="math inline">\(\beta_1 x_1\)</span>.</p>
<p>En este análisis, denominado <em>regresión lineal múltiple</em>, a menudo escucharán a la gente decir que la pendiente BB <span class="math inline">\(\beta_1\)</span> está <em>ajustada</em> (<em>adjusted</em> en inglés) para el efecto HR. Si el modelo es correcto, entonces se ha tomado en cuenta la confusión. ¿Pero cómo estimamos <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span> de los datos? Para esto, aprendemos sobre modelos lineales y estimaciones de mínimos cuadrados.</p>
</div>
</div>
<div id="lse" class="section level2">
<h2><span class="header-section-number">18.3</span> Estimaciones de mínimos cuadrados</h2>
<p>Hemos explicado cómo cuando los datos tienen una distribución normal de dos variables, entonces los valores esperados condicionales siguen la línea de regresión. El hecho de que el valor esperado condicional es una línea no es una suposición adicional, sino más bien un resultado derivado. Sin embargo, en la práctica es común escribir un modelo que describa la relación entre dos o más variables utilizando un <em>modelo lineal</em> (<em>linear model</em> en inglés).</p>
<p>Notamos que “lineal” aquí no se refiere exclusivamente a líneas, sino al hecho de que el valor esperado condicional es una combinación lineal de cantidades conocidas. En matemáticas, cuando multiplicamos cada variable por una constante y luego las sumamos, decimos que formamos una combinación lineal de las variables. Por ejemplo, <span class="math inline">\(3x - 4y + 5z\)</span> es una combinación lineal de <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span> y <span class="math inline">\(z\)</span>. También podemos añadir una constante y por eso <span class="math inline">\(2 + 3x - 4y + 5z\)</span> también es una combinación lineal de <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span> y <span class="math inline">\(z\)</span>.</p>
<p>Entonces <span class="math inline">\(\beta_0 + \beta_1 x_1 + \beta_2 x_2\)</span> es una combinación lineal de <span class="math inline">\(x_1\)</span> y <span class="math inline">\(x_2\)</span>. El modelo lineal más sencillo es una constante <span class="math inline">\(\beta_0\)</span>; el segundo más sencillo es una línea <span class="math inline">\(\beta_0 + \beta_1 x\)</span>. Si tuviéramos que especificar un modelo lineal para los datos de Galton, denotaríamos la <span class="math inline">\(N\)</span> alturas de padres observadas con <span class="math inline">\(x_1, \dots, x_n\)</span>, entonces modelamos las <span class="math inline">\(N\)</span> alturas de hijos que estamos tratando de predecir con:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \, i=1,\dots,N.
\]</span></p>
<p>Aquí <span class="math inline">\(x_i\)</span> es la altura del padre, que es fija (no aleatoria) debido al condicionamiento, y <span class="math inline">\(Y_i\)</span> es la altura aleatoria del hijo que queremos predecir. Suponemos además que <span class="math inline">\(\varepsilon_i\)</span> son independientes entre sí, tienen valor esperado 0 y la desviación estándar, llámenla <span class="math inline">\(\sigma\)</span>, no depende de <span class="math inline">\(i\)</span>.</p>
<p>En el modelo anterior, sabemos el <span class="math inline">\(x_i\)</span>, pero para tener un modelo útil para la predicción, necesitamos <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>. Los estimamos a partir de los datos. Una vez que hagamos esto, podemos predecir alturas de hijos para cualquier altura de padre <span class="math inline">\(x\)</span>. Mostramos cómo hacer esto en la siguiente sección.</p>
<p>Noten que si suponemos además que el <span class="math inline">\(\varepsilon\)</span> tiene una distribución normal, entonces este modelo es exactamente el mismo que obtuvimos anteriormente suponiendo que los datos siguen una distribución normal de dos variables. Una diferencia algo matizada es que en el primer acercamiento suponemos que los datos siguen una distribución normal de dos variables y que no suponemos un modelo lineal, sino que lo derivamos. En la práctica, los modelos lineales son simplemente supuestos y no necesariamente suponemos normalidad: la distribución de <span class="math inline">\(\varepsilon\)</span>s no se especifica. Sin embargo, si sus datos siguen una distribución normal de dos variables, se cumple el modelo lineal anterior. Si sus datos no siguen una distribución normal de dos variables, necesitarán justificar el modelo de otra forma.</p>
<div id="interpretando-modelos-lineales" class="section level3">
<h3><span class="header-section-number">18.3.1</span> Interpretando modelos lineales</h3>
<p>Una razón por la que los modelos lineales son populares es porque son interpretables. En el caso de los datos de Galton, podemos interpretar los datos de esta manera: debido a los genes heredados, la predicción de la altura del hijo crece por <span class="math inline">\(\beta_1\)</span> para cada pulgada que aumentamos la altura del padre <span class="math inline">\(x\)</span>. Porque no todos los hijos con padres de estatura <span class="math inline">\(x\)</span> son de la misma altura, necesitamos el término <span class="math inline">\(\varepsilon\)</span>, lo que explica la variabilidad restante. Esta variabilidad restante incluye el efecto genético de la madre, los factores ambientales y otros factores biológicos aleatorios.</p>
<p>Dada la forma en que escribimos el modelo anterior, el intercepto <span class="math inline">\(\beta_0\)</span> no es muy interpretable, ya que es la altura pronosticada de un hijo con un padre que mide 0 pulgadas. Debido a la regresión a la media, la predicción generalmente será un poco más grande que 0. Para hacer que el parámetro de pendiente sea más interpretable, podemos reescribir el modelo como:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 (x_i - \bar{x}) + \varepsilon_i, \, i=1,\dots,N
\]</span></p>
<p>con <span class="math inline">\(\bar{x} = 1/N \sum_{i=1}^N x_i\)</span> el promedio de <span class="math inline">\(x\)</span>. En este caso <span class="math inline">\(\beta_0\)</span> representa la altura cuando <span class="math inline">\(x_i = \bar{x}\)</span>, que es la altura del hijo de un padre promedio.</p>
</div>
<div id="estimaciones-de-mínimos-cuadrados-lse" class="section level3">
<h3><span class="header-section-number">18.3.2</span> Estimaciones de mínimos cuadrados (LSE)</h3>
<p>Para que los modelos lineales sean útiles, tenemos que estimar los <span class="math inline">\(\beta\)</span>s desconocidos. El enfoque estándar en la ciencia es encontrar los valores que minimizan la distancia del modelo ajustado a los datos. La siguiente ecuación se llama la ecuación de mínimos cuadrados (LS o <em>least squares</em> en inglés) y la veremos a menudo en este capítulo. Para los datos de Galton, escribiríamos:</p>
<p><span class="math display">\[
RSS = \sum_{i=1}^n \left\{ y_i - \left(\beta_0 + \beta_1 x_i \right)\right\}^2
\]</span></p>
<p>Esta cantidad se denomina suma de errores cuadrados (RSS o <em>residual sum of squares</em> en inglés). Una vez que encontremos los valores que minimizan el RSS, llamaremos a los valores las estimaciones de mínimos cuadrados (LSE o <em>least squares estimates</em> en inglés) y los denotaremos con <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span>. Demostremos esto con el set de datos previamente definido:</p>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="modelos-lineales.html#cb683-1"></a><span class="kw">library</span>(HistData)</span>
<span id="cb683-2"><a href="modelos-lineales.html#cb683-2"></a><span class="kw">data</span>(<span class="st">&quot;GaltonFamilies&quot;</span>)</span>
<span id="cb683-3"><a href="modelos-lineales.html#cb683-3"></a><span class="kw">set.seed</span>(<span class="dv">1983</span>)</span>
<span id="cb683-4"><a href="modelos-lineales.html#cb683-4"></a>galton_heights &lt;-<span class="st"> </span>GaltonFamilies <span class="op">%&gt;%</span></span>
<span id="cb683-5"><a href="modelos-lineales.html#cb683-5"></a><span class="st">  </span><span class="kw">filter</span>(gender <span class="op">==</span><span class="st"> &quot;male&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb683-6"><a href="modelos-lineales.html#cb683-6"></a><span class="st">  </span><span class="kw">group_by</span>(family) <span class="op">%&gt;%</span></span>
<span id="cb683-7"><a href="modelos-lineales.html#cb683-7"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb683-8"><a href="modelos-lineales.html#cb683-8"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb683-9"><a href="modelos-lineales.html#cb683-9"></a><span class="st">  </span><span class="kw">select</span>(father, childHeight) <span class="op">%&gt;%</span></span>
<span id="cb683-10"><a href="modelos-lineales.html#cb683-10"></a><span class="st">  </span><span class="kw">rename</span>(<span class="dt">son =</span> childHeight)</span></code></pre></div>
<p>Escribamos una función que calcule el RSS para cualquier par de valores <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>.</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="modelos-lineales.html#cb684-1"></a>rss &lt;-<span class="st"> </span><span class="cf">function</span>(beta0, beta1, data){</span>
<span id="cb684-2"><a href="modelos-lineales.html#cb684-2"></a>  resid &lt;-<span class="st"> </span>galton_heights<span class="op">$</span>son <span class="op">-</span><span class="st"> </span>(beta0<span class="op">+</span>beta1<span class="op">*</span>galton_heights<span class="op">$</span>father)</span>
<span id="cb684-3"><a href="modelos-lineales.html#cb684-3"></a>  <span class="kw">return</span>(<span class="kw">sum</span>(resid<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb684-4"><a href="modelos-lineales.html#cb684-4"></a>}</span></code></pre></div>
<p>Entonces, para cualquier par de valores, obtenemos un RSS. Aquí hay un gráfico del RSS como función de <span class="math inline">\(\beta_1\)</span> cuando mantenemos el <span class="math inline">\(\beta_0\)</span> fijo en 25.</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="modelos-lineales.html#cb685-1"></a>beta1 =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">len=</span><span class="kw">nrow</span>(galton_heights))</span>
<span id="cb685-2"><a href="modelos-lineales.html#cb685-2"></a>results &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta1 =</span> beta1,</span>
<span id="cb685-3"><a href="modelos-lineales.html#cb685-3"></a>                      <span class="dt">rss =</span> <span class="kw">sapply</span>(beta1, rss, <span class="dt">beta0 =</span> <span class="dv">25</span>))</span>
<span id="cb685-4"><a href="modelos-lineales.html#cb685-4"></a>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(beta1, rss)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb685-5"><a href="modelos-lineales.html#cb685-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(beta1, rss))</span></code></pre></div>
<p><img src="libro_files/figure-html/rss-versus-estimate-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Podemos ver un mínimo claro para <span class="math inline">\(\beta_1\)</span> alrededor de 0.65. Sin embargo, este mínimo para <span class="math inline">\(\beta_1\)</span> es para cuando <span class="math inline">\(\beta_0 = 25\)</span>, un valor que elegimos arbitrariamente. No sabemos si (25, 0.65) es el par que minimiza la ecuación en todos los pares posibles.</p>
<p>Prueba y error no funcionarán en este caso. Podríamos buscar un mínimo dentro de una cuadrícula fina de valores de <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>, pero esto requiere mucho tiempo innecesariamente ya que podemos usar cálculo: tomen las derivadas parciales, fíjenlas en 0 y resuelvan para <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span>. Por supuesto, si tenemos muchos parámetros, estas ecuaciones pueden volverse bastante complejas. Pero hay funciones en R que hacen estos cálculos por nosotros. Aprenderemos esto a continuación. Para aprender las matemáticas detrás de esto, pueden consultar un libro sobre modelos lineales.</p>
</div>
<div id="la-función-lm" class="section level3">
<h3><span class="header-section-number">18.3.3</span> La función <code>lm</code></h3>
<p>En R, podemos obtener las estimaciones de mínimos cuadrados usando la función <code>lm</code>. Para ajustar el modelo:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i
\]</span></p>
<p>con <span class="math inline">\(Y_i\)</span> la altura del hijo y <span class="math inline">\(x_i\)</span> la altura del padre, podemos usar este código para obtener las estimaciones de mínimos cuadrados.</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="modelos-lineales.html#cb686-1"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(son <span class="op">~</span><span class="st"> </span>father, <span class="dt">data =</span> galton_heights)</span>
<span id="cb686-2"><a href="modelos-lineales.html#cb686-2"></a>fit<span class="op">$</span>coef</span>
<span id="cb686-3"><a href="modelos-lineales.html#cb686-3"></a><span class="co">#&gt; (Intercept)      father </span></span>
<span id="cb686-4"><a href="modelos-lineales.html#cb686-4"></a><span class="co">#&gt;      37.288       0.461</span></span></code></pre></div>
<p>La forma más común que usamos <code>lm</code> es mediante el uso del cáracter <code>~</code> para dejar <code>lm</code> saber cuál es la variable que estamos prediciendo (a la izquierda de <code>~</code>) y que estamos utilizando para predecir (a la derecha de <code>~</code>). El intercepto se agrega automáticamente al modelo que se ajustará.</p>
<p>El objeto <code>fit</code> incluye más información sobre el ajuste. Podemos usar la función <code>summary</code> para extraer más de esta información (que no mostramos):</p>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="modelos-lineales.html#cb687-1"></a><span class="kw">summary</span>(fit)</span>
<span id="cb687-2"><a href="modelos-lineales.html#cb687-2"></a><span class="co">#&gt; </span></span>
<span id="cb687-3"><a href="modelos-lineales.html#cb687-3"></a><span class="co">#&gt; Call:</span></span>
<span id="cb687-4"><a href="modelos-lineales.html#cb687-4"></a><span class="co">#&gt; lm(formula = son ~ father, data = galton_heights)</span></span>
<span id="cb687-5"><a href="modelos-lineales.html#cb687-5"></a><span class="co">#&gt; </span></span>
<span id="cb687-6"><a href="modelos-lineales.html#cb687-6"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb687-7"><a href="modelos-lineales.html#cb687-7"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb687-8"><a href="modelos-lineales.html#cb687-8"></a><span class="co">#&gt; -9.354 -1.566 -0.008  1.726  9.415 </span></span>
<span id="cb687-9"><a href="modelos-lineales.html#cb687-9"></a><span class="co">#&gt; </span></span>
<span id="cb687-10"><a href="modelos-lineales.html#cb687-10"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb687-11"><a href="modelos-lineales.html#cb687-11"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb687-12"><a href="modelos-lineales.html#cb687-12"></a><span class="co">#&gt; (Intercept)  37.2876     4.9862    7.48  3.4e-12 ***</span></span>
<span id="cb687-13"><a href="modelos-lineales.html#cb687-13"></a><span class="co">#&gt; father        0.4614     0.0721    6.40  1.4e-09 ***</span></span>
<span id="cb687-14"><a href="modelos-lineales.html#cb687-14"></a><span class="co">#&gt; ---</span></span>
<span id="cb687-15"><a href="modelos-lineales.html#cb687-15"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb687-16"><a href="modelos-lineales.html#cb687-16"></a><span class="co">#&gt; </span></span>
<span id="cb687-17"><a href="modelos-lineales.html#cb687-17"></a><span class="co">#&gt; Residual standard error: 2.45 on 177 degrees of freedom</span></span>
<span id="cb687-18"><a href="modelos-lineales.html#cb687-18"></a><span class="co">#&gt; Multiple R-squared:  0.188,  Adjusted R-squared:  0.183 </span></span>
<span id="cb687-19"><a href="modelos-lineales.html#cb687-19"></a><span class="co">#&gt; F-statistic: 40.9 on 1 and 177 DF,  p-value: 1.36e-09</span></span></code></pre></div>
<p>Para entender parte de la información incluida en este resumen, debemos recordar que las LSE son variables aleatorias. La estadística matemática nos da algunas ideas sobre la distribución de estas variables aleatorias.</p>
</div>
<div id="lse-son-variables-aleatorias" class="section level3">
<h3><span class="header-section-number">18.3.4</span> LSE son variables aleatorias</h3>
<p>El LSE se deriva de los datos <span class="math inline">\(y_1,\dots,y_N\)</span>, que son una realización de variables aleatorias <span class="math inline">\(Y_1, \dots, Y_N\)</span>. Esto implica que nuestras estimaciones son variables aleatorias. Para ver esto, podemos ejecutar una simulación Monte Carlo en la que suponemos que los datos de altura del hijo y el padre definen una población, tomar una muestra aleatoria de tamaño <span class="math inline">\(N=50\)</span>, y calcular el coeficiente de pendiente de regresión para cada uno:</p>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="modelos-lineales.html#cb688-1"></a>B &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb688-2"><a href="modelos-lineales.html#cb688-2"></a>N &lt;-<span class="st"> </span><span class="dv">50</span></span>
<span id="cb688-3"><a href="modelos-lineales.html#cb688-3"></a>lse &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {</span>
<span id="cb688-4"><a href="modelos-lineales.html#cb688-4"></a>  <span class="kw">sample_n</span>(galton_heights, N, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb688-5"><a href="modelos-lineales.html#cb688-5"></a><span class="st">    </span><span class="kw">lm</span>(son <span class="op">~</span><span class="st"> </span>father, <span class="dt">data =</span> .) <span class="op">%&gt;%</span></span>
<span id="cb688-6"><a href="modelos-lineales.html#cb688-6"></a><span class="st">    </span>.<span class="op">$</span>coef</span>
<span id="cb688-7"><a href="modelos-lineales.html#cb688-7"></a>})</span>
<span id="cb688-8"><a href="modelos-lineales.html#cb688-8"></a>lse &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta_0 =</span> lse[<span class="dv">1</span>,], <span class="dt">beta_1 =</span> lse[<span class="dv">2</span>,])</span></code></pre></div>
<p>Podemos ver la variabilidad de las estimaciones graficando sus distribuciones:</p>
<p><img src="libro_files/figure-html/lse-distributions-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>La razón por la que se ven normales es porque el teorema del límite central también aplica aquí: para <span class="math inline">\(N\)</span> suficientemente grande, las estimaciones de mínimos cuadrados serán aproximadamente normales con el valor esperado <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>, respectivamente. Los errores estándar son un poco complicados para calcular, pero la teoría matemática nos permite calcularlos y están incluidos en el resumen proporcionado por la función <code>lm</code>. Aquí lo vemos para uno de nuestros sets de datos simulados:</p>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="modelos-lineales.html#cb689-1"></a><span class="kw">sample_n</span>(galton_heights, N, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb689-2"><a href="modelos-lineales.html#cb689-2"></a><span class="st">  </span><span class="kw">lm</span>(son <span class="op">~</span><span class="st"> </span>father, <span class="dt">data =</span> .) <span class="op">%&gt;%</span></span>
<span id="cb689-3"><a href="modelos-lineales.html#cb689-3"></a><span class="st">  </span>summary <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>coef</span>
<span id="cb689-4"><a href="modelos-lineales.html#cb689-4"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb689-5"><a href="modelos-lineales.html#cb689-5"></a><span class="co">#&gt; (Intercept)    19.28     11.656    1.65 1.05e-01</span></span>
<span id="cb689-6"><a href="modelos-lineales.html#cb689-6"></a><span class="co">#&gt; father          0.72      0.169    4.25 9.79e-05</span></span></code></pre></div>
<p>Pueden ver que las estimaciones de errores estándar informadas por la función <code>summary</code> están cerca de los errores estándar de la simulación:</p>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="modelos-lineales.html#cb690-1"></a>lse <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">se_0 =</span> <span class="kw">sd</span>(beta_<span class="dv">0</span>), <span class="dt">se_1 =</span> <span class="kw">sd</span>(beta_<span class="dv">1</span>))</span>
<span id="cb690-2"><a href="modelos-lineales.html#cb690-2"></a><span class="co">#&gt;   se_0  se_1</span></span>
<span id="cb690-3"><a href="modelos-lineales.html#cb690-3"></a><span class="co">#&gt; 1 8.84 0.128</span></span></code></pre></div>
<p>La función <code>summary</code> también informa estadísticas t (<code>t value</code>) y valores p (<code>Pr(&gt;|t|)</code>). La estadística t no se basa realmente en el teorema del límite central, sino más bien en la suposición de que los <span class="math inline">\(\varepsilon\)</span>s siguen una distribución normal. Bajo este supuesto, la teoría matemática nos dice que el LSE dividido por su error estándar, <span class="math inline">\(\hat{\beta}_0/ \hat{\mbox{SE}}(\hat{\beta}_0 )\)</span> y <span class="math inline">\(\hat{\beta}_1/ \hat{\mbox{SE}}(\hat{\beta}_1 )\)</span>, sigue una distribución t con <span class="math inline">\(N-p\)</span> grados de libertad, con <span class="math inline">\(p\)</span> el número de parámetros en nuestro modelo. En el caso de la altura <span class="math inline">\(p=2\)</span>, los dos valores p prueban la hipótesis nula de que <span class="math inline">\(\beta_0 = 0\)</span> y <span class="math inline">\(\beta_1=0\)</span>, respectivamente.</p>
<p>Recuerden que, como describimos en la Sección <a href="models.html#t-dist">16.10</a> para <span class="math inline">\(N\)</span> suficientemente grande, el CLT funciona y la distribución t se vuelve casi igual a la distribución normal. Además, tengan en cuenta que podemos construir intervalos de confianza, pero pronto aprenderemos sobre <strong>broom</strong>, un paquete adicional que lo hace fácil.</p>
<p>Aunque no mostramos ejemplos en este libro, las pruebas de hipótesis con modelos de regresión se usan comúnmente en epidemiología y economía para hacer afirmaciones como “el efecto de A en B fue estadísticamente significativo después de ajustar por X, Y y Z”. Sin embargo, varios supuestos tienen que ser válidos para que estas afirmaciones sean verdaderas.</p>
</div>
<div id="valores-pronosticados-son-variables-aleatorias" class="section level3">
<h3><span class="header-section-number">18.3.5</span> Valores pronosticados son variables aleatorias</h3>
<p>Una vez que ajustemos nuestro modelo, podemos obtener predicciones de <span class="math inline">\(Y\)</span> usando las estimaciones al modelo de regresión. Por ejemplo, si la altura del padre es <span class="math inline">\(x\)</span>, entonces nuestra predicción <span class="math inline">\(\hat{Y}\)</span> para la altura del hijo será:</p>
<p><span class="math display">\[\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 x\]</span></p>
<p>Cuando graficamos <span class="math inline">\(\hat{Y}\)</span> versus <span class="math inline">\(x\)</span>, vemos la línea de regresión.</p>
<p>Tengan en cuenta que la predicción <span class="math inline">\(\hat{Y}\)</span> también es una variable aleatoria y la teoría matemática nos dice cuáles son los errores estándar. Si suponemos que los errores son normales o tienen un tamaño de muestra lo suficientemente grande, también podemos usar la teoría para construir intervalos de confianza. De hecho, la capa <code>geom_smooth(method = "lm")</code> de <strong>ggplot2</strong> que anteriormente usamos grafica <span class="math inline">\(\hat{Y}\)</span> y lo rodea por intervalos de confianza:</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="modelos-lineales.html#cb691-1"></a>galton_heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(son, father)) <span class="op">+</span></span>
<span id="cb691-2"><a href="modelos-lineales.html#cb691-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb691-3"><a href="modelos-lineales.html#cb691-3"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</span>
<span id="cb691-4"><a href="modelos-lineales.html#cb691-4"></a><span class="co">#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</span></span></code></pre></div>
<p><img src="libro_files/figure-html/father-son-regression-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>La función <code>predict</code> de R toma un objeto <code>lm</code> como entrada y devuelve la predicción. Si se piden, se proveen los errores estándar y otra información a partir de la cual podemos construir intervalos de confianza:</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="modelos-lineales.html#cb692-1"></a>fit &lt;-<span class="st"> </span>galton_heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lm</span>(son <span class="op">~</span><span class="st"> </span>father, <span class="dt">data =</span> .)</span>
<span id="cb692-2"><a href="modelos-lineales.html#cb692-2"></a></span>
<span id="cb692-3"><a href="modelos-lineales.html#cb692-3"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)</span>
<span id="cb692-4"><a href="modelos-lineales.html#cb692-4"></a></span>
<span id="cb692-5"><a href="modelos-lineales.html#cb692-5"></a><span class="kw">names</span>(y_hat)</span>
<span id="cb692-6"><a href="modelos-lineales.html#cb692-6"></a><span class="co">#&gt; [1] &quot;fit&quot;            &quot;se.fit&quot;         &quot;df&quot;             &quot;residual.scale&quot;</span></span></code></pre></div>
</div>
</div>
<div id="ejercicios-34" class="section level2">
<h2><span class="header-section-number">18.4</span> Ejercicios</h2>
<p>Hemos demostrado cómo BB y sencillos tienen un poder predictivo similar para anotar carreras. Otra forma de comparar la utilidad de estas métricas de béisbol es evaluando cuán estables son a lo largo de los años. Dado que tenemos que elegir jugadores a base de sus desempeños anteriores, preferiremos métricas que sean más estables. En estos ejercicios, compararemos la estabilidad de sencillos y BBs.</p>
<p>1. Antes de comenzar, queremos generar dos tablas. Una para 2002 y otra para el promedio de las temporadas 1999-2001. Queremos definir estadísticas por turnos al bate. Aquí vemos como creamos la tabla para el 2017, quedándonos solo con jugadores con más de 100 turnos al bate.</p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="modelos-lineales.html#cb693-1"></a><span class="kw">library</span>(Lahman)</span>
<span id="cb693-2"><a href="modelos-lineales.html#cb693-2"></a>dat &lt;-<span class="st"> </span>Batting <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">==</span><span class="st"> </span><span class="dv">2002</span>) <span class="op">%&gt;%</span></span>
<span id="cb693-3"><a href="modelos-lineales.html#cb693-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pa =</span> AB <span class="op">+</span><span class="st"> </span>BB,</span>
<span id="cb693-4"><a href="modelos-lineales.html#cb693-4"></a>         <span class="dt">singles =</span> (H <span class="op">-</span><span class="st"> </span>X2B <span class="op">-</span><span class="st"> </span>X3B <span class="op">-</span><span class="st"> </span>HR)<span class="op">/</span><span class="st"> </span>pa, <span class="dt">bb =</span> BB<span class="op">/</span><span class="st"> </span>pa) <span class="op">%&gt;%</span></span>
<span id="cb693-5"><a href="modelos-lineales.html#cb693-5"></a><span class="st">  </span><span class="kw">filter</span>(pa <span class="op">&gt;=</span><span class="st"> </span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb693-6"><a href="modelos-lineales.html#cb693-6"></a><span class="st">  </span><span class="kw">select</span>(playerID, singles, bb)</span></code></pre></div>
<p>Ahora calcule una tabla similar pero con tasas calculadas durante 1999-2001.</p>
<p>2. En la sección <a href="#joins"><strong>??</strong></a> aprenderemmos sobre <code>inner_join</code>, que puede usar para poner los datos y promedios de 2001 en la misma tabla:</p>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="modelos-lineales.html#cb694-1"></a>dat &lt;-<span class="st"> </span><span class="kw">inner_join</span>(dat, avg, <span class="dt">by =</span> <span class="st">&quot;playerID&quot;</span>)</span></code></pre></div>
<p>Calcule la correlación entre 2002 y las temporadas anteriores para sencillos y BB.</p>
<p>3. Note que la correlación es mayor para BB. Para rápidamente tener una idea de la incertidumbre asociada con esta estimación de correlación, ajustaremos un modelo lineal y calcularemos los intervalos de confianza para el coeficiente de pendiente. Sin embargo, primero haga diagramas de dispersión para confirmar que es apropiado ajustar un modelo lineal.</p>
<p>4. Ahora ajuste un modelo lineal para cada métrica y use la función <code>confint</code> para comparar las estimaciones.</p>
</div>
<div id="regresión-lineal-en-el-tidyverse" class="section level2">
<h2><span class="header-section-number">18.5</span> Regresión lineal en el tidyverse</h2>
<p>Para ver cómo usamos la función <code>lm</code> en un análisis más complejo, volvamos al ejemplo del béisbol. En un ejemplo anterior, estimamos líneas de regresión para predecir carreras para BB en diferentes estratos de HR. Primero construimos un <em>data frame</em> similar a este:</p>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="modelos-lineales.html#cb695-1"></a>dat &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb695-2"><a href="modelos-lineales.html#cb695-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">HR =</span> <span class="kw">round</span>(HR<span class="op">/</span>G, <span class="dv">1</span>),</span>
<span id="cb695-3"><a href="modelos-lineales.html#cb695-3"></a>         <span class="dt">BB =</span> BB<span class="op">/</span>G,</span>
<span id="cb695-4"><a href="modelos-lineales.html#cb695-4"></a>         <span class="dt">R =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb695-5"><a href="modelos-lineales.html#cb695-5"></a><span class="st">  </span><span class="kw">select</span>(HR, BB, R) <span class="op">%&gt;%</span></span>
<span id="cb695-6"><a href="modelos-lineales.html#cb695-6"></a><span class="st">  </span><span class="kw">filter</span>(HR <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.4</span> <span class="op">&amp;</span><span class="st"> </span>HR<span class="op">&lt;=</span><span class="fl">1.2</span>)</span></code></pre></div>
<p>Como todavía no sabíamos de la función <code>lm</code> para calcular la línea de regresión en cada estrato, utilizamos la fórmula así:</p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="modelos-lineales.html#cb696-1"></a>get_slope &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) <span class="kw">cor</span>(x, y) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y)<span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(x)</span>
<span id="cb696-2"><a href="modelos-lineales.html#cb696-2"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb696-3"><a href="modelos-lineales.html#cb696-3"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb696-4"><a href="modelos-lineales.html#cb696-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(BB, R))</span></code></pre></div>
<p>Argumentamos que las pendientes son similares y que las diferencias quizás se debieron a una variación aleatoria. Para ofrecer una defensa más rigurosa de que las pendientes eran las mismas, lo que condujo a nuestro modelo de múltiples variables, pudimos calcular los intervalos de confianza para cada pendiente. No hemos aprendido la fórmula para esto, pero la función <code>lm</code> provee suficiente información para construirlos.</p>
<p>Primero, noten que si intentamos usar la función <code>lm</code> para obtener la pendiente estimada de esta manera:</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="modelos-lineales.html#cb697-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb697-2"><a href="modelos-lineales.html#cb697-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb697-3"><a href="modelos-lineales.html#cb697-3"></a><span class="st">  </span><span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> .) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>coef</span>
<span id="cb697-4"><a href="modelos-lineales.html#cb697-4"></a><span class="co">#&gt; (Intercept)          BB </span></span>
<span id="cb697-5"><a href="modelos-lineales.html#cb697-5"></a><span class="co">#&gt;       2.198       0.638</span></span></code></pre></div>
<p>no obtenemos el resultado que queremos. La función <code>lm</code> ignora el <code>group_by</code> ya que <code>lm</code> no es parte del <strong>tidyverse</strong> y no sabe cómo manejar el resultado de un tibble agrupado.</p>
<p>Las funciones de <strong>tidyverse</strong> saben cómo interpretar los tibbles agrupados. Además, para facilitar la creación de una secuencia de comandos con el <em>pipe</em> <code>%&gt;%</code>, las funciones de <strong>tidyverse</strong> consistentemente devuelven <em>data frames</em>, ya que esto asegura que el resultado de una función sea aceptado como la entrada de otra. Pero la mayoría de las funciones de R no reconocen los tibbles agrupados ni devuelven <em>data frames</em>. La función <code>lm</code> es un ejemplo. Las funciones <code>do</code> sirven como un puente entre las funciones de R, como <code>lm</code>, y el <strong>tidyverse</strong>. La función <code>do</code> entiende tibbles agrupados y siempre devuelve un <em>data frame</em>.</p>
<p>Entonces, intentemos usar la función <code>do</code> para ajustar una línea de regresión a cada estrato de HR:</p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="modelos-lineales.html#cb698-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb698-2"><a href="modelos-lineales.html#cb698-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb698-3"><a href="modelos-lineales.html#cb698-3"></a><span class="st">  </span><span class="kw">do</span>(<span class="dt">fit =</span> <span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> .))</span>
<span id="cb698-4"><a href="modelos-lineales.html#cb698-4"></a><span class="co">#&gt; # A tibble: 9 x 2</span></span>
<span id="cb698-5"><a href="modelos-lineales.html#cb698-5"></a><span class="co">#&gt; # Rowwise: </span></span>
<span id="cb698-6"><a href="modelos-lineales.html#cb698-6"></a><span class="co">#&gt;      HR fit   </span></span>
<span id="cb698-7"><a href="modelos-lineales.html#cb698-7"></a><span class="co">#&gt;   &lt;dbl&gt; &lt;list&gt;</span></span>
<span id="cb698-8"><a href="modelos-lineales.html#cb698-8"></a><span class="co">#&gt; 1   0.4 &lt;lm&gt;  </span></span>
<span id="cb698-9"><a href="modelos-lineales.html#cb698-9"></a><span class="co">#&gt; 2   0.5 &lt;lm&gt;  </span></span>
<span id="cb698-10"><a href="modelos-lineales.html#cb698-10"></a><span class="co">#&gt; 3   0.6 &lt;lm&gt;  </span></span>
<span id="cb698-11"><a href="modelos-lineales.html#cb698-11"></a><span class="co">#&gt; 4   0.7 &lt;lm&gt;  </span></span>
<span id="cb698-12"><a href="modelos-lineales.html#cb698-12"></a><span class="co">#&gt; 5   0.8 &lt;lm&gt;  </span></span>
<span id="cb698-13"><a href="modelos-lineales.html#cb698-13"></a><span class="co">#&gt; # … with 4 more rows</span></span></code></pre></div>
<p>Observen que ajustamos una línea de regresión a cada estrato. La función <code>do</code> creará un <em>data frame</em> con la primera columna como el valor de los estratos y una columna denominada <code>fit</code> (escogimos el nombre, pero puede ser cualquier cosa). La columna contendrá el resultado de la llamada <code>lm</code>. Por lo tanto, el tibble resultante tiene una columna con objetos <code>lm</code>, que no es muy útil.</p>
<p>Además, si no nombramos una columna (noten que arriba la nombramos <code>fit</code>), entonces <code>do</code> devolverá el <em>output</em> real de <code>lm</code>, no un <em>data frame</em>, y esto dará como resultado un error ya que <code>do</code> espera un <em>data frame</em> como resultado.</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="modelos-lineales.html#cb699-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb699-2"><a href="modelos-lineales.html#cb699-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb699-3"><a href="modelos-lineales.html#cb699-3"></a><span class="st">  </span><span class="kw">do</span>(<span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> .))</span></code></pre></div>
<p><code>Error: Results 1, 2, 3, 4, 5, ... must be data frames, not lm</code></p>
<p>Para construir un <em>data frame</em> útil, el <em>output</em> de la función también debe ser un <em>data frame</em>. Podríamos construir una función que devuelva solo lo que queremos en forma de un <em>data frame</em>:</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb700-1"><a href="modelos-lineales.html#cb700-1"></a>get_slope &lt;-<span class="st"> </span><span class="cf">function</span>(data){</span>
<span id="cb700-2"><a href="modelos-lineales.html#cb700-2"></a>  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> data)</span>
<span id="cb700-3"><a href="modelos-lineales.html#cb700-3"></a>  <span class="kw">data.frame</span>(<span class="dt">slope =</span> fit<span class="op">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb700-4"><a href="modelos-lineales.html#cb700-4"></a>             <span class="dt">se =</span> <span class="kw">summary</span>(fit)<span class="op">$</span>coefficient[<span class="dv">2</span>,<span class="dv">2</span>])</span>
<span id="cb700-5"><a href="modelos-lineales.html#cb700-5"></a>}</span></code></pre></div>
<p>Y luego usar <code>do</code> <strong>sin</strong> nombrar el <em>output</em>, puesto que ya estamos obteniendo un <em>data frame</em>:</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="modelos-lineales.html#cb701-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb701-2"><a href="modelos-lineales.html#cb701-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb701-3"><a href="modelos-lineales.html#cb701-3"></a><span class="st">  </span><span class="kw">do</span>(<span class="kw">get_slope</span>(.))</span>
<span id="cb701-4"><a href="modelos-lineales.html#cb701-4"></a><span class="co">#&gt; # A tibble: 9 x 3</span></span>
<span id="cb701-5"><a href="modelos-lineales.html#cb701-5"></a><span class="co">#&gt; # Groups:   HR [9]</span></span>
<span id="cb701-6"><a href="modelos-lineales.html#cb701-6"></a><span class="co">#&gt;      HR slope     se</span></span>
<span id="cb701-7"><a href="modelos-lineales.html#cb701-7"></a><span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb701-8"><a href="modelos-lineales.html#cb701-8"></a><span class="co">#&gt; 1   0.4 0.734 0.208 </span></span>
<span id="cb701-9"><a href="modelos-lineales.html#cb701-9"></a><span class="co">#&gt; 2   0.5 0.566 0.110 </span></span>
<span id="cb701-10"><a href="modelos-lineales.html#cb701-10"></a><span class="co">#&gt; 3   0.6 0.412 0.0974</span></span>
<span id="cb701-11"><a href="modelos-lineales.html#cb701-11"></a><span class="co">#&gt; 4   0.7 0.285 0.0705</span></span>
<span id="cb701-12"><a href="modelos-lineales.html#cb701-12"></a><span class="co">#&gt; 5   0.8 0.365 0.0653</span></span>
<span id="cb701-13"><a href="modelos-lineales.html#cb701-13"></a><span class="co">#&gt; # … with 4 more rows</span></span></code></pre></div>
<p>Si nombramos el <em>output</em>, obtenemos algo que no queremos, una columna que contiene <em>data frames</em>:</p>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb702-1"><a href="modelos-lineales.html#cb702-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb702-2"><a href="modelos-lineales.html#cb702-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb702-3"><a href="modelos-lineales.html#cb702-3"></a><span class="st">  </span><span class="kw">do</span>(<span class="dt">slope =</span> <span class="kw">get_slope</span>(.))</span>
<span id="cb702-4"><a href="modelos-lineales.html#cb702-4"></a><span class="co">#&gt; # A tibble: 9 x 2</span></span>
<span id="cb702-5"><a href="modelos-lineales.html#cb702-5"></a><span class="co">#&gt; # Rowwise: </span></span>
<span id="cb702-6"><a href="modelos-lineales.html#cb702-6"></a><span class="co">#&gt;      HR slope           </span></span>
<span id="cb702-7"><a href="modelos-lineales.html#cb702-7"></a><span class="co">#&gt;   &lt;dbl&gt; &lt;list&gt;          </span></span>
<span id="cb702-8"><a href="modelos-lineales.html#cb702-8"></a><span class="co">#&gt; 1   0.4 &lt;df[,2] [1 × 2]&gt;</span></span>
<span id="cb702-9"><a href="modelos-lineales.html#cb702-9"></a><span class="co">#&gt; 2   0.5 &lt;df[,2] [1 × 2]&gt;</span></span>
<span id="cb702-10"><a href="modelos-lineales.html#cb702-10"></a><span class="co">#&gt; 3   0.6 &lt;df[,2] [1 × 2]&gt;</span></span>
<span id="cb702-11"><a href="modelos-lineales.html#cb702-11"></a><span class="co">#&gt; 4   0.7 &lt;df[,2] [1 × 2]&gt;</span></span>
<span id="cb702-12"><a href="modelos-lineales.html#cb702-12"></a><span class="co">#&gt; 5   0.8 &lt;df[,2] [1 × 2]&gt;</span></span>
<span id="cb702-13"><a href="modelos-lineales.html#cb702-13"></a><span class="co">#&gt; # … with 4 more rows</span></span></code></pre></div>
<p>Esto no es muy útil, así que discutamos una última característica de <code>do</code>. Si el <em>data frame</em> que se devuelve tiene más de una fila, se concatenarán adecuadamente. Aquí hay un ejemplo en el que devolvemos los estimados de ambos parámetros:</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="modelos-lineales.html#cb703-1"></a>get_lse &lt;-<span class="st"> </span><span class="cf">function</span>(data){</span>
<span id="cb703-2"><a href="modelos-lineales.html#cb703-2"></a>  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> data)</span>
<span id="cb703-3"><a href="modelos-lineales.html#cb703-3"></a>  <span class="kw">data.frame</span>(<span class="dt">term =</span> <span class="kw">names</span>(fit<span class="op">$</span>coefficients),</span>
<span id="cb703-4"><a href="modelos-lineales.html#cb703-4"></a>             <span class="dt">slope =</span> fit<span class="op">$</span>coefficients,</span>
<span id="cb703-5"><a href="modelos-lineales.html#cb703-5"></a>             <span class="dt">se =</span> <span class="kw">summary</span>(fit)<span class="op">$</span>coefficient[,<span class="dv">2</span>])</span>
<span id="cb703-6"><a href="modelos-lineales.html#cb703-6"></a>}</span>
<span id="cb703-7"><a href="modelos-lineales.html#cb703-7"></a></span>
<span id="cb703-8"><a href="modelos-lineales.html#cb703-8"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb703-9"><a href="modelos-lineales.html#cb703-9"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb703-10"><a href="modelos-lineales.html#cb703-10"></a><span class="st">  </span><span class="kw">do</span>(<span class="kw">get_lse</span>(.))</span>
<span id="cb703-11"><a href="modelos-lineales.html#cb703-11"></a><span class="co">#&gt; # A tibble: 18 x 4</span></span>
<span id="cb703-12"><a href="modelos-lineales.html#cb703-12"></a><span class="co">#&gt; # Groups:   HR [9]</span></span>
<span id="cb703-13"><a href="modelos-lineales.html#cb703-13"></a><span class="co">#&gt;      HR term        slope    se</span></span>
<span id="cb703-14"><a href="modelos-lineales.html#cb703-14"></a><span class="co">#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb703-15"><a href="modelos-lineales.html#cb703-15"></a><span class="co">#&gt; 1   0.4 (Intercept) 1.36  0.631</span></span>
<span id="cb703-16"><a href="modelos-lineales.html#cb703-16"></a><span class="co">#&gt; 2   0.4 BB          0.734 0.208</span></span>
<span id="cb703-17"><a href="modelos-lineales.html#cb703-17"></a><span class="co">#&gt; 3   0.5 (Intercept) 2.01  0.344</span></span>
<span id="cb703-18"><a href="modelos-lineales.html#cb703-18"></a><span class="co">#&gt; 4   0.5 BB          0.566 0.110</span></span>
<span id="cb703-19"><a href="modelos-lineales.html#cb703-19"></a><span class="co">#&gt; 5   0.6 (Intercept) 2.53  0.305</span></span>
<span id="cb703-20"><a href="modelos-lineales.html#cb703-20"></a><span class="co">#&gt; # … with 13 more rows</span></span></code></pre></div>
<p>Si creen que todo esto es demasiado complicado, no están solos. Para simplificar las cosas, presentamos el paquete <strong>broom</strong> que fue diseñado para facilitar el uso de funciones que ajustan modelos, como <code>lm</code>, con el <strong>tidyverse</strong>.</p>
<div id="el-paquete-broom" class="section level3">
<h3><span class="header-section-number">18.5.1</span> El paquete broom</h3>
<p>Nuestra tarea original era proveer una estimación y un intervalo de confianza para las estimaciones de pendiente de cada estrato. El paquete <strong>broom</strong> hará esto bastante fácil.</p>
<p>El paquete <strong>broom</strong> tiene tres funciones principales, todas las cuales extraen información del objeto devuelto por <code>lm</code> y lo devuelve en un <em>data frame</em> que <strong>tidyverse</strong> entiende. Estas funciones son <code>tidy</code>, <code>glance</code> y <code>augment</code>. La función <code>tidy</code> devuelve estimaciones e información relacionada como un <em>data frame</em>:</p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb704-1"><a href="modelos-lineales.html#cb704-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb704-2"><a href="modelos-lineales.html#cb704-2"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> dat)</span>
<span id="cb704-3"><a href="modelos-lineales.html#cb704-3"></a><span class="kw">tidy</span>(fit)</span>
<span id="cb704-4"><a href="modelos-lineales.html#cb704-4"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb704-5"><a href="modelos-lineales.html#cb704-5"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb704-6"><a href="modelos-lineales.html#cb704-6"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb704-7"><a href="modelos-lineales.html#cb704-7"></a><span class="co">#&gt; 1 (Intercept)    2.20     0.113       19.4 1.12e-70</span></span>
<span id="cb704-8"><a href="modelos-lineales.html#cb704-8"></a><span class="co">#&gt; 2 BB             0.638    0.0344      18.5 1.35e-65</span></span></code></pre></div>
<p>Podemos agregar otros resúmenes importantes, como los intervalos de confianza:</p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="modelos-lineales.html#cb705-1"></a><span class="kw">tidy</span>(fit, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span>
<span id="cb705-2"><a href="modelos-lineales.html#cb705-2"></a><span class="co">#&gt; # A tibble: 2 x 7</span></span>
<span id="cb705-3"><a href="modelos-lineales.html#cb705-3"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value conf.low conf.high</span></span>
<span id="cb705-4"><a href="modelos-lineales.html#cb705-4"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb705-5"><a href="modelos-lineales.html#cb705-5"></a><span class="co">#&gt; 1 (Intercept)    2.20     0.113       19.4 1.12e-70    1.98      2.42 </span></span>
<span id="cb705-6"><a href="modelos-lineales.html#cb705-6"></a><span class="co">#&gt; 2 BB             0.638    0.0344      18.5 1.35e-65    0.570     0.705</span></span></code></pre></div>
<p>Debido a que el resultado es un <em>data frame</em>, podemos usarlo inmediatamente con <code>do</code> para unir los comandos que producen la tabla que queremos. Como se devuelve un <em>data frame</em>, podemos filtrar y seleccionar las filas y columnas que queramos, que facilita trabajar con <strong>ggplot2</strong>:</p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="modelos-lineales.html#cb706-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb706-2"><a href="modelos-lineales.html#cb706-2"></a><span class="st">  </span><span class="kw">group_by</span>(HR) <span class="op">%&gt;%</span></span>
<span id="cb706-3"><a href="modelos-lineales.html#cb706-3"></a><span class="st">  </span><span class="kw">do</span>(<span class="kw">tidy</span>(<span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB, <span class="dt">data =</span> .), <span class="dt">conf.int =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span></span>
<span id="cb706-4"><a href="modelos-lineales.html#cb706-4"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;BB&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb706-5"><a href="modelos-lineales.html#cb706-5"></a><span class="st">  </span><span class="kw">select</span>(HR, estimate, conf.low, conf.high) <span class="op">%&gt;%</span></span>
<span id="cb706-6"><a href="modelos-lineales.html#cb706-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(HR, <span class="dt">y =</span> estimate, <span class="dt">ymin =</span> conf.low, <span class="dt">ymax =</span> conf.high)) <span class="op">+</span></span>
<span id="cb706-7"><a href="modelos-lineales.html#cb706-7"></a><span class="st">  </span><span class="kw">geom_errorbar</span>() <span class="op">+</span></span>
<span id="cb706-8"><a href="modelos-lineales.html#cb706-8"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="libro_files/figure-html/do-tidy-example-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Ahora volvemos a discutir nuestra tarea original de determinar si las pendientes cambiaron. El gráfico que acabamos de hacer, usando <code>do</code> y <code>tidy</code>, muestra que los intervalos de confianza se superponen, que provee una buena confirmación visual de que nuestra suposición de que la pendiente no cambia es cierta.</p>
<p>Las otras funciones ofrecidas por <strong>broom</strong>, <code>glance</code> y <code>augment</code>, se relacionan con resultados específicos del modelo y de la observación, respectivamente. Aquí podemos ver los resúmenes que resultan de ajustar modelos que <code>glance</code> devuelve:</p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="modelos-lineales.html#cb707-1"></a><span class="kw">glance</span>(fit)</span>
<span id="cb707-2"><a href="modelos-lineales.html#cb707-2"></a><span class="co">#&gt; # A tibble: 1 x 12</span></span>
<span id="cb707-3"><a href="modelos-lineales.html#cb707-3"></a><span class="co">#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC</span></span>
<span id="cb707-4"><a href="modelos-lineales.html#cb707-4"></a><span class="co">#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb707-5"><a href="modelos-lineales.html#cb707-5"></a><span class="co">#&gt; 1     0.266         0.265 0.454      343. 1.35e-65     1  -596. 1199.</span></span>
<span id="cb707-6"><a href="modelos-lineales.html#cb707-6"></a><span class="co">#&gt; # … with 4 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;,</span></span>
<span id="cb707-7"><a href="modelos-lineales.html#cb707-7"></a><span class="co">#&gt; #   df.residual &lt;int&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<p>Pueden obtener más información sobre estos resúmenes en cualquier libro de texto de regresión.</p>
<p>Veremos un ejemplo de <code>augment</code> en la siguiente sección.</p>
</div>
</div>
<div id="ejercicios-35" class="section level2">
<h2><span class="header-section-number">18.6</span> Ejercicios</h2>
<p>1. En una sección anterior, calculamos la correlación entre madres e hijas, madres e hijos, padres e hijas, y padres e hijos, y notamos que la correlación más alta es entre padres e hijos y la más baja es entre madres e hijos. Podemos calcular estas correlaciones usando:</p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb708-1"><a href="modelos-lineales.html#cb708-1"></a><span class="kw">data</span>(<span class="st">&quot;GaltonFamilies&quot;</span>)</span>
<span id="cb708-2"><a href="modelos-lineales.html#cb708-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb708-3"><a href="modelos-lineales.html#cb708-3"></a>galton_heights &lt;-<span class="st"> </span>GaltonFamilies <span class="op">%&gt;%</span></span>
<span id="cb708-4"><a href="modelos-lineales.html#cb708-4"></a><span class="st">  </span><span class="kw">group_by</span>(family, gender) <span class="op">%&gt;%</span></span>
<span id="cb708-5"><a href="modelos-lineales.html#cb708-5"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb708-6"><a href="modelos-lineales.html#cb708-6"></a><span class="st">  </span><span class="kw">ungroup</span>()</span>
<span id="cb708-7"><a href="modelos-lineales.html#cb708-7"></a></span>
<span id="cb708-8"><a href="modelos-lineales.html#cb708-8"></a>cors &lt;-<span class="st"> </span>galton_heights <span class="op">%&gt;%</span></span>
<span id="cb708-9"><a href="modelos-lineales.html#cb708-9"></a><span class="st">  </span><span class="kw">gather</span>(parent, parentHeight, father<span class="op">:</span>mother) <span class="op">%&gt;%</span></span>
<span id="cb708-10"><a href="modelos-lineales.html#cb708-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">child =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> &quot;female&quot;</span>, <span class="st">&quot;daughter&quot;</span>, <span class="st">&quot;son&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb708-11"><a href="modelos-lineales.html#cb708-11"></a><span class="st">  </span><span class="kw">unite</span>(pair, <span class="kw">c</span>(<span class="st">&quot;parent&quot;</span>, <span class="st">&quot;child&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb708-12"><a href="modelos-lineales.html#cb708-12"></a><span class="st">  </span><span class="kw">group_by</span>(pair) <span class="op">%&gt;%</span></span>
<span id="cb708-13"><a href="modelos-lineales.html#cb708-13"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">cor =</span> <span class="kw">cor</span>(parentHeight, childHeight))</span></code></pre></div>
<p>¿Son estas diferencias estadísticamente significativas? Para responder, calcularemos las pendientes de la línea de regresión junto con sus errores estándar. Comience usando <code>lm</code> y el paquete <strong>broom</strong> para calcular las pendientes LSE y los errores estándar.</p>
<p>2. Repita el ejercicio anterior, pero calcule también un intervalo de confianza.</p>
<p>3. Grafique los intervalos de confianza y observe que se superponen, que implica que los datos son consistentes con que la herencia de altura y sexo son independientes.</p>
<p>4. Debido a que estamos seleccionando niños al azar, podemos hacer algo como una prueba de permutación aquí. Repita el cálculo de correlaciones 100 veces tomando una muestra diferente cada vez. Sugerencia: use un código similar al que usamos con las simulaciones.</p>
<p>5. Ajuste un modelo de regresión lineal para obtener los efectos de BB y HR en las carreras (a nivel de equipo) para el año 1971. Utilice la función <code>tidy</code> del paquete <strong>broom</strong> para obtener los resultados en un <em>data frame</em>.</p>
<p>6. Ahora repitamos lo anterior para cada año desde 1961 y hagamos un gráfico. Utilice <code>do</code> y el paquete <strong>broom</strong> para ajustar este modelo para cada año desde 1961.</p>
<p>7. Use los resultados del ejercicio anterior para graficar los efectos estimados de BB en las carreras.</p>
<p>8. <strong>Avanzado</strong>. Escriba una función que tome R, HR y BB como argumentos y ajuste dos modelos lineales: <code>R ~ BB</code> y <code>R~BB+HR</code>. Luego use la función <code>do</code> para obtener el <code>BB</code> para ambos modelos para cada año desde 1961. Luego, grafíquelos como función de tiempo y compárelos.</p>
</div>
<div id="estudio-de-caso-moneyball-continuación" class="section level2">
<h2><span class="header-section-number">18.7</span> Estudio de caso: Moneyball (continuación)</h2>
<p>Al tratar de responder de cuán bien las BB predicen las carreras, la exploración de datos nos llevó a un modelo:</p>
<p><span class="math display">\[
\mbox{E}[R \mid BB = x_1, HR = x_2] = \beta_0 + \beta_1 x_1 + \beta_2 x_2
\]</span></p>
<p>Aquí, los datos son aproximadamente normales y las distribuciones condicionales también fueron normales. Por lo tanto, tiene sentido usar un modelo lineal:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i,1} + \beta_2 x_{i,2} + \varepsilon_i
\]</span></p>
<p>con <span class="math inline">\(Y_i\)</span> representando carreras por juego para el equipo <span class="math inline">\(i\)</span>, <span class="math inline">\(x_{i,1}\)</span> representando BB por juego, y <span class="math inline">\(x_{i,2}\)</span> representando HR por juego. Para usar <code>lm</code> aquí, necesitamos que la función sepa que tenemos dos variables predictivas. Entonces usamos el símbolo <code>+</code> de la siguiente manera:</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="modelos-lineales.html#cb709-1"></a>fit &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span></span>
<span id="cb709-2"><a href="modelos-lineales.html#cb709-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb709-3"><a href="modelos-lineales.html#cb709-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BB =</span> BB<span class="op">/</span>G, <span class="dt">HR =</span> HR<span class="op">/</span>G, <span class="dt">R =</span> R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb709-4"><a href="modelos-lineales.html#cb709-4"></a><span class="st">  </span><span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB <span class="op">+</span><span class="st"> </span>HR, <span class="dt">data =</span> .)</span></code></pre></div>
<p>Nosotros podemos usar <code>tidy</code> para ver un buen resumen:</p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="modelos-lineales.html#cb710-1"></a><span class="kw">tidy</span>(fit, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span>
<span id="cb710-2"><a href="modelos-lineales.html#cb710-2"></a><span class="co">#&gt; # A tibble: 3 x 7</span></span>
<span id="cb710-3"><a href="modelos-lineales.html#cb710-3"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value conf.low conf.high</span></span>
<span id="cb710-4"><a href="modelos-lineales.html#cb710-4"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb710-5"><a href="modelos-lineales.html#cb710-5"></a><span class="co">#&gt; 1 (Intercept)    1.74     0.0824      21.2 7.62e- 83    1.58      1.91 </span></span>
<span id="cb710-6"><a href="modelos-lineales.html#cb710-6"></a><span class="co">#&gt; 2 BB             0.387    0.0270      14.3 1.20e- 42    0.334     0.440</span></span>
<span id="cb710-7"><a href="modelos-lineales.html#cb710-7"></a><span class="co">#&gt; 3 HR             1.56     0.0490      31.9 1.78e-155    1.47      1.66</span></span></code></pre></div>
<p>Cuando ajustamos el modelo con una sola variable, las pendientes estimadas fueron 0.735 y 1.845 para BB y HR, respectivamente. Tengan en cuenta que cuando se ajusta el modelo de múltiples variables, ambos disminuyen, con el efecto BB disminuyendo mucho más.</p>
<p>Ahora queremos construir una métrica para elegir jugadores. Tenemos que considerar sencillos, dobles y triples. ¿Podemos construir un modelo que prediga carreras basado en todos estos resultados?</p>
<p>Ahora vamos a dar un “salto de fe” y suponer que estas cinco variables son conjuntamente normales. Esto significa que si elegimos cualquiera de ellos y mantenemos los otros cuatro fijos, la relación con el resultado es lineal y la pendiente no depende de los cuatro valores que se mantienen constantes. Si esto es cierto, entonces un modelo lineal para nuestros datos es:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i,1} + \beta_2 x_{i,2} + \beta_3 x_{i,3}+ \beta_4 x_{i,4} + \beta_5 x_{i,5} + \varepsilon_i
\]</span></p>
<p>con <span class="math inline">\(x_{i,1}, x_{i,2}, x_{i,3}, x_{i,4}, x_{i,5}\)</span> representando BB, sencillos, dobles, triples y HR respectivamente.</p>
<p>Utilizando <code>lm</code>, podemos encontrar rápidamente el LSE para los parámetros usando:</p>
<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="modelos-lineales.html#cb711-1"></a>fit &lt;-<span class="st"> </span>Teams <span class="op">%&gt;%</span></span>
<span id="cb711-2"><a href="modelos-lineales.html#cb711-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1961</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb711-3"><a href="modelos-lineales.html#cb711-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BB =</span> BB<span class="op">/</span><span class="st"> </span>G,</span>
<span id="cb711-4"><a href="modelos-lineales.html#cb711-4"></a>         <span class="dt">singles =</span> (H <span class="op">-</span><span class="st"> </span>X2B <span class="op">-</span><span class="st"> </span>X3B <span class="op">-</span><span class="st"> </span>HR)<span class="op">/</span><span class="st"> </span>G,</span>
<span id="cb711-5"><a href="modelos-lineales.html#cb711-5"></a>         <span class="dt">doubles =</span> X2B<span class="op">/</span><span class="st"> </span>G,</span>
<span id="cb711-6"><a href="modelos-lineales.html#cb711-6"></a>         <span class="dt">triples =</span> X3B<span class="op">/</span><span class="st"> </span>G,</span>
<span id="cb711-7"><a href="modelos-lineales.html#cb711-7"></a>         <span class="dt">HR =</span> HR<span class="op">/</span><span class="st"> </span>G,</span>
<span id="cb711-8"><a href="modelos-lineales.html#cb711-8"></a>         <span class="dt">R =</span> R<span class="op">/</span><span class="st"> </span>G) <span class="op">%&gt;%</span></span>
<span id="cb711-9"><a href="modelos-lineales.html#cb711-9"></a><span class="st">  </span><span class="kw">lm</span>(R <span class="op">~</span><span class="st"> </span>BB <span class="op">+</span><span class="st"> </span>singles <span class="op">+</span><span class="st"> </span>doubles <span class="op">+</span><span class="st"> </span>triples <span class="op">+</span><span class="st"> </span>HR, <span class="dt">data =</span> .)</span></code></pre></div>
<p>Podemos ver los coeficientes usando <code>tidy</code>:</p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="modelos-lineales.html#cb712-1"></a>coefs &lt;-<span class="st"> </span><span class="kw">tidy</span>(fit, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span>
<span id="cb712-2"><a href="modelos-lineales.html#cb712-2"></a></span>
<span id="cb712-3"><a href="modelos-lineales.html#cb712-3"></a>coefs</span>
<span id="cb712-4"><a href="modelos-lineales.html#cb712-4"></a><span class="co">#&gt; # A tibble: 6 x 7</span></span>
<span id="cb712-5"><a href="modelos-lineales.html#cb712-5"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value conf.low conf.high</span></span>
<span id="cb712-6"><a href="modelos-lineales.html#cb712-6"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb712-7"><a href="modelos-lineales.html#cb712-7"></a><span class="co">#&gt; 1 (Intercept)   -2.77     0.0862     -32.1 4.76e-157   -2.94     -2.60 </span></span>
<span id="cb712-8"><a href="modelos-lineales.html#cb712-8"></a><span class="co">#&gt; 2 BB             0.371    0.0117      31.6 1.87e-153    0.348     0.394</span></span>
<span id="cb712-9"><a href="modelos-lineales.html#cb712-9"></a><span class="co">#&gt; 3 singles        0.519    0.0127      40.8 8.67e-217    0.494     0.544</span></span>
<span id="cb712-10"><a href="modelos-lineales.html#cb712-10"></a><span class="co">#&gt; 4 doubles        0.771    0.0226      34.1 8.44e-171    0.727     0.816</span></span>
<span id="cb712-11"><a href="modelos-lineales.html#cb712-11"></a><span class="co">#&gt; 5 triples        1.24     0.0768      16.1 2.12e- 52    1.09      1.39 </span></span>
<span id="cb712-12"><a href="modelos-lineales.html#cb712-12"></a><span class="co">#&gt; # … with 1 more row</span></span></code></pre></div>
<p>Para ver cuán bien nuestra métrica predice carreras, podemos predecir el número de carreras para cada equipo en 2002 usando la función <code>predict</code>, y entonces hacer un gráfico:</p>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="modelos-lineales.html#cb713-1"></a>Teams <span class="op">%&gt;%</span></span>
<span id="cb713-2"><a href="modelos-lineales.html#cb713-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">2002</span>) <span class="op">%&gt;%</span></span>
<span id="cb713-3"><a href="modelos-lineales.html#cb713-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BB =</span> BB<span class="op">/</span>G,</span>
<span id="cb713-4"><a href="modelos-lineales.html#cb713-4"></a>         <span class="dt">singles =</span> (H<span class="op">-</span>X2B<span class="op">-</span>X3B<span class="op">-</span>HR)<span class="op">/</span>G,</span>
<span id="cb713-5"><a href="modelos-lineales.html#cb713-5"></a>         <span class="dt">doubles =</span> X2B<span class="op">/</span>G,</span>
<span id="cb713-6"><a href="modelos-lineales.html#cb713-6"></a>         <span class="dt">triples =</span>X3B<span class="op">/</span>G,</span>
<span id="cb713-7"><a href="modelos-lineales.html#cb713-7"></a>         <span class="dt">HR=</span>HR<span class="op">/</span>G,</span>
<span id="cb713-8"><a href="modelos-lineales.html#cb713-8"></a>         <span class="dt">R=</span>R<span class="op">/</span>G) <span class="op">%&gt;%</span></span>
<span id="cb713-9"><a href="modelos-lineales.html#cb713-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">R_hat =</span> <span class="kw">predict</span>(fit, <span class="dt">newdata =</span> .)) <span class="op">%&gt;%</span></span>
<span id="cb713-10"><a href="modelos-lineales.html#cb713-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(R_hat, R, <span class="dt">label =</span> teamID)) <span class="op">+</span></span>
<span id="cb713-11"><a href="modelos-lineales.html#cb713-11"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb713-12"><a href="modelos-lineales.html#cb713-12"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">nudge_x=</span><span class="fl">0.1</span>, <span class="dt">cex =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb713-13"><a href="modelos-lineales.html#cb713-13"></a><span class="st">  </span><span class="kw">geom_abline</span>()</span></code></pre></div>
<p><img src="libro_files/figure-html/model-predicts-runs-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Nuestro modelo hace un buen trabajo, como lo demuestra el hecho de que los puntos del gráfico observado versus los del gráfico previsto caen cerca de la línea de identidad.</p>
<p>Entonces, en lugar de usar el promedio de bateo, o solo el número de HR, como una medida de selección de jugadores, podemos usar nuestro modelo ajustado para formar una métrica que se relacione más directamente con la producción de carreras. Específicamente, para definir una métrica para un jugador A, imaginamos un equipo compuesto por jugadores como el jugador A y usamos nuestro modelo de regresión ajustado para predecir cuántas carreras produciría este equipo. La fórmula se vería así:
-2.769 +
0.371 <span class="math inline">\(\times\)</span> BB +
0.519 <span class="math inline">\(\times\)</span> singles +
0.771 <span class="math inline">\(\times\)</span> dobles +
1.24 <span class="math inline">\(\times\)</span> triples +
1.443 <span class="math inline">\(\times\)</span> HR.</p>
<p>Para definir una métrica específica al jugador, tenemos un poco más de trabajo por hacer. Un reto aquí es que derivamos la métrica para equipos, basada en estadísticas de resumen a nivel de equipo. Por ejemplo, el valor de HR que se ingresa en la ecuación es HR por juego para todo el equipo. Si en vez calculamos el HR por juego para un jugador, el valor será mucho más bajo dado que ya no son 9 bateadores contribuyendo al total sino un solo jugador. Además, si un jugador solo juega parte del juego y obtiene menos oportunidades que el promedio, todavía se considera un juego jugado. Para los jugadores, una tasa que toma en cuenta oportunidades es la tasa por turnos al bate.</p>
<p>Para hacer que la tasa de equipo por juego sea comparable a la tasa de jugador por turno al bate, calculamos el número promedio de turnos al bate por juego:</p>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="modelos-lineales.html#cb714-1"></a>pa_per_game &lt;-<span class="st"> </span>Batting <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">==</span><span class="st"> </span><span class="dv">2002</span>) <span class="op">%&gt;%</span></span>
<span id="cb714-2"><a href="modelos-lineales.html#cb714-2"></a><span class="st">  </span><span class="kw">group_by</span>(teamID) <span class="op">%&gt;%</span></span>
<span id="cb714-3"><a href="modelos-lineales.html#cb714-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">pa_per_game =</span> <span class="kw">sum</span>(AB<span class="op">+</span>BB)<span class="op">/</span><span class="kw">max</span>(G)) <span class="op">%&gt;%</span></span>
<span id="cb714-4"><a href="modelos-lineales.html#cb714-4"></a><span class="st">  </span><span class="kw">pull</span>(pa_per_game) <span class="op">%&gt;%</span></span>
<span id="cb714-5"><a href="modelos-lineales.html#cb714-5"></a><span class="st">  </span>mean</span>
<span id="cb714-6"><a href="modelos-lineales.html#cb714-6"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span></code></pre></div>
<p>Calculamos las tasas de turnos al bate para jugadores disponibles en 2002 con datos de 1997-2001. Para evitar pequeños artefactos de muestra, filtramos jugadores con menos de 200 turnos al bate por año. Aquí está el cálculo completo en una línea: [fix eng compare]</p>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="modelos-lineales.html#cb715-1"></a>players &lt;-<span class="st"> </span>Batting <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(yearID <span class="op">%in%</span><span class="st"> </span><span class="dv">1997</span><span class="op">:</span><span class="dv">2001</span>) <span class="op">%&gt;%</span></span>
<span id="cb715-2"><a href="modelos-lineales.html#cb715-2"></a><span class="st">  </span><span class="kw">group_by</span>(playerID) <span class="op">%&gt;%</span></span>
<span id="cb715-3"><a href="modelos-lineales.html#cb715-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">PA =</span> BB <span class="op">+</span><span class="st"> </span>AB) <span class="op">%&gt;%</span></span>
<span id="cb715-4"><a href="modelos-lineales.html#cb715-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">G =</span> <span class="kw">sum</span>(PA)<span class="op">/</span>pa_per_game,</span>
<span id="cb715-5"><a href="modelos-lineales.html#cb715-5"></a>            <span class="dt">BB =</span> <span class="kw">sum</span>(BB)<span class="op">/</span>G,</span>
<span id="cb715-6"><a href="modelos-lineales.html#cb715-6"></a>            <span class="dt">singles =</span> <span class="kw">sum</span>(H<span class="op">-</span>X2B<span class="op">-</span>X3B<span class="op">-</span>HR)<span class="op">/</span>G,</span>
<span id="cb715-7"><a href="modelos-lineales.html#cb715-7"></a>            <span class="dt">doubles =</span> <span class="kw">sum</span>(X2B)<span class="op">/</span>G,</span>
<span id="cb715-8"><a href="modelos-lineales.html#cb715-8"></a>            <span class="dt">triples =</span> <span class="kw">sum</span>(X3B)<span class="op">/</span>G,</span>
<span id="cb715-9"><a href="modelos-lineales.html#cb715-9"></a>            <span class="dt">HR =</span> <span class="kw">sum</span>(HR)<span class="op">/</span>G,</span>
<span id="cb715-10"><a href="modelos-lineales.html#cb715-10"></a>            <span class="dt">AVG =</span> <span class="kw">sum</span>(H)<span class="op">/</span><span class="kw">sum</span>(AB),</span>
<span id="cb715-11"><a href="modelos-lineales.html#cb715-11"></a>            <span class="dt">PA =</span> <span class="kw">sum</span>(PA)) <span class="op">%&gt;%</span></span>
<span id="cb715-12"><a href="modelos-lineales.html#cb715-12"></a><span class="st">  </span><span class="kw">filter</span>(PA <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb715-13"><a href="modelos-lineales.html#cb715-13"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>G) <span class="op">%&gt;%</span></span>
<span id="cb715-14"><a href="modelos-lineales.html#cb715-14"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">R_hat =</span> <span class="kw">predict</span>(fit, <span class="dt">newdata =</span> .))</span>
<span id="cb715-15"><a href="modelos-lineales.html#cb715-15"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span></code></pre></div>
<p>Las carreras predichas específicas al jugador calculadas aquí se pueden interpretar como el número de carreras que predecimos que un equipo anotará si todos los bateadores son exactamente como ese jugador. La distribución demuestra que existe una gran variabilidad entre los jugadores:</p>
<div class="sourceCode" id="cb716"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb716-1"><a href="modelos-lineales.html#cb716-1"></a><span class="kw">qplot</span>(R_hat, <span class="dt">data =</span> players, <span class="dt">binwidth =</span> <span class="fl">0.5</span>, <span class="dt">color =</span> <span class="kw">I</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<p><img src="libro_files/figure-html/r-hat-hist-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="añadiendo-información-sobre-salario-y-posición" class="section level3">
<h3><span class="header-section-number">18.7.1</span> Añadiendo información sobre salario y posición</h3>
<p>Para realmente construir el equipo, necesitaremos conocer sus salarios y su posición defensiva. Para hacer esto, unimos el <em>data frame</em> <code>players</code> que acabamos de crear con el <em>data frame</em> de información del jugador incluido en algunas de las otras tablas de datos de Lahman. Aprenderemos más sobre la función <code>join</code> que aprendimos en la Sección <a href="#joins"><strong>??</strong></a>.</p>
<p>Comiencen añadiendo los salarios del 2002 para cada jugador:</p>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="modelos-lineales.html#cb717-1"></a>players &lt;-<span class="st"> </span>Salaries <span class="op">%&gt;%</span></span>
<span id="cb717-2"><a href="modelos-lineales.html#cb717-2"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">==</span><span class="st"> </span><span class="dv">2002</span>) <span class="op">%&gt;%</span></span>
<span id="cb717-3"><a href="modelos-lineales.html#cb717-3"></a><span class="st">  </span><span class="kw">select</span>(playerID, salary) <span class="op">%&gt;%</span></span>
<span id="cb717-4"><a href="modelos-lineales.html#cb717-4"></a><span class="st">  </span><span class="kw">right_join</span>(players, <span class="dt">by=</span><span class="st">&quot;playerID&quot;</span>)</span></code></pre></div>
<p>A continuación, agregamos su posición defensiva. Esta es una tarea algo complicada porque los jugadores juegan más de una posición cada año. La tabla de paquetes <code>Appearances</code> de <strong>Lahman</strong> indica cuántos juegos jugó cada jugador en cada posición y podemos elegir la posición que más se jugó usando <code>which.max</code> en cada fila. Usamos <code>apply</code> para hacer esto. Sin embargo, debido a que algunos jugadores son intercambiados, aparecen más de una vez en la tabla, por lo que primero sumamos sus turnos al bate en los equipos. Aquí, escogemos la posición en la que más jugó el jugador usando la función <code>top_n</code>. Para asegurarnos de que solo elegimos una posición, en el caso de empates, elegimos la primera fila del <em>data frame</em> resultante. También eliminamos la posición <code>OF</code> que significa <em>outfielder</em>, una generalización de tres posiciones: jardín izquierdo (LF o <em>left field</em> en inglés), jardín central (CF o <em>center field</em> en inglés) y campo derecho (RF o <em>right field</em> en inglés). También eliminamos los lanzadores, ya que no batean en la liga en la que juegan los Atléticos.</p>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb718-1"><a href="modelos-lineales.html#cb718-1"></a>position_names &lt;-</span>
<span id="cb718-2"><a href="modelos-lineales.html#cb718-2"></a><span class="st">  </span><span class="kw">paste0</span>(<span class="st">&quot;G_&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>,<span class="st">&quot;c&quot;</span>,<span class="st">&quot;1b&quot;</span>,<span class="st">&quot;2b&quot;</span>,<span class="st">&quot;3b&quot;</span>,<span class="st">&quot;ss&quot;</span>,<span class="st">&quot;lf&quot;</span>,<span class="st">&quot;cf&quot;</span>,<span class="st">&quot;rf&quot;</span>, <span class="st">&quot;dh&quot;</span>))</span>
<span id="cb718-3"><a href="modelos-lineales.html#cb718-3"></a></span>
<span id="cb718-4"><a href="modelos-lineales.html#cb718-4"></a>tmp &lt;-<span class="st"> </span>Appearances <span class="op">%&gt;%</span></span>
<span id="cb718-5"><a href="modelos-lineales.html#cb718-5"></a><span class="st">  </span><span class="kw">filter</span>(yearID <span class="op">==</span><span class="st"> </span><span class="dv">2002</span>) <span class="op">%&gt;%</span></span>
<span id="cb718-6"><a href="modelos-lineales.html#cb718-6"></a><span class="st">  </span><span class="kw">group_by</span>(playerID) <span class="op">%&gt;%</span></span>
<span id="cb718-7"><a href="modelos-lineales.html#cb718-7"></a><span class="st">  </span><span class="kw">summarize_at</span>(position_names, sum) <span class="op">%&gt;%</span></span>
<span id="cb718-8"><a href="modelos-lineales.html#cb718-8"></a><span class="st">  </span><span class="kw">ungroup</span>()</span>
<span id="cb718-9"><a href="modelos-lineales.html#cb718-9"></a></span>
<span id="cb718-10"><a href="modelos-lineales.html#cb718-10"></a>pos &lt;-<span class="st"> </span>tmp <span class="op">%&gt;%</span></span>
<span id="cb718-11"><a href="modelos-lineales.html#cb718-11"></a><span class="st">  </span><span class="kw">select</span>(position_names) <span class="op">%&gt;%</span></span>
<span id="cb718-12"><a href="modelos-lineales.html#cb718-12"></a><span class="st">  </span><span class="kw">apply</span>(., <span class="dv">1</span>, which.max)</span>
<span id="cb718-13"><a href="modelos-lineales.html#cb718-13"></a><span class="co">#&gt; Note: Using an external vector in selections is ambiguous.</span></span>
<span id="cb718-14"><a href="modelos-lineales.html#cb718-14"></a><span class="co">#&gt; ℹ Use `all_of(position_names)` instead of `position_names` to silence this message.</span></span>
<span id="cb718-15"><a href="modelos-lineales.html#cb718-15"></a><span class="co">#&gt; ℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.</span></span>
<span id="cb718-16"><a href="modelos-lineales.html#cb718-16"></a><span class="co">#&gt; This message is displayed once per session.</span></span>
<span id="cb718-17"><a href="modelos-lineales.html#cb718-17"></a></span>
<span id="cb718-18"><a href="modelos-lineales.html#cb718-18"></a>players &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">playerID =</span> tmp<span class="op">$</span>playerID, <span class="dt">POS =</span> position_names[pos]) <span class="op">%&gt;%</span></span>
<span id="cb718-19"><a href="modelos-lineales.html#cb718-19"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">POS =</span> <span class="kw">str_to_upper</span>(<span class="kw">str_remove</span>(POS, <span class="st">&quot;G_&quot;</span>))) <span class="op">%&gt;%</span></span>
<span id="cb718-20"><a href="modelos-lineales.html#cb718-20"></a><span class="st">  </span><span class="kw">filter</span>(POS <span class="op">!=</span><span class="st"> &quot;P&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb718-21"><a href="modelos-lineales.html#cb718-21"></a><span class="st">  </span><span class="kw">right_join</span>(players, <span class="dt">by=</span><span class="st">&quot;playerID&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb718-22"><a href="modelos-lineales.html#cb718-22"></a><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(POS) <span class="op">&amp;</span><span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(salary))</span></code></pre></div>
<p>Finalmente, agregamos su nombre y apellido:</p>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="modelos-lineales.html#cb719-1"></a>players &lt;-<span class="st"> </span>Master <span class="op">%&gt;%</span></span>
<span id="cb719-2"><a href="modelos-lineales.html#cb719-2"></a><span class="st">  </span><span class="kw">select</span>(playerID, nameFirst, nameLast, debut) <span class="op">%&gt;%</span></span>
<span id="cb719-3"><a href="modelos-lineales.html#cb719-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">debut =</span> <span class="kw">as.Date</span>(debut)) <span class="op">%&gt;%</span></span>
<span id="cb719-4"><a href="modelos-lineales.html#cb719-4"></a><span class="st">  </span><span class="kw">right_join</span>(players, <span class="dt">by=</span><span class="st">&quot;playerID&quot;</span>)</span></code></pre></div>
<p>Si son fanáticos del béisbol, reconocerán a los 10 mejores jugadores:</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="modelos-lineales.html#cb720-1"></a>players <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(nameFirst, nameLast, POS, salary, R_hat) <span class="op">%&gt;%</span></span>
<span id="cb720-2"><a href="modelos-lineales.html#cb720-2"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(R_hat)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">10</span>)</span>
<span id="cb720-3"><a href="modelos-lineales.html#cb720-3"></a><span class="co">#&gt; Selecting by R_hat</span></span>
<span id="cb720-4"><a href="modelos-lineales.html#cb720-4"></a><span class="co">#&gt;    nameFirst nameLast POS   salary R_hat</span></span>
<span id="cb720-5"><a href="modelos-lineales.html#cb720-5"></a><span class="co">#&gt; 1      Barry    Bonds  LF 15000000  8.44</span></span>
<span id="cb720-6"><a href="modelos-lineales.html#cb720-6"></a><span class="co">#&gt; 2      Larry   Walker  RF 12666667  8.34</span></span>
<span id="cb720-7"><a href="modelos-lineales.html#cb720-7"></a><span class="co">#&gt; 3       Todd   Helton  1B  5000000  7.76</span></span>
<span id="cb720-8"><a href="modelos-lineales.html#cb720-8"></a><span class="co">#&gt; 4      Manny  Ramirez  LF 15462727  7.71</span></span>
<span id="cb720-9"><a href="modelos-lineales.html#cb720-9"></a><span class="co">#&gt; 5      Sammy     Sosa  RF 15000000  7.56</span></span>
<span id="cb720-10"><a href="modelos-lineales.html#cb720-10"></a><span class="co">#&gt; 6       Jeff  Bagwell  1B 11000000  7.41</span></span>
<span id="cb720-11"><a href="modelos-lineales.html#cb720-11"></a><span class="co">#&gt; 7       Mike   Piazza   C 10571429  7.34</span></span>
<span id="cb720-12"><a href="modelos-lineales.html#cb720-12"></a><span class="co">#&gt; 8      Jason   Giambi  1B 10428571  7.26</span></span>
<span id="cb720-13"><a href="modelos-lineales.html#cb720-13"></a><span class="co">#&gt; 9      Edgar Martinez  DH  7086668  7.26</span></span>
<span id="cb720-14"><a href="modelos-lineales.html#cb720-14"></a><span class="co">#&gt; 10       Jim    Thome  1B  8000000  7.23</span></span></code></pre></div>
</div>
<div id="escoger-nueve-jugadores" class="section level3">
<h3><span class="header-section-number">18.7.2</span> Escoger nueve jugadores</h3>
<p>En promedio, los jugadores con una métrica más alta tienen salarios más altos:</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="modelos-lineales.html#cb721-1"></a>players <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(salary, R_hat, <span class="dt">color =</span> POS)) <span class="op">+</span></span>
<span id="cb721-2"><a href="modelos-lineales.html#cb721-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb721-3"><a href="modelos-lineales.html#cb721-3"></a><span class="st">  </span><span class="kw">scale_x_log10</span>()</span></code></pre></div>
<p><img src="libro_files/figure-html/predicted-runs-vs-salary-1.png" width="70%" style="display: block; margin: auto;" /></p>
<!--Notice the very high salaries for most players. We do see some low-cost players with very high metrics. These will be great for our team. Some of these are likely young players that have not yet been able to negotiate a salary and are unavailable.

Aquí rehacemos el gráfico sin jugadores que debutaron antes de 1998. Usamos la función __lubridate__ `year`, introducido en la Sección \@ref(lubridate).

```r
library(lubridate)
players %>% filter(year(debut) < 1998) %>%
ggplot(aes(salary, R_hat, color = POS)) +
geom_point() +
scale_x_log10()
```

<img src="libro_files/figure-html/predicted-runs-vs-salary-no-rookies-1.png" width="70%" style="display: block; margin: auto;" />
-->
<p>Podemos buscar buenas ofertas mirando a los jugadores que producen muchas más carreras que otros con salarios similares. Podemos usar esta tabla para decidir qué jugadores escoger y mantener nuestro salario total por debajo de los 40 millones de dólares con los que tuvo que trabajar Billy Beane. Esto se puede hacer usando lo que los científicos de computación llaman programación lineal. Esto no es algo que enseñamos, pero aquí están los jugadores seleccionados con este acercamiento:</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
nameFirst
</th>
<th style="text-align:left;">
nameLast
</th>
<th style="text-align:left;">
POS
</th>
<th style="text-align:right;">
salary
</th>
<th style="text-align:right;">
R_hat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Todd
</td>
<td style="text-align:left;">
Helton
</td>
<td style="text-align:left;">
1B
</td>
<td style="text-align:right;">
5000000
</td>
<td style="text-align:right;">
7.76
</td>
</tr>
<tr>
<td style="text-align:left;">
Mike
</td>
<td style="text-align:left;">
Piazza
</td>
<td style="text-align:left;">
C
</td>
<td style="text-align:right;">
10571429
</td>
<td style="text-align:right;">
7.34
</td>
</tr>
<tr>
<td style="text-align:left;">
Edgar
</td>
<td style="text-align:left;">
Martinez
</td>
<td style="text-align:left;">
DH
</td>
<td style="text-align:right;">
7086668
</td>
<td style="text-align:right;">
7.26
</td>
</tr>
<tr>
<td style="text-align:left;">
Jim
</td>
<td style="text-align:left;">
Edmonds
</td>
<td style="text-align:left;">
CF
</td>
<td style="text-align:right;">
7333333
</td>
<td style="text-align:right;">
6.55
</td>
</tr>
<tr>
<td style="text-align:left;">
Jeff
</td>
<td style="text-align:left;">
Kent
</td>
<td style="text-align:left;">
2B
</td>
<td style="text-align:right;">
6000000
</td>
<td style="text-align:right;">
6.39
</td>
</tr>
<tr>
<td style="text-align:left;">
Phil
</td>
<td style="text-align:left;">
Nevin
</td>
<td style="text-align:left;">
3B
</td>
<td style="text-align:right;">
2600000
</td>
<td style="text-align:right;">
6.16
</td>
</tr>
<tr>
<td style="text-align:left;">
Matt
</td>
<td style="text-align:left;">
Stairs
</td>
<td style="text-align:left;">
RF
</td>
<td style="text-align:right;">
500000
</td>
<td style="text-align:right;">
6.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Henry
</td>
<td style="text-align:left;">
Rodriguez
</td>
<td style="text-align:left;">
LF
</td>
<td style="text-align:right;">
300000
</td>
<td style="text-align:right;">
5.94
</td>
</tr>
<tr>
<td style="text-align:left;">
John
</td>
<td style="text-align:left;">
Valentin
</td>
<td style="text-align:left;">
SS
</td>
<td style="text-align:right;">
550000
</td>
<td style="text-align:right;">
5.27
</td>
</tr>
</tbody>
</table>
<p>Vemos que todos estos jugadores tienen BB por encima del promedio y la mayoría tienen tasas de HR por encima del promedio, mientras que lo mismo no es cierto para sencillos. Aquí incluimos una tabla con estadísticas estandarizadas para todos los jugadores, de modo que, por ejemplo, los bateadores de HR por encima del promedio tienen valores superiores a 0.</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
nameLast
</th>
<th style="text-align:right;">
BB
</th>
<th style="text-align:right;">
singles
</th>
<th style="text-align:right;">
doubles
</th>
<th style="text-align:right;">
triples
</th>
<th style="text-align:right;">
HR
</th>
<th style="text-align:right;">
AVG
</th>
<th style="text-align:right;">
R_hat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Helton
</td>
<td style="text-align:right;">
0.909
</td>
<td style="text-align:right;">
-0.215
</td>
<td style="text-align:right;">
2.649
</td>
<td style="text-align:right;">
-0.311
</td>
<td style="text-align:right;">
1.522
</td>
<td style="text-align:right;">
2.670
</td>
<td style="text-align:right;">
2.532
</td>
</tr>
<tr>
<td style="text-align:left;">
Piazza
</td>
<td style="text-align:right;">
0.328
</td>
<td style="text-align:right;">
0.423
</td>
<td style="text-align:right;">
0.204
</td>
<td style="text-align:right;">
-1.418
</td>
<td style="text-align:right;">
1.825
</td>
<td style="text-align:right;">
2.199
</td>
<td style="text-align:right;">
2.089
</td>
</tr>
<tr>
<td style="text-align:left;">
Martinez
</td>
<td style="text-align:right;">
2.135
</td>
<td style="text-align:right;">
-0.005
</td>
<td style="text-align:right;">
1.265
</td>
<td style="text-align:right;">
-1.224
</td>
<td style="text-align:right;">
0.808
</td>
<td style="text-align:right;">
2.203
</td>
<td style="text-align:right;">
2.000
</td>
</tr>
<tr>
<td style="text-align:left;">
Edmonds
</td>
<td style="text-align:right;">
1.071
</td>
<td style="text-align:right;">
-0.558
</td>
<td style="text-align:right;">
0.791
</td>
<td style="text-align:right;">
-1.152
</td>
<td style="text-align:right;">
0.973
</td>
<td style="text-align:right;">
0.854
</td>
<td style="text-align:right;">
1.256
</td>
</tr>
<tr>
<td style="text-align:left;">
Kent
</td>
<td style="text-align:right;">
0.232
</td>
<td style="text-align:right;">
-0.732
</td>
<td style="text-align:right;">
2.011
</td>
<td style="text-align:right;">
0.448
</td>
<td style="text-align:right;">
0.766
</td>
<td style="text-align:right;">
0.787
</td>
<td style="text-align:right;">
1.087
</td>
</tr>
<tr>
<td style="text-align:left;">
Nevin
</td>
<td style="text-align:right;">
0.307
</td>
<td style="text-align:right;">
-0.905
</td>
<td style="text-align:right;">
0.479
</td>
<td style="text-align:right;">
-1.191
</td>
<td style="text-align:right;">
1.193
</td>
<td style="text-align:right;">
0.105
</td>
<td style="text-align:right;">
0.848
</td>
</tr>
<tr>
<td style="text-align:left;">
Stairs
</td>
<td style="text-align:right;">
1.100
</td>
<td style="text-align:right;">
-1.513
</td>
<td style="text-align:right;">
-0.046
</td>
<td style="text-align:right;">
-1.129
</td>
<td style="text-align:right;">
1.121
</td>
<td style="text-align:right;">
-0.561
</td>
<td style="text-align:right;">
0.741
</td>
</tr>
<tr>
<td style="text-align:left;">
Rodriguez
</td>
<td style="text-align:right;">
0.201
</td>
<td style="text-align:right;">
-1.596
</td>
<td style="text-align:right;">
0.332
</td>
<td style="text-align:right;">
-0.782
</td>
<td style="text-align:right;">
1.320
</td>
<td style="text-align:right;">
-0.672
</td>
<td style="text-align:right;">
0.610
</td>
</tr>
<tr>
<td style="text-align:left;">
Valentin
</td>
<td style="text-align:right;">
0.180
</td>
<td style="text-align:right;">
-0.929
</td>
<td style="text-align:right;">
1.794
</td>
<td style="text-align:right;">
-0.435
</td>
<td style="text-align:right;">
-0.045
</td>
<td style="text-align:right;">
-0.472
</td>
<td style="text-align:right;">
-0.089
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="la-falacia-de-la-regresión" class="section level2">
<h2><span class="header-section-number">18.8</span> La falacia de la regresión</h2>
<p>Wikipedia define la <em>maldición de segundo año</em> (<em>sophomore slump</em> en inglés) como:</p>
<blockquote>
<p>Una caída de segundo año o maldición de segundo año se refiere a una instancia en la que un segundo esfuerzo, o segundo año, no cumple con los estándares del primer esfuerzo. Se usa comúnmente para referirse a la apatía de los estudiantes (segundo año de secundaria, colegio o universidad), el rendimiento de los atletas (segunda temporada de juego), cantantes/bandas (segundo álbum), programas de televisión (segunda temporada) y películas (secuelas/precuelas).</p>
</blockquote>
<p>En las Grandes Ligas de Béisbol, el premio al novato del año (ROY o <em>Rookie of the Year</em>) se otorga al jugador de primer año que se considera que ha tenido el mejor desempeño. La frase maldición de segundo año se usa para describir la observación de que a los ganadores del premio ROY no les va tan bien durante su segundo año. Por ejemplo, este artículo de Fox Sports<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> pregunta “¿La impresionante clase de novatos del MLB de 2015 sufrirá una caída de segundo año?”</p>
<p>¿Los datos confirman la existencia de una maldición de segundo año? Vamos a ver. Al examinar los datos para el promedio de bateo, vemos que esta observación es válida para los ROY de mayor rendimiento:</p>
<!--The data is available in the Lahman library, but we have to do some work to create a table with the statistics for all the ROY. First we create a table with player ID, their names, and their most played position.-->
<!--
Ahora, crearemos una tabla con solo los ganadores del premio ROY y agregaremos sus estadísticas de bateo. Filtramos a los lanzadores, ya que los lanzadores no reciben premios por batear y nos vamos a centrar en la ofensiva. Específicamente, nos enfocaremos en el promedio de bateo ya que es el resumen del que la mayoría de los expertos hablan cuando se habla de la caída de segundo año:
-->
<!--
También mantendremos solo las temporadas de novatos y de segundo año y eliminaremos a los jugadores que no jugaron las temporadas de segundo año:
-->
<!--
Finalmente, usaremos la función `spread` para tener una columna para los promedios de bateo de novato y segundo año
-->
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
nameFirst
</th>
<th style="text-align:left;">
nameLast
</th>
<th style="text-align:right;">
rookie_year
</th>
<th style="text-align:right;">
rookie
</th>
<th style="text-align:right;">
sophomore
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Willie
</td>
<td style="text-align:left;">
McCovey
</td>
<td style="text-align:right;">
1959
</td>
<td style="text-align:right;">
0.354
</td>
<td style="text-align:right;">
0.238
</td>
</tr>
<tr>
<td style="text-align:left;">
Ichiro
</td>
<td style="text-align:left;">
Suzuki
</td>
<td style="text-align:right;">
2001
</td>
<td style="text-align:right;">
0.350
</td>
<td style="text-align:right;">
0.321
</td>
</tr>
<tr>
<td style="text-align:left;">
Al
</td>
<td style="text-align:left;">
Bumbry
</td>
<td style="text-align:right;">
1973
</td>
<td style="text-align:right;">
0.337
</td>
<td style="text-align:right;">
0.233
</td>
</tr>
<tr>
<td style="text-align:left;">
Fred
</td>
<td style="text-align:left;">
Lynn
</td>
<td style="text-align:right;">
1975
</td>
<td style="text-align:right;">
0.331
</td>
<td style="text-align:right;">
0.314
</td>
</tr>
<tr>
<td style="text-align:left;">
Albert
</td>
<td style="text-align:left;">
Pujols
</td>
<td style="text-align:right;">
2001
</td>
<td style="text-align:right;">
0.329
</td>
<td style="text-align:right;">
0.314
</td>
</tr>
</tbody>
</table>
<p>De hecho, la proporción de jugadores que tienen un promedio de bateo más bajo en su segundo año es NaN.</p>
<p>Entonces, ¿es “nerviosismo” o “maldición”? Para responder a esta pregunta, volvamos nuestra atención a todos los jugadores que jugaron las temporadas 2013 y 2014 y batearon más de 130 veces (mínimo para ganar el ROY).</p>
<!--We perform similar operations to what we did above: -->
<pre><code>#&gt; `summarise()` regrouping output by &#39;playerID&#39; (override with `.groups` argument)</code></pre>
<p>El mismo patrón surge cuando miramos a los jugadores con el mejor desempeño: los promedios de bateo disminuyen para la mayoría de los mejores jugadores.</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
nameFirst
</th>
<th style="text-align:left;">
nameLast
</th>
<th style="text-align:right;">
2013
</th>
<th style="text-align:right;">
2014
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Miguel
</td>
<td style="text-align:left;">
Cabrera
</td>
<td style="text-align:right;">
0.348
</td>
<td style="text-align:right;">
0.313
</td>
</tr>
<tr>
<td style="text-align:left;">
Hanley
</td>
<td style="text-align:left;">
Ramirez
</td>
<td style="text-align:right;">
0.345
</td>
<td style="text-align:right;">
0.283
</td>
</tr>
<tr>
<td style="text-align:left;">
Michael
</td>
<td style="text-align:left;">
Cuddyer
</td>
<td style="text-align:right;">
0.331
</td>
<td style="text-align:right;">
0.332
</td>
</tr>
<tr>
<td style="text-align:left;">
Scooter
</td>
<td style="text-align:left;">
Gennett
</td>
<td style="text-align:right;">
0.324
</td>
<td style="text-align:right;">
0.289
</td>
</tr>
<tr>
<td style="text-align:left;">
Joe
</td>
<td style="text-align:left;">
Mauer
</td>
<td style="text-align:right;">
0.324
</td>
<td style="text-align:right;">
0.277
</td>
</tr>
</tbody>
</table>
<p>¡Pero estos no son novatos! Además, miren lo que les sucede a los peores jugadores del 2013:</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
nameFirst
</th>
<th style="text-align:left;">
nameLast
</th>
<th style="text-align:right;">
2013
</th>
<th style="text-align:right;">
2014
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Danny
</td>
<td style="text-align:left;">
Espinosa
</td>
<td style="text-align:right;">
0.158
</td>
<td style="text-align:right;">
0.219
</td>
</tr>
<tr>
<td style="text-align:left;">
Dan
</td>
<td style="text-align:left;">
Uggla
</td>
<td style="text-align:right;">
0.179
</td>
<td style="text-align:right;">
0.149
</td>
</tr>
<tr>
<td style="text-align:left;">
Jeff
</td>
<td style="text-align:left;">
Mathis
</td>
<td style="text-align:right;">
0.181
</td>
<td style="text-align:right;">
0.200
</td>
</tr>
<tr>
<td style="text-align:left;">
B. J.
</td>
<td style="text-align:left;">
Upton
</td>
<td style="text-align:right;">
0.184
</td>
<td style="text-align:right;">
0.208
</td>
</tr>
<tr>
<td style="text-align:left;">
Adam
</td>
<td style="text-align:left;">
Rosales
</td>
<td style="text-align:right;">
0.190
</td>
<td style="text-align:right;">
0.262
</td>
</tr>
</tbody>
</table>
<p>¡Sus promedios de bateo en su mayoría suben! ¿Es esto una especie de “bendición” de segundo año? No lo es. No hay tal cosa como una maldición de segundo año. Todo esto se explica con un simple hecho estadístico: la correlación para el rendimiento en dos años separados es alta, pero no perfecta:</p>
<p><img src="libro_files/figure-html/regression-fallacy-1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>La correlación es 0.46 y
los datos se parecen mucho a una distribución normal de dos variables, que significa que predecimos un promedio de bateo <span class="math inline">\(Y\)</span> del 2014 para cualquier jugador que tuviera un promedio de bateo <span class="math inline">\(X\)</span> en el 2013 con:</p>
<p><span class="math display">\[ \frac{Y - .255}{.032} = 0.46 \left( \frac{X - .261}{.023}\right) \]</span></p>
<p>Debido a que la correlación no es perfecta, la regresión nos dice que, en promedio, esperamos que los jugadores de alto desempeño del 2013 tengan un peor desempeño en 2014. No es una maldición; es solo por casualidad. El ROY se selecciona de los valores superiores de <span class="math inline">\(X\)</span> entonces se espera que <span class="math inline">\(Y\)</span> muestre regresión a la media.</p>
</div>
<div id="modelos-de-error-de-medición" class="section level2">
<h2><span class="header-section-number">18.9</span> Modelos de error de medición</h2>
<p>Hasta ahora, todos nuestros ejemplos de regresión lineal se han aplicado a dos o más variables aleatorias. Suponemos que los pares siguen una distribución normales de dos variables y lo usamos para motivar un modelo lineal. Este enfoque cubre la mayoría de los ejemplos reales de regresión lineal. La otra aplicación importante proviene de los modelos de errores de medición. En estas aplicaciones, es común tener una covariable no aleatoria, como el tiempo, y la aleatoriedad se introduce por error de medición en lugar de muestreo o variabilidad natural.</p>
<p>Para entender estos modelos, imaginen que son Galileo en el siglo XVI tratando de describir la velocidad de un objeto que cae. Un asistente sube a la torre de Pisa y deja caer una pelota, mientras que otros asistentes registran la posición en diferentes momentos. Simulemos algunos datos usando las ecuaciones que conocemos hoy y agregando algunos errores de medición. La función <code>rfalling_object</code> de <strong>dslabs</strong> genera estas simulaciones:</p>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="modelos-lineales.html#cb723-1"></a><span class="kw">library</span>(dslabs)</span>
<span id="cb723-2"><a href="modelos-lineales.html#cb723-2"></a>falling_object &lt;-<span class="st"> </span><span class="kw">rfalling_object</span>()</span></code></pre></div>
<p>Los asistentes le entregan los datos a Galileo y esto es lo que él ve:</p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="modelos-lineales.html#cb724-1"></a>falling_object <span class="op">%&gt;%</span></span>
<span id="cb724-2"><a href="modelos-lineales.html#cb724-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(time, observed_distance)) <span class="op">+</span></span>
<span id="cb724-3"><a href="modelos-lineales.html#cb724-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb724-4"><a href="modelos-lineales.html#cb724-4"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Distance in meters&quot;</span>) <span class="op">+</span></span>
<span id="cb724-5"><a href="modelos-lineales.html#cb724-5"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Time in seconds&quot;</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/gravity-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Galileo no conoce la ecuación exacta, pero al observar el gráfico anterior, deduce que la posición debe seguir una parábola, que podemos escribir así:</p>
<p><span class="math display">\[ f(x) = \beta_0 + \beta_1 x + \beta_2 x^2\]</span></p>
<p>Los datos no caen exactamente en una parábola. Galileo sabe que esto se debe a un error de medición. Sus ayudantes cometen errores al medir la distancia. Para tomar esto en cuenta, modela los datos con:</p>
<p><span class="math display">\[ Y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i, i=1,\dots,n \]</span></p>
<p>con <span class="math inline">\(Y_i\)</span> representando la distancia en metros, <span class="math inline">\(x_i\)</span> representando el tiempo en segundos y <span class="math inline">\(\varepsilon\)</span> tomando en cuenta el error de medición. Se supone que el error de medición sea aleatorio, independiente el uno del otro y que con la misma distribución para cada <span class="math inline">\(i\)</span>. También suponemos que no hay sesgo, que significa que el valor esperado <span class="math inline">\(\mbox{E}[\varepsilon] = 0\)</span>.</p>
<p>Noten que este es un modelo lineal porque es una combinación lineal de cantidades conocidas (<span class="math inline">\(x\)</span> y <span class="math inline">\(x^2\)</span> son conocidos) y parámetros desconocidos (los <span class="math inline">\(\beta\)</span>s son parámetros desconocidos para Galileo). A diferencia de nuestros ejemplos anteriores, aquí <span class="math inline">\(x\)</span> es una cantidad fija; no estamos condicionando.</p>
<p>Para plantear una nueva teoría física y comenzar a hacer predicciones sobre la caída de otros objetos, Galileo necesita números reales, en lugar de parámetros desconocidos. Usar LSE parece un enfoque razonable. ¿Cómo encontramos el LSE?</p>
<p>Los cálculos de LSE no requieren que los errores sean aproximadamente normales. La función <code>lm</code> encontrará los <span class="math inline">\(\beta\)</span>s que minimizarán la suma residual de cuadrados:</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="modelos-lineales.html#cb725-1"></a>fit &lt;-<span class="st"> </span>falling_object <span class="op">%&gt;%</span></span>
<span id="cb725-2"><a href="modelos-lineales.html#cb725-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">time_sq =</span> time<span class="op">^</span><span class="dv">2</span>) <span class="op">%&gt;%</span></span>
<span id="cb725-3"><a href="modelos-lineales.html#cb725-3"></a><span class="st">  </span><span class="kw">lm</span>(observed_distance<span class="op">~</span>time<span class="op">+</span>time_sq, <span class="dt">data=</span>.)</span>
<span id="cb725-4"><a href="modelos-lineales.html#cb725-4"></a><span class="kw">tidy</span>(fit)</span>
<span id="cb725-5"><a href="modelos-lineales.html#cb725-5"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb725-6"><a href="modelos-lineales.html#cb725-6"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb725-7"><a href="modelos-lineales.html#cb725-7"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb725-8"><a href="modelos-lineales.html#cb725-8"></a><span class="co">#&gt; 1 (Intercept)   56.1       0.592    94.9   2.23e-17</span></span>
<span id="cb725-9"><a href="modelos-lineales.html#cb725-9"></a><span class="co">#&gt; 2 time          -0.786     0.845    -0.930 3.72e- 1</span></span>
<span id="cb725-10"><a href="modelos-lineales.html#cb725-10"></a><span class="co">#&gt; 3 time_sq       -4.53      0.251   -18.1   1.58e- 9</span></span></code></pre></div>
<p>Verifiquemos si la parábola estimada se ajusta a los datos. La función <code>augment</code> de <strong>broom</strong> nos permite hacer esto fácilmente:</p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb726-1"><a href="modelos-lineales.html#cb726-1"></a><span class="kw">augment</span>(fit) <span class="op">%&gt;%</span></span>
<span id="cb726-2"><a href="modelos-lineales.html#cb726-2"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb726-3"><a href="modelos-lineales.html#cb726-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(time, observed_distance)) <span class="op">+</span></span>
<span id="cb726-4"><a href="modelos-lineales.html#cb726-4"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(time, .fitted), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/falling-object-fit-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Gracias a nuestros maestros de física de escuela secundaria, sabemos que la ecuación para la trayectoria de un objeto que cae es:</p>
<p><span class="math display">\[d = h_0 + v_0 t - 0.5 \times 9.8 t^2\]</span></p>
<p>con <span class="math inline">\(h_0\)</span> y <span class="math inline">\(v_0\)</span> la altura inicial y la velocidad, respectivamente. Los datos que simulamos anteriormente siguieron esta ecuación y agregaron un error de medición a fin de simular <code>n</code> observaciones para dejar caer una pelota <span class="math inline">\((v_0=0)\)</span> desde la torre de Pisa <span class="math inline">\((h_0=55.86)\)</span>.</p>
<p>Estos son consistentes con las estimaciones de los parámetros:</p>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="modelos-lineales.html#cb727-1"></a><span class="kw">tidy</span>(fit, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span>
<span id="cb727-2"><a href="modelos-lineales.html#cb727-2"></a><span class="co">#&gt; # A tibble: 3 x 7</span></span>
<span id="cb727-3"><a href="modelos-lineales.html#cb727-3"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value conf.low conf.high</span></span>
<span id="cb727-4"><a href="modelos-lineales.html#cb727-4"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb727-5"><a href="modelos-lineales.html#cb727-5"></a><span class="co">#&gt; 1 (Intercept)   56.1       0.592    94.9   2.23e-17    54.8      57.4 </span></span>
<span id="cb727-6"><a href="modelos-lineales.html#cb727-6"></a><span class="co">#&gt; 2 time          -0.786     0.845    -0.930 3.72e- 1    -2.65      1.07</span></span>
<span id="cb727-7"><a href="modelos-lineales.html#cb727-7"></a><span class="co">#&gt; 3 time_sq       -4.53      0.251   -18.1   1.58e- 9    -5.08     -3.98</span></span></code></pre></div>
<p>La altura de la torre de Pisa está dentro del intervalo de confianza para <span class="math inline">\(\beta_0\)</span>, la velocidad inicial 0 está en el intervalo de confianza para <span class="math inline">\(\beta_1\)</span> (recuerden que el valor p es mayor que 0.05), y la constante de aceleración está en un intervalo de confianza para <span class="math inline">\(-2 \times \beta_2\)</span>.</p>
</div>
<div id="ejercicios-36" class="section level2">
<h2><span class="header-section-number">18.10</span> Ejercicios</h2>
<p>Desde la década de 1980, los <em>sabermetricians</em> han utilizado una estadística de resumen diferente del promedio de bateo para evaluar a los jugadores. Se dieron cuenta de que las BB eran importantes y que los dobles, triples y HR deberían pesarse más que los sencillos. Como resultado, propusieron la siguiente métrica:</p>
<p><span class="math display">\[
\frac{\mbox{BB}}{\mbox{PA}} + \frac{\mbox{Singles} + 2 \mbox{Doubles} + 3 \mbox{Triples} + 4\mbox{HR}}{\mbox{AB}}
\]</span></p>
<p>Denominaron a la métrica: <em>on-base-percentage plus slugging percentage</em> o OPS. Aunque los <em>sabermetricians</em> probablemente no usaron la regresión, aquí mostramos cómo OPS está cerca de lo que se obtiene con la regresión.</p>
<p>1. Calcule el OPS para cada equipo en la temporada 2001. Luego, grafique carreras por juego versus OPS.</p>
<p>2. Para cada año desde 1961, calcule la correlación entre carreras por juego y OPS; luego, grafique estas correlaciones como función del año.</p>
<p>3. Tenga en cuenta que podemos reescribir OPS como un promedio ponderado de BB, sencillos, dobles, triples y HR. Sabemos que los pesos para dobles, triples y HR son 2, 3 y 4 veces mayores que para los sencillos. ¿Pero y los BB? ¿Cuál es el peso para BB en relación con sencillos? Sugerencia: el peso de BB en relación con sencillos será una función de AB y PA.</p>
<p>4. Tenga en cuenta que el peso para BB, <span class="math inline">\(\frac{\mbox{AB}}{\mbox{PA}}\)</span>, cambiará de un equipo a otro. Para ver cuán variable es, calcule y grafique esta cantidad para cada equipo para cada año desde 1961. Luego, vuelva a graficarla, pero en lugar de calcularla para cada equipo, calcule y grafique la razón para todo el año. Entonces, una vez que esté claro de que no hay mucha tendencia de tiempo o equipo, indique el promedio general.</p>
<p>5. Ahora sabemos que la fórmula para OPS es proporcional a <span class="math inline">\(0.91 \times \mbox{BB} + \mbox{singles} + 2 \times \mbox{doubles} + 3 \times \mbox{triples} + 4 \times \mbox{HR}\)</span>. Veamos cómo se comparan estos coeficientes con esos obtenidos con la regresión. Ajuste un modelo de regresión a los datos después de 1961, como se hizo anteriormente: usando estadísticas por juego para cada año para cada equipo. Después de ajustar este modelo, indique los coeficientes como pesos relativos al coeficiente para sencillos.</p>
<p>6. Vemos que nuestros coeficientes del modelo de regresión lineal siguen la misma tendencia general que esos utilizados por OPS, pero con un peso ligeramente menor para las métricas que no son sencillos. Para cada equipo en los años posteriores a 1961, calcule el OPS, las carreras predichas con el modelo de regresión, y calcule la correlación entre los dos, así como la correlación con carreras por juego.</p>
<p>7. Vemos que el uso del enfoque de regresión predice carreras un poco mejor que OPS, pero no tanto. Sin embargo, tenga en cuenta que hemos estado calculando OPS y prediciendo carreras para los equipos cuando estas medidas se utilizan para evaluar a los jugadores. Demostremos que OPS es bastante similar a lo que se obtiene con la regresión a nivel de jugador. Para la temporada de 1961 y las posteriores, calcule el OPS y las carreras previstas de nuestro modelo para cada jugador y grafíquelas. Use la corrección de PA por juego que usamos en el capítulo anterior.</p>
<p>8. ¿Qué jugadores han mostrado la mayor diferencia entre su rango por carreras predichas y OPS?</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="66">
<li id="fn66"><p><a href="http://mlb.mlb.com/stats/league_leaders.jsp" class="uri">http://mlb.mlb.com/stats/league_leaders.jsp</a><a href="modelos-lineales.html#fnref66" class="footnote-back">↩︎</a></p></li>
<li id="fn67"><p><a href="https://en.wikipedia.org/wiki/Bill_James" class="uri">https://en.wikipedia.org/wiki/Bill_James</a><a href="modelos-lineales.html#fnref67" class="footnote-back">↩︎</a></p></li>
<li id="fn68"><p><a href="https://en.wikipedia.org/wiki/Sabermetrics" class="uri">https://en.wikipedia.org/wiki/Sabermetrics</a><a href="modelos-lineales.html#fnref68" class="footnote-back">↩︎</a></p></li>
<li id="fn69"><p><a href="https://en.wikipedia.org/wiki/User:Cburnett" class="uri">https://en.wikipedia.org/wiki/User:Cburnett</a><a href="modelos-lineales.html#fnref69" class="footnote-back">↩︎</a></p></li>
<li id="fn70"><p><a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en" class="uri">https://creativecommons.org/licenses/by-sa/3.0/deed.en</a> <a href="modelos-lineales.html#fnref70" class="footnote-back">↩︎</a></p></li>
<li id="fn71"><p><a href="https://www.flickr.com/people/27003603@N00" class="uri">https://www.flickr.com/people/27003603@N00</a><a href="modelos-lineales.html#fnref71" class="footnote-back">↩︎</a></p></li>
<li id="fn72"><p><a href="https://creativecommons.org/licenses/by-sa/2.0" class="uri">https://creativecommons.org/licenses/by-sa/2.0</a><a href="modelos-lineales.html#fnref72" class="footnote-back">↩︎</a></p></li>
<li id="fn73"><p><a href="http://www.baseball-almanac.com/awards/lou_brock_award.shtml" class="uri">http://www.baseball-almanac.com/awards/lou_brock_award.shtml</a><a href="modelos-lineales.html#fnref73" class="footnote-back">↩︎</a></p></li>
<li id="fn74"><p><a href="https://www.foxsports.com/stories/mlb/will-mlbs-tremendous-rookie-class-of-2015-suffer-a-sophomore-slump" class="uri">https://www.foxsports.com/stories/mlb/will-mlbs-tremendous-rookie-class-of-2015-suffer-a-sophomore-slump</a><a href="modelos-lineales.html#fnref74" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="la-asociación-no-implica-causalidad.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rafalab/dslibro/edit/master/regression/moneyball-motivation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
