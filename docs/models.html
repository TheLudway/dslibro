<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 16 Modelos estadísticos | libro.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 16 Modelos estadísticos | libro.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 16 Modelos estadísticos | libro.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inference.html"/>
<link rel="next" href="regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introducción a la Ciencia de Datos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i>Introducción</a><ul>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#los-casos-de-estudio"><i class="fa fa-check"></i>Los casos de estudio</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#quién-encontrará-útil-este-libro"><i class="fa fa-check"></i>¿Quién encontrará útil este libro?</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#que-cubre-este-libro"><i class="fa fa-check"></i>¿Que cubre este libro?</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#qué-no-cubre-este-libro"><i class="fa fa-check"></i>¿Qué no cubre este libro?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Comenzando con R y RStudio</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#por-qué-r"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué R?</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#la-consola-r"><i class="fa fa-check"></i><b>1.2</b> La consola R</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#scripts"><i class="fa fa-check"></i><b>1.3</b> <em>Scripts</em></a></li>
<li class="chapter" data-level="1.4" data-path="getting-started.html"><a href="getting-started.html#rstudio"><i class="fa fa-check"></i><b>1.4</b> RStudio</a><ul>
<li class="chapter" data-level="1.4.1" data-path="getting-started.html"><a href="getting-started.html#paneles"><i class="fa fa-check"></i><b>1.4.1</b> Paneles</a></li>
<li class="chapter" data-level="1.4.2" data-path="getting-started.html"><a href="getting-started.html#key-bindings"><i class="fa fa-check"></i><b>1.4.2</b> <em>Key bindings</em></a></li>
<li class="chapter" data-level="1.4.3" data-path="getting-started.html"><a href="getting-started.html#cómo-ejecutar-comandos-mientras-edita-scripts"><i class="fa fa-check"></i><b>1.4.3</b> Cómo ejecutar comandos mientras edita <em>scripts</em></a></li>
<li class="chapter" data-level="1.4.4" data-path="getting-started.html"><a href="getting-started.html#cómo-cambiar-las-opciones-globales"><i class="fa fa-check"></i><b>1.4.4</b> Cómo cambiar las opciones globales</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="getting-started.html"><a href="getting-started.html#instalación-de-paquetes-de-r"><i class="fa fa-check"></i><b>1.5</b> Instalación de paquetes de R</a></li>
</ul></li>
<li class="part"><span><b>I R</b></span></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> Lo básico de R</a><ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#caso-de-estudio-los-asesinatos-con-armas-en-ee.-uu."><i class="fa fa-check"></i><b>2.1</b> Caso de estudio: los asesinatos con armas en EE. UU.</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#lo-básico"><i class="fa fa-check"></i><b>2.2</b> Lo básico</a><ul>
<li class="chapter" data-level="2.2.1" data-path="r-basics.html"><a href="r-basics.html#objetos"><i class="fa fa-check"></i><b>2.2.1</b> Objetos</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-basics.html"><a href="r-basics.html#el-espacio-de-trabajo"><i class="fa fa-check"></i><b>2.2.2</b> El espacio de trabajo</a></li>
<li class="chapter" data-level="2.2.3" data-path="r-basics.html"><a href="r-basics.html#funciones"><i class="fa fa-check"></i><b>2.2.3</b> Funciones</a></li>
<li class="chapter" data-level="2.2.4" data-path="r-basics.html"><a href="r-basics.html#otros-objetos-predefinidos"><i class="fa fa-check"></i><b>2.2.4</b> Otros objetos predefinidos</a></li>
<li class="chapter" data-level="2.2.5" data-path="r-basics.html"><a href="r-basics.html#nombres-de-variables"><i class="fa fa-check"></i><b>2.2.5</b> Nombres de variables</a></li>
<li class="chapter" data-level="2.2.6" data-path="r-basics.html"><a href="r-basics.html#cómo-guardar-su-espacio-de-trabajo"><i class="fa fa-check"></i><b>2.2.6</b> Cómo guardar su espacio de trabajo</a></li>
<li class="chapter" data-level="2.2.7" data-path="r-basics.html"><a href="r-basics.html#scripts-motivantes"><i class="fa fa-check"></i><b>2.2.7</b> <em>Scripts</em> motivantes</a></li>
<li class="chapter" data-level="2.2.8" data-path="r-basics.html"><a href="r-basics.html#cómo-comentar-su-código"><i class="fa fa-check"></i><b>2.2.8</b> Cómo comentar su código</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#ejercicios"><i class="fa fa-check"></i><b>2.3</b> Ejercicios</a></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#tipos-de-datos"><i class="fa fa-check"></i><b>2.4</b> Tipos de datos</a><ul>
<li class="chapter" data-level="2.4.1" data-path="r-basics.html"><a href="r-basics.html#data-frames"><i class="fa fa-check"></i><b>2.4.1</b> <em>data frames</em></a></li>
<li class="chapter" data-level="2.4.2" data-path="r-basics.html"><a href="r-basics.html#cómo-examinar-un-objeto"><i class="fa fa-check"></i><b>2.4.2</b> Cómo examinar un objeto</a></li>
<li class="chapter" data-level="2.4.3" data-path="r-basics.html"><a href="r-basics.html#el-operador-de-acceso"><i class="fa fa-check"></i><b>2.4.3</b> El operador de acceso: <code>$</code></a></li>
<li class="chapter" data-level="2.4.4" data-path="r-basics.html"><a href="r-basics.html#vectores-numéricos-de-caracteres-y-lógicos"><i class="fa fa-check"></i><b>2.4.4</b> Vectores: numéricos, de caracteres y lógicos</a></li>
<li class="chapter" data-level="2.4.5" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>2.4.5</b> Factores</a></li>
<li class="chapter" data-level="2.4.6" data-path="r-basics.html"><a href="r-basics.html#listas"><i class="fa fa-check"></i><b>2.4.6</b> Listas</a></li>
<li class="chapter" data-level="2.4.7" data-path="r-basics.html"><a href="r-basics.html#matrices"><i class="fa fa-check"></i><b>2.4.7</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#ejercicios-1"><i class="fa fa-check"></i><b>2.5</b> Ejercicios</a></li>
<li class="chapter" data-level="2.6" data-path="r-basics.html"><a href="r-basics.html#vectors"><i class="fa fa-check"></i><b>2.6</b> Vectores</a><ul>
<li class="chapter" data-level="2.6.1" data-path="r-basics.html"><a href="r-basics.html#cómo-crear-vectores"><i class="fa fa-check"></i><b>2.6.1</b> Cómo crear vectores</a></li>
<li class="chapter" data-level="2.6.2" data-path="r-basics.html"><a href="r-basics.html#nombres"><i class="fa fa-check"></i><b>2.6.2</b> Nombres</a></li>
<li class="chapter" data-level="2.6.3" data-path="r-basics.html"><a href="r-basics.html#secuencias"><i class="fa fa-check"></i><b>2.6.3</b> Secuencias</a></li>
<li class="chapter" data-level="2.6.4" data-path="r-basics.html"><a href="r-basics.html#cómo-crear-un-subconjunto"><i class="fa fa-check"></i><b>2.6.4</b> Cómo crear un subconjunto</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="r-basics.html"><a href="r-basics.html#la-conversión-forzada"><i class="fa fa-check"></i><b>2.7</b> La conversión forzada</a><ul>
<li class="chapter" data-level="2.7.1" data-path="r-basics.html"><a href="r-basics.html#not-available-na"><i class="fa fa-check"></i><b>2.7.1</b> <em>Not available</em> (NA)</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="r-basics.html"><a href="r-basics.html#ejercicios-2"><i class="fa fa-check"></i><b>2.8</b> Ejercicios</a></li>
<li class="chapter" data-level="2.9" data-path="r-basics.html"><a href="r-basics.html#sorting"><i class="fa fa-check"></i><b>2.9</b> <em>Sorting</em></a><ul>
<li class="chapter" data-level="2.9.1" data-path="r-basics.html"><a href="r-basics.html#sort"><i class="fa fa-check"></i><b>2.9.1</b> <code>sort</code></a></li>
<li class="chapter" data-level="2.9.2" data-path="r-basics.html"><a href="r-basics.html#order"><i class="fa fa-check"></i><b>2.9.2</b> <code>order</code></a></li>
<li class="chapter" data-level="2.9.3" data-path="r-basics.html"><a href="r-basics.html#max-y-which.max"><i class="fa fa-check"></i><b>2.9.3</b> <code>max</code> y <code>which.max</code></a></li>
<li class="chapter" data-level="2.9.4" data-path="r-basics.html"><a href="r-basics.html#rank"><i class="fa fa-check"></i><b>2.9.4</b> <code>rank</code></a></li>
<li class="chapter" data-level="2.9.5" data-path="r-basics.html"><a href="r-basics.html#cuidado-con-el-reciclaje"><i class="fa fa-check"></i><b>2.9.5</b> Cuidado con el reciclaje</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="r-basics.html"><a href="r-basics.html#ejercicios-3"><i class="fa fa-check"></i><b>2.10</b> Ejercicios</a></li>
<li class="chapter" data-level="2.11" data-path="r-basics.html"><a href="r-basics.html#aritmética-de-vectores"><i class="fa fa-check"></i><b>2.11</b> Aritmética de vectores</a><ul>
<li class="chapter" data-level="2.11.1" data-path="r-basics.html"><a href="r-basics.html#rescaling-un-vector"><i class="fa fa-check"></i><b>2.11.1</b> <em>Rescaling</em> un vector</a></li>
<li class="chapter" data-level="2.11.2" data-path="r-basics.html"><a href="r-basics.html#dos-vectores"><i class="fa fa-check"></i><b>2.11.2</b> Dos vectores</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="r-basics.html"><a href="r-basics.html#ejercicios-4"><i class="fa fa-check"></i><b>2.12</b> Ejercicios</a></li>
<li class="chapter" data-level="2.13" data-path="r-basics.html"><a href="r-basics.html#indexación"><i class="fa fa-check"></i><b>2.13</b> Indexación</a><ul>
<li class="chapter" data-level="2.13.1" data-path="r-basics.html"><a href="r-basics.html#crear-subconjuntos-con-lógicos"><i class="fa fa-check"></i><b>2.13.1</b> Crear subconjuntos con lógicos</a></li>
<li class="chapter" data-level="2.13.2" data-path="r-basics.html"><a href="r-basics.html#operadores-lógicos"><i class="fa fa-check"></i><b>2.13.2</b> Operadores lógicos</a></li>
<li class="chapter" data-level="2.13.3" data-path="r-basics.html"><a href="r-basics.html#which"><i class="fa fa-check"></i><b>2.13.3</b> <code>which</code></a></li>
<li class="chapter" data-level="2.13.4" data-path="r-basics.html"><a href="r-basics.html#match"><i class="fa fa-check"></i><b>2.13.4</b> <code>match</code></a></li>
<li class="chapter" data-level="2.13.5" data-path="r-basics.html"><a href="r-basics.html#in"><i class="fa fa-check"></i><b>2.13.5</b> <code>%in%</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="r-basics.html"><a href="r-basics.html#ejercicios-5"><i class="fa fa-check"></i><b>2.14</b> Ejercicios</a></li>
<li class="chapter" data-level="2.15" data-path="r-basics.html"><a href="r-basics.html#gráficos-básicos"><i class="fa fa-check"></i><b>2.15</b> Gráficos básicos</a><ul>
<li class="chapter" data-level="2.15.1" data-path="r-basics.html"><a href="r-basics.html#plot"><i class="fa fa-check"></i><b>2.15.1</b> <code>plot</code></a></li>
<li class="chapter" data-level="2.15.2" data-path="r-basics.html"><a href="r-basics.html#hist"><i class="fa fa-check"></i><b>2.15.2</b> <code>hist</code></a></li>
<li class="chapter" data-level="2.15.3" data-path="r-basics.html"><a href="r-basics.html#boxplot"><i class="fa fa-check"></i><b>2.15.3</b> <code>boxplot</code></a></li>
<li class="chapter" data-level="2.15.4" data-path="r-basics.html"><a href="r-basics.html#image"><i class="fa fa-check"></i><b>2.15.4</b> <code>image</code></a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="r-basics.html"><a href="r-basics.html#ejercicios-6"><i class="fa fa-check"></i><b>2.16</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html"><i class="fa fa-check"></i><b>3</b> Conceptos básicos de programación</a><ul>
<li class="chapter" data-level="3.1" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#conditionals"><i class="fa fa-check"></i><b>3.1</b> Expresiones condicionales</a></li>
<li class="chapter" data-level="3.2" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#cómo-definir-funciones"><i class="fa fa-check"></i><b>3.2</b> Cómo definir funciones</a></li>
<li class="chapter" data-level="3.3" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#namespaces"><i class="fa fa-check"></i><b>3.3</b> <em>Namespaces</em></a></li>
<li class="chapter" data-level="3.4" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#bucles-for"><i class="fa fa-check"></i><b>3.4</b> Bucles-for</a></li>
<li class="chapter" data-level="3.5" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#vectorization"><i class="fa fa-check"></i><b>3.5</b> Vectorización y funcionales</a></li>
<li class="chapter" data-level="3.6" data-path="conceptos-básicos-de-programación.html"><a href="conceptos-básicos-de-programación.html#ejercicios-7"><i class="fa fa-check"></i><b>3.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>4</b> <em>tidyverse</em></a><ul>
<li class="chapter" data-level="4.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy-data"><i class="fa fa-check"></i><b>4.1</b> Data <em>tidy</em></a></li>
<li class="chapter" data-level="4.2" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-8"><i class="fa fa-check"></i><b>4.2</b> Ejercicios</a></li>
<li class="chapter" data-level="4.3" data-path="tidyverse.html"><a href="tidyverse.html#cómo-manipular-los-data-frames"><i class="fa fa-check"></i><b>4.3</b> Cómo manipular los <em>data frames</em></a><ul>
<li class="chapter" data-level="4.3.1" data-path="tidyverse.html"><a href="tidyverse.html#cómo-añadir-una-columna-con-mutate"><i class="fa fa-check"></i><b>4.3.1</b> Cómo añadir una columna con <code>mutate</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="tidyverse.html"><a href="tidyverse.html#cómo-crear-subconjuntos-con-filter"><i class="fa fa-check"></i><b>4.3.2</b> Cómo crear subconjuntos con <code>filter</code></a></li>
<li class="chapter" data-level="4.3.3" data-path="tidyverse.html"><a href="tidyverse.html#cómo-seleccionar-columnas-con-select"><i class="fa fa-check"></i><b>4.3.3</b> Cómo seleccionar columnas con <code>select</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-9"><i class="fa fa-check"></i><b>4.4</b> Ejercicios</a></li>
<li class="chapter" data-level="4.5" data-path="tidyverse.html"><a href="tidyverse.html#el-pipe"><i class="fa fa-check"></i><b>4.5</b> El <em>pipe</em>: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.6" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-10"><i class="fa fa-check"></i><b>4.6</b> Ejercicios</a></li>
<li class="chapter" data-level="4.7" data-path="tidyverse.html"><a href="tidyverse.html#cómo-resumir-datos"><i class="fa fa-check"></i><b>4.7</b> Cómo resumir datos</a><ul>
<li class="chapter" data-level="4.7.1" data-path="tidyverse.html"><a href="tidyverse.html#summarize"><i class="fa fa-check"></i><b>4.7.1</b> <code>summarize</code></a></li>
<li class="chapter" data-level="4.7.2" data-path="tidyverse.html"><a href="tidyverse.html#pull"><i class="fa fa-check"></i><b>4.7.2</b> <code>pull</code></a></li>
<li class="chapter" data-level="4.7.3" data-path="tidyverse.html"><a href="tidyverse.html#group-by"><i class="fa fa-check"></i><b>4.7.3</b> Cómo agrupar y luego resumir con <code>group_by</code></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="tidyverse.html"><a href="tidyverse.html#cómo-ordenar-los-data-frames"><i class="fa fa-check"></i><b>4.8</b> Cómo ordenar los <em>data frames</em></a><ul>
<li class="chapter" data-level="4.8.1" data-path="tidyverse.html"><a href="tidyverse.html#cómo-ordenar-anidadamente"><i class="fa fa-check"></i><b>4.8.1</b> Cómo ordenar anidadamente</a></li>
<li class="chapter" data-level="4.8.2" data-path="tidyverse.html"><a href="tidyverse.html#los-primeros-n"><i class="fa fa-check"></i><b>4.8.2</b> Los primeros <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-11"><i class="fa fa-check"></i><b>4.9</b> Ejercicios</a></li>
<li class="chapter" data-level="4.10" data-path="tidyverse.html"><a href="tidyverse.html#tibbles"><i class="fa fa-check"></i><b>4.10</b> <em>Tibbles</em></a><ul>
<li class="chapter" data-level="4.10.1" data-path="tidyverse.html"><a href="tidyverse.html#los-tibbles-se-ven-mejor"><i class="fa fa-check"></i><b>4.10.1</b> Los <em>tibbles</em> se ven mejor</a></li>
<li class="chapter" data-level="4.10.2" data-path="tidyverse.html"><a href="tidyverse.html#los-subconjuntos-de-tibbles-son-tibbles"><i class="fa fa-check"></i><b>4.10.2</b> Los subconjuntos de <em>tibbles</em> son <em>tibbles</em></a></li>
<li class="chapter" data-level="4.10.3" data-path="tidyverse.html"><a href="tidyverse.html#los-tibbles-pueden-tener-entradas-complejas"><i class="fa fa-check"></i><b>4.10.3</b> Los <em>tibbles</em> pueden tener entradas complejas</a></li>
<li class="chapter" data-level="4.10.4" data-path="tidyverse.html"><a href="tidyverse.html#los-tibbles-se-pueden-agrupar"><i class="fa fa-check"></i><b>4.10.4</b> Los <em>tibbles</em> se pueden agrupar</a></li>
<li class="chapter" data-level="4.10.5" data-path="tidyverse.html"><a href="tidyverse.html#cómo-crear-un-tibble-usando-tibble-en-lugar-de-data.frame"><i class="fa fa-check"></i><b>4.10.5</b> Cómo crear un <em>tibble</em> usando <code>tibble</code> en lugar de <code>data.frame</code></a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="tidyverse.html"><a href="tidyverse.html#el-operador-punto"><i class="fa fa-check"></i><b>4.11</b> El operador punto</a></li>
<li class="chapter" data-level="4.12" data-path="tidyverse.html"><a href="tidyverse.html#do"><i class="fa fa-check"></i><b>4.12</b> <code>do</code></a></li>
<li class="chapter" data-level="4.13" data-path="tidyverse.html"><a href="tidyverse.html#el-paquete-purrr"><i class="fa fa-check"></i><b>4.13</b> El paquete <strong>purrr</strong></a></li>
<li class="chapter" data-level="4.14" data-path="tidyverse.html"><a href="tidyverse.html#los-condicionales-de-tidyverse"><i class="fa fa-check"></i><b>4.14</b> Los condicionales de <em>tidyverse</em></a><ul>
<li class="chapter" data-level="4.14.1" data-path="tidyverse.html"><a href="tidyverse.html#case_when"><i class="fa fa-check"></i><b>4.14.1</b> <code>case_when</code></a></li>
<li class="chapter" data-level="4.14.2" data-path="tidyverse.html"><a href="tidyverse.html#between"><i class="fa fa-check"></i><b>4.14.2</b> <code>between</code></a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="tidyverse.html"><a href="tidyverse.html#ejercicios-12"><i class="fa fa-check"></i><b>4.15</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>5</b> Importando datos</a><ul>
<li class="chapter" data-level="5.1" data-path="importing-data.html"><a href="importing-data.html#las-rutas-y-el-directorio-de-trabajo"><i class="fa fa-check"></i><b>5.1</b> Las rutas y el directorio de trabajo</a><ul>
<li class="chapter" data-level="5.1.1" data-path="importing-data.html"><a href="importing-data.html#el-sistema-de-archivos"><i class="fa fa-check"></i><b>5.1.1</b> El sistema de archivos</a></li>
<li class="chapter" data-level="5.1.2" data-path="importing-data.html"><a href="importing-data.html#las-rutas-relativas-y-completas"><i class="fa fa-check"></i><b>5.1.2</b> Las rutas relativas y completas</a></li>
<li class="chapter" data-level="5.1.3" data-path="importing-data.html"><a href="importing-data.html#el-directorio-de-trabajo"><i class="fa fa-check"></i><b>5.1.3</b> El directorio de trabajo</a></li>
<li class="chapter" data-level="5.1.4" data-path="importing-data.html"><a href="importing-data.html#cómo-generar-los-nombres-de-ruta"><i class="fa fa-check"></i><b>5.1.4</b> Cómo generar los nombres de ruta</a></li>
<li class="chapter" data-level="5.1.5" data-path="importing-data.html"><a href="importing-data.html#cómo-copiar-los-archivos-usando-rutas"><i class="fa fa-check"></i><b>5.1.5</b> Cómo copiar los archivos usando rutas</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importing-data.html"><a href="importing-data.html#los-paquetes-readr-y-readxl"><i class="fa fa-check"></i><b>5.2</b> Los paquetes readr y readxl</a><ul>
<li class="chapter" data-level="5.2.1" data-path="importing-data.html"><a href="importing-data.html#readr"><i class="fa fa-check"></i><b>5.2.1</b> readr</a></li>
<li class="chapter" data-level="5.2.2" data-path="importing-data.html"><a href="importing-data.html#readxl"><i class="fa fa-check"></i><b>5.2.2</b> readxl</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="importing-data.html"><a href="importing-data.html#ejercicios-13"><i class="fa fa-check"></i><b>5.3</b> Ejercicios</a></li>
<li class="chapter" data-level="5.4" data-path="importing-data.html"><a href="importing-data.html#cómo-descargar-archivos"><i class="fa fa-check"></i><b>5.4</b> Cómo descargar archivos</a></li>
<li class="chapter" data-level="5.5" data-path="importing-data.html"><a href="importing-data.html#las-funciones-de-importación-de-base-r"><i class="fa fa-check"></i><b>5.5</b> Las funciones de importación de base R</a><ul>
<li class="chapter" data-level="5.5.1" data-path="importing-data.html"><a href="importing-data.html#scan"><i class="fa fa-check"></i><b>5.5.1</b> <code>scan</code></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="importing-data.html"><a href="importing-data.html#archivos-de-texto-versus-archivos-binarios"><i class="fa fa-check"></i><b>5.6</b> Archivos de texto versus archivos binarios</a></li>
<li class="chapter" data-level="5.7" data-path="importing-data.html"><a href="importing-data.html#unicode-versus-ascii"><i class="fa fa-check"></i><b>5.7</b> Unicode versus ASCII</a></li>
<li class="chapter" data-level="5.8" data-path="importing-data.html"><a href="importing-data.html#cómo-organizar-datos-con-hojas-de-cálculo"><i class="fa fa-check"></i><b>5.8</b> Cómo organizar datos con hojas de cálculo</a></li>
<li class="chapter" data-level="5.9" data-path="importing-data.html"><a href="importing-data.html#ejercicios-14"><i class="fa fa-check"></i><b>5.9</b> Ejercicios</a></li>
</ul></li>
<li class="part"><span><b>II Visualización de datos</b></span></li>
<li class="chapter" data-level="6" data-path="introducción-a-la-visualización-de-datos.html"><a href="introducción-a-la-visualización-de-datos.html"><i class="fa fa-check"></i><b>6</b> Introducción a la visualización de datos</a></li>
<li class="chapter" data-level="7" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i><b>7</b> ggplot2</a><ul>
<li class="chapter" data-level="7.1" data-path="ggplot2.html"><a href="ggplot2.html#los-componentes-de-un-gráfico"><i class="fa fa-check"></i><b>7.1</b> Los componentes de un gráfico</a></li>
<li class="chapter" data-level="7.2" data-path="ggplot2.html"><a href="ggplot2.html#objetos-ggplot"><i class="fa fa-check"></i><b>7.2</b> objetos <code>ggplot</code></a></li>
<li class="chapter" data-level="7.3" data-path="ggplot2.html"><a href="ggplot2.html#geometrías"><i class="fa fa-check"></i><b>7.3</b> Geometrías</a></li>
<li class="chapter" data-level="7.4" data-path="ggplot2.html"><a href="ggplot2.html#mapeos-estéticos"><i class="fa fa-check"></i><b>7.4</b> Mapeos estéticos</a></li>
<li class="chapter" data-level="7.5" data-path="ggplot2.html"><a href="ggplot2.html#capas"><i class="fa fa-check"></i><b>7.5</b> Capas</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ggplot2.html"><a href="ggplot2.html#cómo-probar-varios-argumentos"><i class="fa fa-check"></i><b>7.5.1</b> Cómo probar varios argumentos</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ggplot2.html"><a href="ggplot2.html#mapeos-estéticos-globales-versus-locales"><i class="fa fa-check"></i><b>7.6</b> Mapeos estéticos globales versus locales</a></li>
<li class="chapter" data-level="7.7" data-path="ggplot2.html"><a href="ggplot2.html#escalas"><i class="fa fa-check"></i><b>7.7</b> Escalas</a></li>
<li class="chapter" data-level="7.8" data-path="ggplot2.html"><a href="ggplot2.html#etiquetas-y-títulos"><i class="fa fa-check"></i><b>7.8</b> Etiquetas y títulos</a></li>
<li class="chapter" data-level="7.9" data-path="ggplot2.html"><a href="ggplot2.html#categorías-como-colores"><i class="fa fa-check"></i><b>7.9</b> Categorías como colores</a></li>
<li class="chapter" data-level="7.10" data-path="ggplot2.html"><a href="ggplot2.html#anotación-formas-y-ajustes"><i class="fa fa-check"></i><b>7.10</b> Anotación, formas y ajustes</a></li>
<li class="chapter" data-level="7.11" data-path="ggplot2.html"><a href="ggplot2.html#add-on-packages"><i class="fa fa-check"></i><b>7.11</b> Paquetes complementarios</a></li>
<li class="chapter" data-level="7.12" data-path="ggplot2.html"><a href="ggplot2.html#cómo-combinarlo-todo"><i class="fa fa-check"></i><b>7.12</b> Cómo combinarlo todo</a></li>
<li class="chapter" data-level="7.13" data-path="ggplot2.html"><a href="ggplot2.html#qplot"><i class="fa fa-check"></i><b>7.13</b> Gráficos rápidos con <code>qplot</code></a></li>
<li class="chapter" data-level="7.14" data-path="ggplot2.html"><a href="ggplot2.html#cuadrículas-de-gráficos"><i class="fa fa-check"></i><b>7.14</b> Cuadrículas de gráficos</a></li>
<li class="chapter" data-level="7.15" data-path="ggplot2.html"><a href="ggplot2.html#ejercicios-15"><i class="fa fa-check"></i><b>7.15</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>8</b> Cómo visualizar distribuciones de datos</a><ul>
<li class="chapter" data-level="8.1" data-path="distributions.html"><a href="distributions.html#tipos-de-variables"><i class="fa fa-check"></i><b>8.1</b> Tipos de variables</a></li>
<li class="chapter" data-level="8.2" data-path="distributions.html"><a href="distributions.html#estudio-de-caso-describiendo-alturas-de-estudiantes"><i class="fa fa-check"></i><b>8.2</b> Estudio de caso: describiendo alturas de estudiantes</a></li>
<li class="chapter" data-level="8.3" data-path="distributions.html"><a href="distributions.html#la-función-de-distribución"><i class="fa fa-check"></i><b>8.3</b> La función de distribución</a></li>
<li class="chapter" data-level="8.4" data-path="distributions.html"><a href="distributions.html#cdf-intro"><i class="fa fa-check"></i><b>8.4</b> Funciones de distribución acumulada</a></li>
<li class="chapter" data-level="8.5" data-path="distributions.html"><a href="distributions.html#histogramas"><i class="fa fa-check"></i><b>8.5</b> Histogramas</a></li>
<li class="chapter" data-level="8.6" data-path="distributions.html"><a href="distributions.html#densidad-suave"><i class="fa fa-check"></i><b>8.6</b> Densidad suave</a><ul>
<li class="chapter" data-level="8.6.1" data-path="distributions.html"><a href="distributions.html#cómo-interpretar-el-eje-y"><i class="fa fa-check"></i><b>8.6.1</b> Cómo interpretar el eje-y</a></li>
<li class="chapter" data-level="8.6.2" data-path="distributions.html"><a href="distributions.html#densidades-permiten-estratificación"><i class="fa fa-check"></i><b>8.6.2</b> Densidades permiten estratificación</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="distributions.html"><a href="distributions.html#ejercicios-16"><i class="fa fa-check"></i><b>8.7</b> Ejercicios</a></li>
<li class="chapter" data-level="8.8" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>8.8</b> La distribución normal</a></li>
<li class="chapter" data-level="8.9" data-path="distributions.html"><a href="distributions.html#unidades-estándar"><i class="fa fa-check"></i><b>8.9</b> Unidades estándar</a></li>
<li class="chapter" data-level="8.10" data-path="distributions.html"><a href="distributions.html#gráficos-q-q"><i class="fa fa-check"></i><b>8.10</b> Gráficos Q-Q</a></li>
<li class="chapter" data-level="8.11" data-path="distributions.html"><a href="distributions.html#percentiles"><i class="fa fa-check"></i><b>8.11</b> Percentiles</a></li>
<li class="chapter" data-level="8.12" data-path="distributions.html"><a href="distributions.html#diagramas-de-caja"><i class="fa fa-check"></i><b>8.12</b> Diagramas de caja</a></li>
<li class="chapter" data-level="8.13" data-path="distributions.html"><a href="distributions.html#stratification"><i class="fa fa-check"></i><b>8.13</b> Estratificación</a></li>
<li class="chapter" data-level="8.14" data-path="distributions.html"><a href="distributions.html#student-height-cont"><i class="fa fa-check"></i><b>8.14</b> Estudio de caso: descripción de alturas de estudiantes (continuación)</a></li>
<li class="chapter" data-level="8.15" data-path="distributions.html"><a href="distributions.html#ejercicios-17"><i class="fa fa-check"></i><b>8.15</b> Ejercicios</a></li>
<li class="chapter" data-level="8.16" data-path="distributions.html"><a href="distributions.html#other-geometries"><i class="fa fa-check"></i><b>8.16</b> Geometrías ggplot2</a><ul>
<li class="chapter" data-level="8.16.1" data-path="distributions.html"><a href="distributions.html#diagramas-de-barras"><i class="fa fa-check"></i><b>8.16.1</b> Diagramas de barras</a></li>
<li class="chapter" data-level="8.16.2" data-path="distributions.html"><a href="distributions.html#histogramas-1"><i class="fa fa-check"></i><b>8.16.2</b> Histogramas</a></li>
<li class="chapter" data-level="8.16.3" data-path="distributions.html"><a href="distributions.html#gráficos-de-densidad"><i class="fa fa-check"></i><b>8.16.3</b> Gráficos de densidad</a></li>
<li class="chapter" data-level="8.16.4" data-path="distributions.html"><a href="distributions.html#diagramas-de-caja-1"><i class="fa fa-check"></i><b>8.16.4</b> Diagramas de caja</a></li>
<li class="chapter" data-level="8.16.5" data-path="distributions.html"><a href="distributions.html#gráficos-q-q-1"><i class="fa fa-check"></i><b>8.16.5</b> Gráficos Q-Q</a></li>
<li class="chapter" data-level="8.16.6" data-path="distributions.html"><a href="distributions.html#imágenes"><i class="fa fa-check"></i><b>8.16.6</b> Imágenes</a></li>
<li class="chapter" data-level="8.16.7" data-path="distributions.html"><a href="distributions.html#gráficos-rápidos"><i class="fa fa-check"></i><b>8.16.7</b> Gráficos rápidos</a></li>
</ul></li>
<li class="chapter" data-level="8.17" data-path="distributions.html"><a href="distributions.html#ejercicios-18"><i class="fa fa-check"></i><b>8.17</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>9</b> Visualización de datos en la práctica</a><ul>
<li class="chapter" data-level="9.1" data-path="gapminder.html"><a href="gapminder.html#estudio-de-caso-nuevas-ideas-sobre-la-pobreza"><i class="fa fa-check"></i><b>9.1</b> Estudio de caso: nuevas ideas sobre la pobreza</a><ul>
<li class="chapter" data-level="9.1.1" data-path="gapminder.html"><a href="gapminder.html#la-prueba-de-hans-rosling"><i class="fa fa-check"></i><b>9.1.1</b> La prueba de Hans Rosling</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="gapminder.html"><a href="gapminder.html#diagrama-de-dispersión"><i class="fa fa-check"></i><b>9.2</b> Diagrama de dispersión</a></li>
<li class="chapter" data-level="9.3" data-path="gapminder.html"><a href="gapminder.html#separar-en-facetas"><i class="fa fa-check"></i><b>9.3</b> Separar en facetas</a><ul>
<li class="chapter" data-level="9.3.1" data-path="gapminder.html"><a href="gapminder.html#facet_wrap"><i class="fa fa-check"></i><b>9.3.1</b> <code>facet_wrap</code></a></li>
<li class="chapter" data-level="9.3.2" data-path="gapminder.html"><a href="gapminder.html#escalas-fijas-para-mejores-comparaciones"><i class="fa fa-check"></i><b>9.3.2</b> Escalas fijas para mejores comparaciones</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="gapminder.html"><a href="gapminder.html#gráficos-de-series-de-tiempo"><i class="fa fa-check"></i><b>9.4</b> Gráficos de series de tiempo</a><ul>
<li class="chapter" data-level="9.4.1" data-path="gapminder.html"><a href="gapminder.html#etiquetas-en-lugar-de-leyendas"><i class="fa fa-check"></i><b>9.4.1</b> Etiquetas en lugar de leyendas</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="gapminder.html"><a href="gapminder.html#transformaciones-de-datos"><i class="fa fa-check"></i><b>9.5</b> Transformaciones de datos</a><ul>
<li class="chapter" data-level="9.5.1" data-path="gapminder.html"><a href="gapminder.html#transformación-logarítmica"><i class="fa fa-check"></i><b>9.5.1</b> Transformación logarítmica</a></li>
<li class="chapter" data-level="9.5.2" data-path="gapminder.html"><a href="gapminder.html#qué-base"><i class="fa fa-check"></i><b>9.5.2</b> ¿Qué base?</a></li>
<li class="chapter" data-level="9.5.3" data-path="gapminder.html"><a href="gapminder.html#transformar-los-valores-o-la-escala"><i class="fa fa-check"></i><b>9.5.3</b> ¿Transformar los valores o la escala?</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="gapminder.html"><a href="gapminder.html#cómo-visualizar-distribuciones-multimodales"><i class="fa fa-check"></i><b>9.6</b> Cómo visualizar distribuciones multimodales</a></li>
<li class="chapter" data-level="9.7" data-path="gapminder.html"><a href="gapminder.html#cómo-comparar-múltiples-distribuciones-con-diagramas-de-caja-y-gráficos-ridge"><i class="fa fa-check"></i><b>9.7</b> Cómo comparar múltiples distribuciones con diagramas de caja y gráficos <em>ridge</em></a><ul>
<li class="chapter" data-level="9.7.1" data-path="gapminder.html"><a href="gapminder.html#diagrama-de-caja"><i class="fa fa-check"></i><b>9.7.1</b> Diagrama de caja</a></li>
<li class="chapter" data-level="9.7.2" data-path="gapminder.html"><a href="gapminder.html#gráficos-ridge"><i class="fa fa-check"></i><b>9.7.2</b> Gráficos <em>ridge</em></a></li>
<li class="chapter" data-level="9.7.3" data-path="gapminder.html"><a href="gapminder.html#ejemplo-distribuciones-de-ingresos-de-1970-versus-2010"><i class="fa fa-check"></i><b>9.7.3</b> Ejemplo: distribuciones de ingresos de 1970 versus 2010</a></li>
<li class="chapter" data-level="9.7.4" data-path="gapminder.html"><a href="gapminder.html#cómo-obtener-acceso-a-variables-calculadas"><i class="fa fa-check"></i><b>9.7.4</b> Cómo obtener acceso a variables calculadas</a></li>
<li class="chapter" data-level="9.7.5" data-path="gapminder.html"><a href="gapminder.html#densidades-ponderadas"><i class="fa fa-check"></i><b>9.7.5</b> Densidades ponderadas</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="gapminder.html"><a href="gapminder.html#la-falacia-ecológica-y-la-importancia-de-mostrar-los-datos"><i class="fa fa-check"></i><b>9.8</b> La falacia ecológica y la importancia de mostrar los datos</a><ul>
<li class="chapter" data-level="9.8.1" data-path="gapminder.html"><a href="gapminder.html#logit"><i class="fa fa-check"></i><b>9.8.1</b> Transformación logística</a></li>
<li class="chapter" data-level="9.8.2" data-path="gapminder.html"><a href="gapminder.html#mostrar-los-datos"><i class="fa fa-check"></i><b>9.8.2</b> Mostrar los datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html"><i class="fa fa-check"></i><b>10</b> Principios de visualización de datos</a><ul>
<li class="chapter" data-level="10.1" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#cómo-codificar-datos-utilizando-señales-visuales"><i class="fa fa-check"></i><b>10.1</b> Cómo codificar datos utilizando señales visuales</a></li>
<li class="chapter" data-level="10.2" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#sepa-cuándo-incluir-0"><i class="fa fa-check"></i><b>10.2</b> Sepa cuándo incluir 0</a></li>
<li class="chapter" data-level="10.3" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#no-distorsionar-cantidades"><i class="fa fa-check"></i><b>10.3</b> No distorsionar cantidades</a></li>
<li class="chapter" data-level="10.4" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#ordenar-categorías-por-un-valor-significativo"><i class="fa fa-check"></i><b>10.4</b> Ordenar categorías por un valor significativo</a></li>
<li class="chapter" data-level="10.5" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#mostrar-los-datos-1"><i class="fa fa-check"></i><b>10.5</b> Mostrar los datos</a></li>
<li class="chapter" data-level="10.6" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#cómo-facilitar-comparaciones"><i class="fa fa-check"></i><b>10.6</b> Cómo facilitar comparaciones</a><ul>
<li class="chapter" data-level="10.6.1" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#use-ejes-comunes"><i class="fa fa-check"></i><b>10.6.1</b> Use ejes comunes</a></li>
<li class="chapter" data-level="10.6.2" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#alinee-gráficos-verticalmente-para-ver-cambios-horizontales-y-horizontalmente-para-ver-cambios-verticales"><i class="fa fa-check"></i><b>10.6.2</b> Alinee gráficos verticalmente para ver cambios horizontales y horizontalmente para ver cambios verticales</a></li>
<li class="chapter" data-level="10.6.3" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#considere-transformaciones"><i class="fa fa-check"></i><b>10.6.3</b> Considere transformaciones</a></li>
<li class="chapter" data-level="10.6.4" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#señales-visuales-comparadas-deben-estar-adyacentes"><i class="fa fa-check"></i><b>10.6.4</b> Señales visuales comparadas deben estar adyacentes</a></li>
<li class="chapter" data-level="10.6.5" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#use-color"><i class="fa fa-check"></i><b>10.6.5</b> Use color</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#piense-en-los-daltónicos"><i class="fa fa-check"></i><b>10.7</b> Piense en los daltónicos</a></li>
<li class="chapter" data-level="10.8" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#gráficos-para-dos-variables"><i class="fa fa-check"></i><b>10.8</b> Gráficos para dos variables</a><ul>
<li class="chapter" data-level="10.8.1" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#slope-charts"><i class="fa fa-check"></i><b>10.8.1</b> Slope charts</a></li>
<li class="chapter" data-level="10.8.2" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#gráfico-bland-altman"><i class="fa fa-check"></i><b>10.8.2</b> Gráfico Bland-Altman</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#cómo-codificar-una-tercera-variable"><i class="fa fa-check"></i><b>10.9</b> Cómo codificar una tercera variable</a></li>
<li class="chapter" data-level="10.10" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#evite-los-gráficos-pseudo-tridimensionales"><i class="fa fa-check"></i><b>10.10</b> Evite los gráficos pseudo-tridimensionales</a></li>
<li class="chapter" data-level="10.11" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#evite-demasiados-dígitos-significativos"><i class="fa fa-check"></i><b>10.11</b> Evite demasiados dígitos significativos</a></li>
<li class="chapter" data-level="10.12" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#conozca-a-su-audiencia"><i class="fa fa-check"></i><b>10.12</b> Conozca a su audiencia</a></li>
<li class="chapter" data-level="10.13" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#ejercicios-19"><i class="fa fa-check"></i><b>10.13</b> Ejercicios</a></li>
<li class="chapter" data-level="10.14" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#vaccines"><i class="fa fa-check"></i><b>10.14</b> Estudio de caso: las vacunas y las enfermedades infecciosas</a></li>
<li class="chapter" data-level="10.15" data-path="principios-de-visualización-de-datos.html"><a href="principios-de-visualización-de-datos.html#ejercicios-20"><i class="fa fa-check"></i><b>10.15</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="robust-summaries.html"><a href="robust-summaries.html"><i class="fa fa-check"></i><b>11</b> Resúmenes robustos</a><ul>
<li class="chapter" data-level="11.1" data-path="robust-summaries.html"><a href="robust-summaries.html#valores-atípicos"><i class="fa fa-check"></i><b>11.1</b> Valores atípicos</a></li>
<li class="chapter" data-level="11.2" data-path="robust-summaries.html"><a href="robust-summaries.html#mediana"><i class="fa fa-check"></i><b>11.2</b> Mediana</a></li>
<li class="chapter" data-level="11.3" data-path="robust-summaries.html"><a href="robust-summaries.html#el-rango-intercuartil-iqr"><i class="fa fa-check"></i><b>11.3</b> El rango intercuartil (IQR)</a></li>
<li class="chapter" data-level="11.4" data-path="robust-summaries.html"><a href="robust-summaries.html#la-definición-de-tukey-de-un-valor-atípico"><i class="fa fa-check"></i><b>11.4</b> La definición de Tukey de un valor atípico</a></li>
<li class="chapter" data-level="11.5" data-path="robust-summaries.html"><a href="robust-summaries.html#desviación-absoluta-mediana"><i class="fa fa-check"></i><b>11.5</b> Desviación absoluta mediana</a></li>
<li class="chapter" data-level="11.6" data-path="robust-summaries.html"><a href="robust-summaries.html#ejercicios-21"><i class="fa fa-check"></i><b>11.6</b> Ejercicios</a></li>
<li class="chapter" data-level="11.7" data-path="robust-summaries.html"><a href="robust-summaries.html#estudio-de-caso-alturas-autoreportadas-de-estudiantes"><i class="fa fa-check"></i><b>11.7</b> Estudio de caso: alturas autoreportadas de estudiantes</a></li>
</ul></li>
<li class="part"><span><b>III Estadísticas con R</b></span></li>
<li class="chapter" data-level="12" data-path="introducción-a-las-estadísticas-con-r.html"><a href="introducción-a-las-estadísticas-con-r.html"><i class="fa fa-check"></i><b>12</b> Introducción a las estadísticas con R</a></li>
<li class="chapter" data-level="13" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>13</b> Probabilidad</a><ul>
<li class="chapter" data-level="13.1" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-discreta"><i class="fa fa-check"></i><b>13.1</b> Probabilidad discreta</a><ul>
<li class="chapter" data-level="13.1.1" data-path="probabilidad.html"><a href="probabilidad.html#frecuencia-relativa"><i class="fa fa-check"></i><b>13.1.1</b> Frecuencia relativa</a></li>
<li class="chapter" data-level="13.1.2" data-path="probabilidad.html"><a href="probabilidad.html#notación"><i class="fa fa-check"></i><b>13.1.2</b> Notación</a></li>
<li class="chapter" data-level="13.1.3" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>13.1.3</b> Distribuciones de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="probabilidad.html"><a href="probabilidad.html#simulaciones-monte-carlo-para-datos-categóricos"><i class="fa fa-check"></i><b>13.2</b> Simulaciones Monte Carlo para datos categóricos</a><ul>
<li class="chapter" data-level="13.2.1" data-path="probabilidad.html"><a href="probabilidad.html#fijar-la-semilla-aleatoria"><i class="fa fa-check"></i><b>13.2.1</b> Fijar la semilla aleatoria</a></li>
<li class="chapter" data-level="13.2.2" data-path="probabilidad.html"><a href="probabilidad.html#con-y-sin-reemplazo"><i class="fa fa-check"></i><b>13.2.2</b> Con y sin reemplazo</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="probabilidad.html"><a href="probabilidad.html#independencia"><i class="fa fa-check"></i><b>13.3</b> Independencia</a></li>
<li class="chapter" data-level="13.4" data-path="probabilidad.html"><a href="probabilidad.html#probabilidades-condicionales"><i class="fa fa-check"></i><b>13.4</b> Probabilidades condicionales</a></li>
<li class="chapter" data-level="13.5" data-path="probabilidad.html"><a href="probabilidad.html#reglas-de-la-adición-y-de-la-multiplicación"><i class="fa fa-check"></i><b>13.5</b> Reglas de la adición y de la multiplicación</a><ul>
<li class="chapter" data-level="13.5.1" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-multiplicación"><i class="fa fa-check"></i><b>13.5.1</b> Regla de la multiplicación</a></li>
<li class="chapter" data-level="13.5.2" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-multiplicación-bajo-independencia"><i class="fa fa-check"></i><b>13.5.2</b> Regla de la multiplicación bajo independencia</a></li>
<li class="chapter" data-level="13.5.3" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-adición"><i class="fa fa-check"></i><b>13.5.3</b> Regla de la adición</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="probabilidad.html"><a href="probabilidad.html#combinaciones-y-permutaciones"><i class="fa fa-check"></i><b>13.6</b> Combinaciones y permutaciones</a><ul>
<li class="chapter" data-level="13.6.1" data-path="probabilidad.html"><a href="probabilidad.html#ejemplo-monte-carlo"><i class="fa fa-check"></i><b>13.6.1</b> Ejemplo Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="probabilidad.html"><a href="probabilidad.html#ejemplos"><i class="fa fa-check"></i><b>13.7</b> Ejemplos</a><ul>
<li class="chapter" data-level="13.7.1" data-path="probabilidad.html"><a href="probabilidad.html#problema-monty-hall"><i class="fa fa-check"></i><b>13.7.1</b> Problema Monty Hall</a></li>
<li class="chapter" data-level="13.7.2" data-path="probabilidad.html"><a href="probabilidad.html#problema-de-cumpleaños"><i class="fa fa-check"></i><b>13.7.2</b> Problema de cumpleaños</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="probabilidad.html"><a href="probabilidad.html#infinito-en-la-práctica"><i class="fa fa-check"></i><b>13.8</b> Infinito en la práctica</a></li>
<li class="chapter" data-level="13.9" data-path="probabilidad.html"><a href="probabilidad.html#ejercicios-22"><i class="fa fa-check"></i><b>13.9</b> Ejercicios</a></li>
<li class="chapter" data-level="13.10" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-continua"><i class="fa fa-check"></i><b>13.10</b> Probabilidad continua</a></li>
<li class="chapter" data-level="13.11" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-teóricas-continuas"><i class="fa fa-check"></i><b>13.11</b> Distribuciones teóricas continuas</a><ul>
<li class="chapter" data-level="13.11.1" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-teóricas-como-aproximaciones"><i class="fa fa-check"></i><b>13.11.1</b> Distribuciones teóricas como aproximaciones</a></li>
<li class="chapter" data-level="13.11.2" data-path="probabilidad.html"><a href="probabilidad.html#la-densidad-de-probabilidad"><i class="fa fa-check"></i><b>13.11.2</b> La densidad de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="13.12" data-path="probabilidad.html"><a href="probabilidad.html#simulaciones-monte-carlo-para-variables-continuas"><i class="fa fa-check"></i><b>13.12</b> Simulaciones Monte Carlo para variables continuas</a></li>
<li class="chapter" data-level="13.13" data-path="probabilidad.html"><a href="probabilidad.html#distribuciones-continuas"><i class="fa fa-check"></i><b>13.13</b> Distribuciones continuas</a></li>
<li class="chapter" data-level="13.14" data-path="probabilidad.html"><a href="probabilidad.html#ejercicios-23"><i class="fa fa-check"></i><b>13.14</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>14</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="14.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-1"><i class="fa fa-check"></i><b>14.1</b> Variables aleatorias</a></li>
<li class="chapter" data-level="14.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#modelos-de-muestreo"><i class="fa fa-check"></i><b>14.2</b> Modelos de muestreo</a></li>
<li class="chapter" data-level="14.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#la-distribución-de-probabilidad-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>14.3</b> La distribución de probabilidad de una variable aleatoria</a></li>
<li class="chapter" data-level="14.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#distribuciones-versus-distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>14.4</b> Distribuciones versus distribuciones de probabilidad</a></li>
<li class="chapter" data-level="14.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#notación-para-variables-aleatorias"><i class="fa fa-check"></i><b>14.5</b> Notación para variables aleatorias</a></li>
<li class="chapter" data-level="14.6" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#el-valor-esperado-y-el-error-estándar"><i class="fa fa-check"></i><b>14.6</b> El valor esperado y el error estándar</a><ul>
<li class="chapter" data-level="14.6.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#población-sd-versus-la-muestra-sd"><i class="fa fa-check"></i><b>14.6.1</b> Población SD versus la muestra SD</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#teorema-del-límite-central"><i class="fa fa-check"></i><b>14.7</b> Teorema del límite central</a><ul>
<li class="chapter" data-level="14.7.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#cuán-grande-es-grande-en-el-teorema-del-límite-central"><i class="fa fa-check"></i><b>14.7.1</b> ¿Cuán grande es grande en el teorema del límite central?</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#propiedades-estadísticas-de-promedios"><i class="fa fa-check"></i><b>14.8</b> Propiedades estadísticas de promedios</a></li>
<li class="chapter" data-level="14.9" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#ley-de-los-grandes-números"><i class="fa fa-check"></i><b>14.9</b> Ley de los grandes números</a><ul>
<li class="chapter" data-level="14.9.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#malinterpretando-la-ley-de-promedios"><i class="fa fa-check"></i><b>14.9.1</b> Malinterpretando la ley de promedios</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#ejercicios-24"><i class="fa fa-check"></i><b>14.10</b> Ejercicios</a></li>
<li class="chapter" data-level="14.11" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#estudio-de-caso-the-big-short"><i class="fa fa-check"></i><b>14.11</b> Estudio de caso: The Big Short</a><ul>
<li class="chapter" data-level="14.11.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#tasas-de-interés-explicadas-con-modelo-de-oportunidad"><i class="fa fa-check"></i><b>14.11.1</b> Tasas de interés explicadas con modelo de oportunidad</a></li>
<li class="chapter" data-level="14.11.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#the-big-short"><i class="fa fa-check"></i><b>14.11.2</b> The Big Short</a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#ejercicios-25"><i class="fa fa-check"></i><b>14.12</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>15</b> Inferencia estadística</a><ul>
<li class="chapter" data-level="15.1" data-path="inference.html"><a href="inference.html#encuestas"><i class="fa fa-check"></i><b>15.1</b> Encuestas</a><ul>
<li class="chapter" data-level="15.1.1" data-path="inference.html"><a href="inference.html#el-modelo-de-muestreo-para-encuestas"><i class="fa fa-check"></i><b>15.1.1</b> El modelo de muestreo para encuestas</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="inference.html"><a href="inference.html#poblaciones-muestras-parámetros-y-estimaciones"><i class="fa fa-check"></i><b>15.2</b> Poblaciones, muestras, parámetros y estimaciones</a><ul>
<li class="chapter" data-level="15.2.1" data-path="inference.html"><a href="inference.html#el-promedio-de-la-muestra"><i class="fa fa-check"></i><b>15.2.1</b> El promedio de la muestra</a></li>
<li class="chapter" data-level="15.2.2" data-path="inference.html"><a href="inference.html#parámetros"><i class="fa fa-check"></i><b>15.2.2</b> Parámetros</a></li>
<li class="chapter" data-level="15.2.3" data-path="inference.html"><a href="inference.html#encuesta-versus-pronóstico"><i class="fa fa-check"></i><b>15.2.3</b> Encuesta versus pronóstico</a></li>
<li class="chapter" data-level="15.2.4" data-path="inference.html"><a href="inference.html#propiedades-de-nuestra-estimación-valor-esperado-y-error-estándar"><i class="fa fa-check"></i><b>15.2.4</b> Propiedades de nuestra estimación: valor esperado y error estándar</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="inference.html"><a href="inference.html#ejercicios-26"><i class="fa fa-check"></i><b>15.3</b> Ejercicios</a></li>
<li class="chapter" data-level="15.4" data-path="inference.html"><a href="inference.html#clt"><i class="fa fa-check"></i><b>15.4</b> Teorema del límite central en la práctica</a><ul>
<li class="chapter" data-level="15.4.1" data-path="inference.html"><a href="inference.html#una-simulación-monte-carlo"><i class="fa fa-check"></i><b>15.4.1</b> Una simulación Monte Carlo</a></li>
<li class="chapter" data-level="15.4.2" data-path="inference.html"><a href="inference.html#la-diferencia"><i class="fa fa-check"></i><b>15.4.2</b> La diferencia</a></li>
<li class="chapter" data-level="15.4.3" data-path="inference.html"><a href="inference.html#sesgo-por-qué-no-realizar-una-encuesta-bien-grande"><i class="fa fa-check"></i><b>15.4.3</b> Sesgo: ¿por qué no realizar una encuesta bien grande?</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="inference.html"><a href="inference.html#ejercicios-27"><i class="fa fa-check"></i><b>15.5</b> Ejercicios</a></li>
<li class="chapter" data-level="15.6" data-path="inference.html"><a href="inference.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>15.6</b> Intervalos de confianza</a><ul>
<li class="chapter" data-level="15.6.1" data-path="inference.html"><a href="inference.html#una-simulación-monte-carlo-1"><i class="fa fa-check"></i><b>15.6.1</b> Una simulación Monte Carlo</a></li>
<li class="chapter" data-level="15.6.2" data-path="inference.html"><a href="inference.html#el-idioma-correcto"><i class="fa fa-check"></i><b>15.6.2</b> El idioma correcto</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="inference.html"><a href="inference.html#ejercicios-28"><i class="fa fa-check"></i><b>15.7</b> Ejercicios</a></li>
<li class="chapter" data-level="15.8" data-path="inference.html"><a href="inference.html#poder"><i class="fa fa-check"></i><b>15.8</b> Poder</a></li>
<li class="chapter" data-level="15.9" data-path="inference.html"><a href="inference.html#valores-p"><i class="fa fa-check"></i><b>15.9</b> valores p</a></li>
<li class="chapter" data-level="15.10" data-path="inference.html"><a href="inference.html#association-tests"><i class="fa fa-check"></i><b>15.10</b> Pruebas de asociación</a><ul>
<li class="chapter" data-level="15.10.1" data-path="inference.html"><a href="inference.html#lady-tasting-tea"><i class="fa fa-check"></i><b>15.10.1</b> Lady Tasting Tea</a></li>
<li class="chapter" data-level="15.10.2" data-path="inference.html"><a href="inference.html#tablas-2x2"><i class="fa fa-check"></i><b>15.10.2</b> Tablas 2x2</a></li>
<li class="chapter" data-level="15.10.3" data-path="inference.html"><a href="inference.html#prueba-de-chi-cuadrado"><i class="fa fa-check"></i><b>15.10.3</b> Prueba de chi-cuadrado</a></li>
<li class="chapter" data-level="15.10.4" data-path="inference.html"><a href="inference.html#odds-ratio"><i class="fa fa-check"></i><b>15.10.4</b> Riesgo relativo</a></li>
<li class="chapter" data-level="15.10.5" data-path="inference.html"><a href="inference.html#intervalos-de-confianza-para-el-riesgo-relativo"><i class="fa fa-check"></i><b>15.10.5</b> Intervalos de confianza para el riesgo relativo</a></li>
<li class="chapter" data-level="15.10.6" data-path="inference.html"><a href="inference.html#corrección-de-recuento-pequeño"><i class="fa fa-check"></i><b>15.10.6</b> Corrección de recuento pequeño</a></li>
<li class="chapter" data-level="15.10.7" data-path="inference.html"><a href="inference.html#muestras-grandes-valores-p-pequeños"><i class="fa fa-check"></i><b>15.10.7</b> Muestras grandes, valores p pequeños</a></li>
</ul></li>
<li class="chapter" data-level="15.11" data-path="inference.html"><a href="inference.html#ejercicios-29"><i class="fa fa-check"></i><b>15.11</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>16</b> Modelos estadísticos</a><ul>
<li class="chapter" data-level="16.1" data-path="models.html"><a href="models.html#agregadores-de-encuestas"><i class="fa fa-check"></i><b>16.1</b> Agregadores de encuestas</a><ul>
<li class="chapter" data-level="16.1.1" data-path="models.html"><a href="models.html#datos-de-encuesta"><i class="fa fa-check"></i><b>16.1.1</b> Datos de encuesta</a></li>
<li class="chapter" data-level="16.1.2" data-path="models.html"><a href="models.html#sesgo-de-los-encuestadores"><i class="fa fa-check"></i><b>16.1.2</b> Sesgo de los encuestadores</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="models.html"><a href="models.html#data-driven-model"><i class="fa fa-check"></i><b>16.2</b> Modelos basados en datos</a></li>
<li class="chapter" data-level="16.3" data-path="models.html"><a href="models.html#ejercicios-30"><i class="fa fa-check"></i><b>16.3</b> Ejercicios</a></li>
<li class="chapter" data-level="16.4" data-path="models.html"><a href="models.html#bayesian-statistics"><i class="fa fa-check"></i><b>16.4</b> Estadísticas bayesianas</a><ul>
<li class="chapter" data-level="16.4.1" data-path="models.html"><a href="models.html#teorema-de-bayes"><i class="fa fa-check"></i><b>16.4.1</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="models.html"><a href="models.html#simulación-del-teorema-de-bayes"><i class="fa fa-check"></i><b>16.5</b> Simulación del teorema de Bayes</a><ul>
<li class="chapter" data-level="16.5.1" data-path="models.html"><a href="models.html#bayes-en-la-práctica"><i class="fa fa-check"></i><b>16.5.1</b> Bayes en la práctica</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="models.html"><a href="models.html#modelos-jerárquicos"><i class="fa fa-check"></i><b>16.6</b> Modelos jerárquicos</a></li>
<li class="chapter" data-level="16.7" data-path="models.html"><a href="models.html#ejercicios-31"><i class="fa fa-check"></i><b>16.7</b> Ejercicios</a></li>
<li class="chapter" data-level="16.8" data-path="models.html"><a href="models.html#election-forecasting"><i class="fa fa-check"></i><b>16.8</b> Estudio de caso: pronóstico de elecciones</a><ul>
<li class="chapter" data-level="16.8.1" data-path="models.html"><a href="models.html#bayesian-approach"><i class="fa fa-check"></i><b>16.8.1</b> Enfoque bayesiano</a></li>
<li class="chapter" data-level="16.8.2" data-path="models.html"><a href="models.html#el-sesgo-general"><i class="fa fa-check"></i><b>16.8.2</b> El sesgo general</a></li>
<li class="chapter" data-level="16.8.3" data-path="models.html"><a href="models.html#representaciones-matemáticas-de-modelos"><i class="fa fa-check"></i><b>16.8.3</b> Representaciones matemáticas de modelos</a></li>
<li class="chapter" data-level="16.8.4" data-path="models.html"><a href="models.html#prediciendo-el-colegio-electoral"><i class="fa fa-check"></i><b>16.8.4</b> Prediciendo el colegio electoral</a></li>
<li class="chapter" data-level="16.8.5" data-path="models.html"><a href="models.html#pronósticos"><i class="fa fa-check"></i><b>16.8.5</b> Pronósticos</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="models.html"><a href="models.html#ejercicios-32"><i class="fa fa-check"></i><b>16.9</b> Ejercicios</a></li>
<li class="chapter" data-level="16.10" data-path="models.html"><a href="models.html#t-dist"><i class="fa fa-check"></i><b>16.10</b> La distribución t</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>17</b> Regresión</a><ul>
<li class="chapter" data-level="17.1" data-path="regression.html"><a href="regression.html#estudio-de-caso-la-altura-es-hereditaria"><i class="fa fa-check"></i><b>17.1</b> Estudio de caso: ¿la altura es hereditaria?</a></li>
<li class="chapter" data-level="17.2" data-path="regression.html"><a href="regression.html#corr-coef"><i class="fa fa-check"></i><b>17.2</b> El coeficiente de correlación</a><ul>
<li class="chapter" data-level="17.2.1" data-path="regression.html"><a href="regression.html#la-correlación-de-muestra-es-una-variable-aleatoria"><i class="fa fa-check"></i><b>17.2.1</b> La correlación de muestra es una variable aleatoria</a></li>
<li class="chapter" data-level="17.2.2" data-path="regression.html"><a href="regression.html#la-correlación-no-siempre-es-un-resumen-útil"><i class="fa fa-check"></i><b>17.2.2</b> La correlación no siempre es un resumen útil</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="regression.html"><a href="regression.html#conditional-expectation"><i class="fa fa-check"></i><b>17.3</b> Valor esperado condicional</a></li>
<li class="chapter" data-level="17.4" data-path="regression.html"><a href="regression.html#la-línea-de-regresión"><i class="fa fa-check"></i><b>17.4</b> La línea de regresión</a><ul>
<li class="chapter" data-level="17.4.1" data-path="regression.html"><a href="regression.html#regresión-mejora-precisión"><i class="fa fa-check"></i><b>17.4.1</b> Regresión mejora precisión</a></li>
<li class="chapter" data-level="17.4.2" data-path="regression.html"><a href="regression.html#distribución-normal-de-dos-variables-avanzada"><i class="fa fa-check"></i><b>17.4.2</b> Distribución normal de dos variables (avanzada)</a></li>
<li class="chapter" data-level="17.4.3" data-path="regression.html"><a href="regression.html#varianza-explicada"><i class="fa fa-check"></i><b>17.4.3</b> Varianza explicada</a></li>
<li class="chapter" data-level="17.4.4" data-path="regression.html"><a href="regression.html#advertencia-hay-dos-líneas-de-regresión"><i class="fa fa-check"></i><b>17.4.4</b> Advertencia: hay dos líneas de regresión</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="regression.html"><a href="regression.html#ejercicios-33"><i class="fa fa-check"></i><b>17.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="modelos-lineales.html"><a href="modelos-lineales.html"><i class="fa fa-check"></i><b>18</b> Modelos lineales</a><ul>
<li class="chapter" data-level="18.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#estudio-de-caso-moneyball"><i class="fa fa-check"></i><b>18.1</b> Estudio de caso: Moneyball</a><ul>
<li class="chapter" data-level="18.1.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#sabermetrics"><i class="fa fa-check"></i><b>18.1.1</b> Sabermetrics</a></li>
<li class="chapter" data-level="18.1.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#conceptos-básicos-de-béisbol"><i class="fa fa-check"></i><b>18.1.2</b> Conceptos básicos de béisbol</a></li>
<li class="chapter" data-level="18.1.3" data-path="modelos-lineales.html"><a href="modelos-lineales.html#no-hay-premios-para-bb"><i class="fa fa-check"></i><b>18.1.3</b> No hay premios para BB</a></li>
<li class="chapter" data-level="18.1.4" data-path="modelos-lineales.html"><a href="modelos-lineales.html#base-por-bolas-o-bases-robadas"><i class="fa fa-check"></i><b>18.1.4</b> ¿Base por bolas o bases robadas?</a></li>
<li class="chapter" data-level="18.1.5" data-path="modelos-lineales.html"><a href="modelos-lineales.html#regresión-aplicada-a-las-estadísticas-de-béisbol"><i class="fa fa-check"></i><b>18.1.5</b> Regresión aplicada a las estadísticas de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#confusión"><i class="fa fa-check"></i><b>18.2</b> Confusión</a><ul>
<li class="chapter" data-level="18.2.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#entender-confusión-a-través-de-estratificación"><i class="fa fa-check"></i><b>18.2.1</b> Entender confusión a través de estratificación</a></li>
<li class="chapter" data-level="18.2.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#regresión-lineal-múltiple"><i class="fa fa-check"></i><b>18.2.2</b> Regresión lineal múltiple</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="modelos-lineales.html"><a href="modelos-lineales.html#lse"><i class="fa fa-check"></i><b>18.3</b> Estimaciones de mínimos cuadrados</a><ul>
<li class="chapter" data-level="18.3.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#interpretando-modelos-lineales"><i class="fa fa-check"></i><b>18.3.1</b> Interpretando modelos lineales</a></li>
<li class="chapter" data-level="18.3.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#estimaciones-de-mínimos-cuadrados-lse"><i class="fa fa-check"></i><b>18.3.2</b> Estimaciones de mínimos cuadrados (LSE)</a></li>
<li class="chapter" data-level="18.3.3" data-path="modelos-lineales.html"><a href="modelos-lineales.html#la-función-lm"><i class="fa fa-check"></i><b>18.3.3</b> La función <code>lm</code></a></li>
<li class="chapter" data-level="18.3.4" data-path="modelos-lineales.html"><a href="modelos-lineales.html#lse-son-variables-aleatorias"><i class="fa fa-check"></i><b>18.3.4</b> LSE son variables aleatorias</a></li>
<li class="chapter" data-level="18.3.5" data-path="modelos-lineales.html"><a href="modelos-lineales.html#valores-pronosticados-son-variables-aleatorias"><i class="fa fa-check"></i><b>18.3.5</b> Valores pronosticados son variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="modelos-lineales.html"><a href="modelos-lineales.html#ejercicios-34"><i class="fa fa-check"></i><b>18.4</b> Ejercicios</a></li>
<li class="chapter" data-level="18.5" data-path="modelos-lineales.html"><a href="modelos-lineales.html#regresión-lineal-en-el-tidyverse"><i class="fa fa-check"></i><b>18.5</b> Regresión lineal en el tidyverse</a><ul>
<li class="chapter" data-level="18.5.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#el-paquete-broom"><i class="fa fa-check"></i><b>18.5.1</b> El paquete broom</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="modelos-lineales.html"><a href="modelos-lineales.html#ejercicios-35"><i class="fa fa-check"></i><b>18.6</b> Ejercicios</a></li>
<li class="chapter" data-level="18.7" data-path="modelos-lineales.html"><a href="modelos-lineales.html#estudio-de-caso-moneyball-continuación"><i class="fa fa-check"></i><b>18.7</b> Estudio de caso: Moneyball (continuación)</a><ul>
<li class="chapter" data-level="18.7.1" data-path="modelos-lineales.html"><a href="modelos-lineales.html#añadiendo-información-sobre-salario-y-posición"><i class="fa fa-check"></i><b>18.7.1</b> Añadiendo información sobre salario y posición</a></li>
<li class="chapter" data-level="18.7.2" data-path="modelos-lineales.html"><a href="modelos-lineales.html#escoger-nueve-jugadores"><i class="fa fa-check"></i><b>18.7.2</b> Escoger nueve jugadores</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="modelos-lineales.html"><a href="modelos-lineales.html#la-falacia-de-la-regresión"><i class="fa fa-check"></i><b>18.8</b> La falacia de la regresión</a></li>
<li class="chapter" data-level="18.9" data-path="modelos-lineales.html"><a href="modelos-lineales.html#modelos-de-error-de-medición"><i class="fa fa-check"></i><b>18.9</b> Modelos de error de medición</a></li>
<li class="chapter" data-level="18.10" data-path="modelos-lineales.html"><a href="modelos-lineales.html#ejercicios-36"><i class="fa fa-check"></i><b>18.10</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html"><i class="fa fa-check"></i><b>19</b> La asociación no implica causalidad</a><ul>
<li class="chapter" data-level="19.1" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#correlación-espuria"><i class="fa fa-check"></i><b>19.1</b> Correlación espuria</a></li>
<li class="chapter" data-level="19.2" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#valores-atípicos-1"><i class="fa fa-check"></i><b>19.2</b> Valores atípicos</a></li>
<li class="chapter" data-level="19.3" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#inversión-de-causa-y-efecto"><i class="fa fa-check"></i><b>19.3</b> Inversión de causa y efecto</a></li>
<li class="chapter" data-level="19.4" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#factores-de-confusión"><i class="fa fa-check"></i><b>19.4</b> Factores de confusión</a><ul>
<li class="chapter" data-level="19.4.1" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#ejemplo-admisiones-a-la-universidad-de-california-berkeley"><i class="fa fa-check"></i><b>19.4.1</b> Ejemplo: admisiones a la Universidad de California, Berkeley</a></li>
<li class="chapter" data-level="19.4.2" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#confusión-explicada-gráficamente"><i class="fa fa-check"></i><b>19.4.2</b> Confusión explicada gráficamente</a></li>
<li class="chapter" data-level="19.4.3" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#promedio-después-de-estratificar"><i class="fa fa-check"></i><b>19.4.3</b> Promedio después de estratificar</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#la-paradoja-de-simpson"><i class="fa fa-check"></i><b>19.5</b> La paradoja de Simpson</a></li>
<li class="chapter" data-level="19.6" data-path="la-asociación-no-implica-causalidad.html"><a href="la-asociación-no-implica-causalidad.html#ejercicios-37"><i class="fa fa-check"></i><b>19.6</b> Ejercicios</a></li>
</ul></li>
<li class="part"><span><b>IV <em>Wrangling</em> de datos</b></span></li>
<li class="chapter" data-level="20" data-path="introducción-al-wrangling-de-datos.html"><a href="introducción-al-wrangling-de-datos.html"><i class="fa fa-check"></i><b>20</b> Introducción al wrangling de datos</a></li>
<li class="chapter" data-level="21" data-path="cómo-cambiar-el-formato-de-datos.html"><a href="cómo-cambiar-el-formato-de-datos.html"><i class="fa fa-check"></i><b>21</b> Cómo cambiar el formato de datos</a><ul>
<li class="chapter" data-level="21.1" data-path="cómo-cambiar-el-formato-de-datos.html"><a href="cómo-cambiar-el-formato-de-datos.html#gather"><i class="fa fa-check"></i><b>21.1</b> <code>gather</code></a></li>
<li class="chapter" data-level="21.2" data-path="cómo-cambiar-el-formato-de-datos.html"><a href="cómo-cambiar-el-formato-de-datos.html#spread"><i class="fa fa-check"></i><b>21.2</b> <code>spread</code></a></li>
<li class="chapter" data-level="21.3" data-path="cómo-cambiar-el-formato-de-datos.html"><a href="cómo-cambiar-el-formato-de-datos.html#separate"><i class="fa fa-check"></i><b>21.3</b> <code>separate</code></a></li>
<li class="chapter" data-level="21.4" data-path="cómo-cambiar-el-formato-de-datos.html"><a href="cómo-cambiar-el-formato-de-datos.html#unite"><i class="fa fa-check"></i><b>21.4</b> <code>unite</code></a></li>
<li class="chapter" data-level="21.5" data-path="cómo-cambiar-el-formato-de-datos.html"><a href="cómo-cambiar-el-formato-de-datos.html#ejercicios-38"><i class="fa fa-check"></i><b>21.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="unir-tablas.html"><a href="unir-tablas.html"><i class="fa fa-check"></i><b>22</b> Unir tablas</a><ul>
<li class="chapter" data-level="22.1" data-path="unir-tablas.html"><a href="unir-tablas.html#joins"><i class="fa fa-check"></i><b>22.1</b> Joins</a><ul>
<li class="chapter" data-level="22.1.1" data-path="unir-tablas.html"><a href="unir-tablas.html#left-join"><i class="fa fa-check"></i><b>22.1.1</b> Left join</a></li>
<li class="chapter" data-level="22.1.2" data-path="unir-tablas.html"><a href="unir-tablas.html#right-join"><i class="fa fa-check"></i><b>22.1.2</b> Right join</a></li>
<li class="chapter" data-level="22.1.3" data-path="unir-tablas.html"><a href="unir-tablas.html#inner-join"><i class="fa fa-check"></i><b>22.1.3</b> Inner join</a></li>
<li class="chapter" data-level="22.1.4" data-path="unir-tablas.html"><a href="unir-tablas.html#full-join"><i class="fa fa-check"></i><b>22.1.4</b> Full join</a></li>
<li class="chapter" data-level="22.1.5" data-path="unir-tablas.html"><a href="unir-tablas.html#semi-join"><i class="fa fa-check"></i><b>22.1.5</b> Semi join</a></li>
<li class="chapter" data-level="22.1.6" data-path="unir-tablas.html"><a href="unir-tablas.html#anti-join"><i class="fa fa-check"></i><b>22.1.6</b> Anti join</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="unir-tablas.html"><a href="unir-tablas.html#binding"><i class="fa fa-check"></i><b>22.2</b> Binding</a><ul>
<li class="chapter" data-level="22.2.1" data-path="unir-tablas.html"><a href="unir-tablas.html#pegando-columnas"><i class="fa fa-check"></i><b>22.2.1</b> Pegando columnas</a></li>
<li class="chapter" data-level="22.2.2" data-path="unir-tablas.html"><a href="unir-tablas.html#pegando-filas"><i class="fa fa-check"></i><b>22.2.2</b> Pegando filas</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="unir-tablas.html"><a href="unir-tablas.html#operadores-de-sets"><i class="fa fa-check"></i><b>22.3</b> Operadores de sets</a><ul>
<li class="chapter" data-level="22.3.1" data-path="unir-tablas.html"><a href="unir-tablas.html#intersecar"><i class="fa fa-check"></i><b>22.3.1</b> Intersecar</a></li>
<li class="chapter" data-level="22.3.2" data-path="unir-tablas.html"><a href="unir-tablas.html#unión"><i class="fa fa-check"></i><b>22.3.2</b> Unión</a></li>
<li class="chapter" data-level="22.3.3" data-path="unir-tablas.html"><a href="unir-tablas.html#setdiff"><i class="fa fa-check"></i><b>22.3.3</b> <code>setdiff</code></a></li>
<li class="chapter" data-level="22.3.4" data-path="unir-tablas.html"><a href="unir-tablas.html#setequal"><i class="fa fa-check"></i><b>22.3.4</b> <code>setequal</code></a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="unir-tablas.html"><a href="unir-tablas.html#ejercicios-39"><i class="fa fa-check"></i><b>22.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="extracción-de-la-web.html"><a href="extracción-de-la-web.html"><i class="fa fa-check"></i><b>23</b> Extracción de la web</a><ul>
<li class="chapter" data-level="23.1" data-path="extracción-de-la-web.html"><a href="extracción-de-la-web.html#html"><i class="fa fa-check"></i><b>23.1</b> HTML</a></li>
<li class="chapter" data-level="23.2" data-path="extracción-de-la-web.html"><a href="extracción-de-la-web.html#el-paquete-rvest"><i class="fa fa-check"></i><b>23.2</b> El paquete rvest</a></li>
<li class="chapter" data-level="23.3" data-path="extracción-de-la-web.html"><a href="extracción-de-la-web.html#css-selectors"><i class="fa fa-check"></i><b>23.3</b> Selectores CSS</a></li>
<li class="chapter" data-level="23.4" data-path="extracción-de-la-web.html"><a href="extracción-de-la-web.html#json"><i class="fa fa-check"></i><b>23.4</b> JSON</a></li>
<li class="chapter" data-level="23.5" data-path="extracción-de-la-web.html"><a href="extracción-de-la-web.html#ejercicios-40"><i class="fa fa-check"></i><b>23.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html"><i class="fa fa-check"></i><b>24</b> Procesamiento de cadenas</a><ul>
<li class="chapter" data-level="24.1" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#stringr"><i class="fa fa-check"></i><b>24.1</b> El paquete stringr</a></li>
<li class="chapter" data-level="24.2" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#estudio-de-caso-1-datos-de-asesinatos-en-ee.-uu."><i class="fa fa-check"></i><b>24.2</b> Estudio de caso 1: datos de asesinatos en EE. UU.</a></li>
<li class="chapter" data-level="24.3" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#estudio-de-caso-2-alturas-autoreportadas"><i class="fa fa-check"></i><b>24.3</b> Estudio de caso 2: alturas autoreportadas</a></li>
<li class="chapter" data-level="24.4" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#cómo-escapar-al-definir-cadenas"><i class="fa fa-check"></i><b>24.4</b> Cómo <em>escapar</em> al definir cadenas</a></li>
<li class="chapter" data-level="24.5" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#expresiones-regulares"><i class="fa fa-check"></i><b>24.5</b> Expresiones regulares</a><ul>
<li class="chapter" data-level="24.5.1" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#las-cadenas-son-una-expresión-regular"><i class="fa fa-check"></i><b>24.5.1</b> Las cadenas son una expresión regular</a></li>
<li class="chapter" data-level="24.5.2" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#caracteres-especiales"><i class="fa fa-check"></i><b>24.5.2</b> Caracteres especiales</a></li>
<li class="chapter" data-level="24.5.3" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#clases-de-caracteres"><i class="fa fa-check"></i><b>24.5.3</b> Clases de caracteres</a></li>
<li class="chapter" data-level="24.5.4" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#anclas"><i class="fa fa-check"></i><b>24.5.4</b> Anclas</a></li>
<li class="chapter" data-level="24.5.5" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#cuantificadores"><i class="fa fa-check"></i><b>24.5.5</b> Cuantificadores</a></li>
<li class="chapter" data-level="24.5.6" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#espacio-en-blanco-s"><i class="fa fa-check"></i><b>24.5.6</b> Espacio en blanco <code>\s</code></a></li>
<li class="chapter" data-level="24.5.7" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#cuantificadores-1"><i class="fa fa-check"></i><b>24.5.7</b> Cuantificadores: <code>*</code>, <code>?</code>, <code>+</code></a></li>
<li class="chapter" data-level="24.5.8" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#no"><i class="fa fa-check"></i><b>24.5.8</b> No</a></li>
<li class="chapter" data-level="24.5.9" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#groups"><i class="fa fa-check"></i><b>24.5.9</b> Grupos</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#buscar-y-reemplazar-con-expresiones-regulares"><i class="fa fa-check"></i><b>24.6</b> Buscar y reemplazar con expresiones regulares</a><ul>
<li class="chapter" data-level="24.6.1" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#buscar-y-reemplazar-usando-grupos"><i class="fa fa-check"></i><b>24.6.1</b> Buscar y reemplazar usando grupos</a></li>
</ul></li>
<li class="chapter" data-level="24.7" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#probar-y-mejorar"><i class="fa fa-check"></i><b>24.7</b> Probar y mejorar</a></li>
<li class="chapter" data-level="24.8" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#podar"><i class="fa fa-check"></i><b>24.8</b> Podar</a></li>
<li class="chapter" data-level="24.9" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#cambio-de-mayúsculas-o-minúsculas"><i class="fa fa-check"></i><b>24.9</b> Cambio de mayúsculas o minúsculas</a></li>
<li class="chapter" data-level="24.10" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#estudio-de-caso-2-alturas-autoreportadas-continuación"><i class="fa fa-check"></i><b>24.10</b> Estudio de caso 2: alturas autoreportadas (continuación)</a><ul>
<li class="chapter" data-level="24.10.1" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#la-función-extract"><i class="fa fa-check"></i><b>24.10.1</b> La función <code>extract</code></a></li>
<li class="chapter" data-level="24.10.2" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#juntando-todas-la-piezas"><i class="fa fa-check"></i><b>24.10.2</b> Juntando todas la piezas</a></li>
</ul></li>
<li class="chapter" data-level="24.11" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#división-de-cadenas"><i class="fa fa-check"></i><b>24.11</b> División de cadenas</a></li>
<li class="chapter" data-level="24.12" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#estudio-de-caso-3-extracción-de-tablas-de-un-pdf"><i class="fa fa-check"></i><b>24.12</b> Estudio de caso 3: extracción de tablas de un PDF</a></li>
<li class="chapter" data-level="24.13" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#recode"><i class="fa fa-check"></i><b>24.13</b> Recodificación</a></li>
<li class="chapter" data-level="24.14" data-path="procesamiento-de-cadenas.html"><a href="procesamiento-de-cadenas.html#ejercicios-41"><i class="fa fa-check"></i><b>24.14</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="cómo-leer-y-procesar-fechas-y-horas.html"><a href="cómo-leer-y-procesar-fechas-y-horas.html"><i class="fa fa-check"></i><b>25</b> Cómo leer y procesar fechas y horas</a><ul>
<li class="chapter" data-level="25.1" data-path="cómo-leer-y-procesar-fechas-y-horas.html"><a href="cómo-leer-y-procesar-fechas-y-horas.html#el-tipo-de-datos-de-fecha"><i class="fa fa-check"></i><b>25.1</b> El tipo de datos de fecha</a></li>
<li class="chapter" data-level="25.2" data-path="cómo-leer-y-procesar-fechas-y-horas.html"><a href="cómo-leer-y-procesar-fechas-y-horas.html#lubridate"><i class="fa fa-check"></i><b>25.2</b> El paquete lubridate</a></li>
<li class="chapter" data-level="25.3" data-path="cómo-leer-y-procesar-fechas-y-horas.html"><a href="cómo-leer-y-procesar-fechas-y-horas.html#ejercicios-42"><i class="fa fa-check"></i><b>25.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="minería-de-textos.html"><a href="minería-de-textos.html"><i class="fa fa-check"></i><b>26</b> Minería de textos</a><ul>
<li class="chapter" data-level="26.1" data-path="minería-de-textos.html"><a href="minería-de-textos.html#estudio-de-caso-tuits-de-trump"><i class="fa fa-check"></i><b>26.1</b> Estudio de caso: tuits de Trump</a></li>
<li class="chapter" data-level="26.2" data-path="minería-de-textos.html"><a href="minería-de-textos.html#texto-como-datos"><i class="fa fa-check"></i><b>26.2</b> Texto como datos</a></li>
<li class="chapter" data-level="26.3" data-path="minería-de-textos.html"><a href="minería-de-textos.html#análisis-de-sentimiento"><i class="fa fa-check"></i><b>26.3</b> Análisis de sentimiento</a></li>
<li class="chapter" data-level="26.4" data-path="minería-de-textos.html"><a href="minería-de-textos.html#ejercicios-43"><i class="fa fa-check"></i><b>26.4</b> Ejercicios</a></li>
</ul></li>
<li class="part"><span><b>V Machine Learning</b></span></li>
<li class="chapter" data-level="27" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html"><i class="fa fa-check"></i><b>27</b> Introducción a <em>machine learning</em></a><ul>
<li class="chapter" data-level="27.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#notación-1"><i class="fa fa-check"></i><b>27.1</b> Notación</a></li>
<li class="chapter" data-level="27.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#un-ejemplo"><i class="fa fa-check"></i><b>27.2</b> Un ejemplo</a></li>
<li class="chapter" data-level="27.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#ejercicios-44"><i class="fa fa-check"></i><b>27.3</b> Ejercicios</a></li>
<li class="chapter" data-level="27.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#métricas-de-evaluación"><i class="fa fa-check"></i><b>27.4</b> Métricas de evaluación</a><ul>
<li class="chapter" data-level="27.4.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#sets-de-entrenamiento-y-evaluación"><i class="fa fa-check"></i><b>27.4.1</b> Sets de entrenamiento y evaluación</a></li>
<li class="chapter" data-level="27.4.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#exactitud-general"><i class="fa fa-check"></i><b>27.4.2</b> Exactitud general</a></li>
<li class="chapter" data-level="27.4.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#la-matriz-de-confusión"><i class="fa fa-check"></i><b>27.4.3</b> La matriz de confusión</a></li>
<li class="chapter" data-level="27.4.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#sensibilidad-y-especificidad"><i class="fa fa-check"></i><b>27.4.4</b> Sensibilidad y especificidad</a></li>
<li class="chapter" data-level="27.4.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#exactitud-equilibrada-y-medida-f_1"><i class="fa fa-check"></i><b>27.4.5</b> Exactitud equilibrada y medida <span class="math inline">\(F_1\)</span></a></li>
<li class="chapter" data-level="27.4.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#la-prevalencia-importa-en-la-práctica"><i class="fa fa-check"></i><b>27.4.6</b> La prevalencia importa en la práctica</a></li>
<li class="chapter" data-level="27.4.7" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#roc-y-curvas-de-recuperación-de-precisión"><i class="fa fa-check"></i><b>27.4.7</b> ROC y curvas de recuperación de precisión</a></li>
<li class="chapter" data-level="27.4.8" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#loss-function"><i class="fa fa-check"></i><b>27.4.8</b> La función de pérdida</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#ejercicios-45"><i class="fa fa-check"></i><b>27.5</b> Ejercicios</a></li>
<li class="chapter" data-level="27.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#probabilidades-y-expectativas-condicionales"><i class="fa fa-check"></i><b>27.6</b> Probabilidades y expectativas condicionales</a><ul>
<li class="chapter" data-level="27.6.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#probabilidades-condicionales-1"><i class="fa fa-check"></i><b>27.6.1</b> Probabilidades condicionales</a></li>
<li class="chapter" data-level="27.6.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#expectativas-condicionales"><i class="fa fa-check"></i><b>27.6.2</b> Expectativas condicionales</a></li>
<li class="chapter" data-level="27.6.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#la-expectativa-condicional-minimiza-la-función-de-pérdida-al-cuadrado"><i class="fa fa-check"></i><b>27.6.3</b> La expectativa condicional minimiza la función de pérdida al cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="27.7" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#ejercicios-46"><i class="fa fa-check"></i><b>27.7</b> Ejercicios</a></li>
<li class="chapter" data-level="27.8" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#two-or-seven"><i class="fa fa-check"></i><b>27.8</b> Estudio de caso: ¿es un 2 o un 7?</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="suavización.html"><a href="suavización.html"><i class="fa fa-check"></i><b>28</b> Suavización</a><ul>
<li class="chapter" data-level="28.1" data-path="suavización.html"><a href="suavización.html#suavización-de-compartimientos"><i class="fa fa-check"></i><b>28.1</b> Suavización de compartimientos</a></li>
<li class="chapter" data-level="28.2" data-path="suavización.html"><a href="suavización.html#kernels"><i class="fa fa-check"></i><b>28.2</b> Kernels</a></li>
<li class="chapter" data-level="28.3" data-path="suavización.html"><a href="suavización.html#regresión-ponderada-local-loess"><i class="fa fa-check"></i><b>28.3</b> Regresión ponderada local (loess)</a><ul>
<li class="chapter" data-level="28.3.1" data-path="suavización.html"><a href="suavización.html#cómo-ajustar-parábolas"><i class="fa fa-check"></i><b>28.3.1</b> Cómo ajustar parábolas</a></li>
<li class="chapter" data-level="28.3.2" data-path="suavización.html"><a href="suavización.html#cuidado-con-los-parámetros-de-suavización-predeterminados"><i class="fa fa-check"></i><b>28.3.2</b> Cuidado con los parámetros de suavización predeterminados</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="suavización.html"><a href="suavización.html#smoothing-ml-connection"><i class="fa fa-check"></i><b>28.4</b> Conectando la suavización al <em>machine learning</em></a></li>
<li class="chapter" data-level="28.5" data-path="suavización.html"><a href="suavización.html#ejercicios-47"><i class="fa fa-check"></i><b>28.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>29</b> Validación cruzada</a><ul>
<li class="chapter" data-level="29.1" data-path="cross-validation.html"><a href="cross-validation.html#knn-cv-intro"><i class="fa fa-check"></i><b>29.1</b> Motivación con <em>k-nearest neighbors</em></a><ul>
<li class="chapter" data-level="29.1.1" data-path="cross-validation.html"><a href="cross-validation.html#sobreentrenamiento"><i class="fa fa-check"></i><b>29.1.1</b> Sobreentrenamiento</a></li>
<li class="chapter" data-level="29.1.2" data-path="cross-validation.html"><a href="cross-validation.html#alisado-excesivo"><i class="fa fa-check"></i><b>29.1.2</b> Alisado excesivo</a></li>
<li class="chapter" data-level="29.1.3" data-path="cross-validation.html"><a href="cross-validation.html#escogiendo-el-k-en-knn"><i class="fa fa-check"></i><b>29.1.3</b> Escogiendo el <span class="math inline">\(k\)</span> en kNN</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="cross-validation.html"><a href="cross-validation.html#descripción-matemática-de-validación-cruzada"><i class="fa fa-check"></i><b>29.2</b> Descripción matemática de validación cruzada</a></li>
<li class="chapter" data-level="29.3" data-path="cross-validation.html"><a href="cross-validation.html#validación-cruzada-k-fold"><i class="fa fa-check"></i><b>29.3</b> Validación cruzada K-fold</a></li>
<li class="chapter" data-level="29.4" data-path="cross-validation.html"><a href="cross-validation.html#ejercicios-48"><i class="fa fa-check"></i><b>29.4</b> Ejercicios</a></li>
<li class="chapter" data-level="29.5" data-path="cross-validation.html"><a href="cross-validation.html#bootstrap"><i class="fa fa-check"></i><b>29.5</b> Bootstrap</a></li>
<li class="chapter" data-level="29.6" data-path="cross-validation.html"><a href="cross-validation.html#ejercicios-49"><i class="fa fa-check"></i><b>29.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>30</b> El paquete caret</a><ul>
<li class="chapter" data-level="30.1" data-path="caret.html"><a href="caret.html#la-función-train-de-caret"><i class="fa fa-check"></i><b>30.1</b> La función <code>train</code> de caret</a></li>
<li class="chapter" data-level="30.2" data-path="caret.html"><a href="caret.html#caret-cv"><i class="fa fa-check"></i><b>30.2</b> Validación cruzada</a></li>
<li class="chapter" data-level="30.3" data-path="caret.html"><a href="caret.html#ejemplo-ajuste-con-loess"><i class="fa fa-check"></i><b>30.3</b> Ejemplo: ajuste con loess</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html"><i class="fa fa-check"></i><b>31</b> Ejemplos de algoritmos</a><ul>
<li class="chapter" data-level="31.1" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#regresión-lineal"><i class="fa fa-check"></i><b>31.1</b> Regresión lineal</a><ul>
<li class="chapter" data-level="31.1.1" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#la-función-predict"><i class="fa fa-check"></i><b>31.1.1</b> La función <code>predict</code></a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#ejercicios-50"><i class="fa fa-check"></i><b>31.2</b> Ejercicios</a></li>
<li class="chapter" data-level="31.3" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#regresión-logística"><i class="fa fa-check"></i><b>31.3</b> Regresión logística</a><ul>
<li class="chapter" data-level="31.3.1" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>31.3.1</b> Modelos lineales generalizados</a></li>
<li class="chapter" data-level="31.3.2" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#regresión-logística-con-más-de-un-predictor"><i class="fa fa-check"></i><b>31.3.2</b> Regresión logística con más de un predictor</a></li>
</ul></li>
<li class="chapter" data-level="31.4" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#ejercicios-51"><i class="fa fa-check"></i><b>31.4</b> Ejercicios</a></li>
<li class="chapter" data-level="31.5" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>31.5</b> k-nearest neighbors</a></li>
<li class="chapter" data-level="31.6" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#ejercicios-52"><i class="fa fa-check"></i><b>31.6</b> Ejercicios</a></li>
<li class="chapter" data-level="31.7" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#modelos-generativos"><i class="fa fa-check"></i><b>31.7</b> Modelos generativos</a><ul>
<li class="chapter" data-level="31.7.1" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#naive-bayes"><i class="fa fa-check"></i><b>31.7.1</b> Naive Bayes</a></li>
<li class="chapter" data-level="31.7.2" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#controlando-la-prevalencia"><i class="fa fa-check"></i><b>31.7.2</b> Controlando la prevalencia</a></li>
<li class="chapter" data-level="31.7.3" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#análisis-discriminante-cuadrático"><i class="fa fa-check"></i><b>31.7.3</b> Análisis discriminante cuadrático</a></li>
<li class="chapter" data-level="31.7.4" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#análisis-discriminante-lineal"><i class="fa fa-check"></i><b>31.7.4</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="31.7.5" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#conexión-a-distancia"><i class="fa fa-check"></i><b>31.7.5</b> Conexión a distancia</a></li>
</ul></li>
<li class="chapter" data-level="31.8" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#estudio-de-caso-más-de-tres-clases"><i class="fa fa-check"></i><b>31.8</b> Estudio de caso: más de tres clases</a></li>
<li class="chapter" data-level="31.9" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#ejercicios-53"><i class="fa fa-check"></i><b>31.9</b> Ejercicios</a></li>
<li class="chapter" data-level="31.10" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#árboles-de-clasificación-y-regresión-cart"><i class="fa fa-check"></i><b>31.10</b> Árboles de clasificación y regresión (CART)</a><ul>
<li class="chapter" data-level="31.10.1" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#la-maldición-de-la-dimensionalidad"><i class="fa fa-check"></i><b>31.10.1</b> La maldición de la dimensionalidad</a></li>
<li class="chapter" data-level="31.10.2" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#carrera-motivación"><i class="fa fa-check"></i><b>31.10.2</b> CARRERA motivación</a></li>
<li class="chapter" data-level="31.10.3" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#árboles-de-regresión"><i class="fa fa-check"></i><b>31.10.3</b> Árboles de regresión</a></li>
<li class="chapter" data-level="31.10.4" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#árboles-de-clasificación-decisión"><i class="fa fa-check"></i><b>31.10.4</b> Árboles de clasificación (decisión)</a></li>
</ul></li>
<li class="chapter" data-level="31.11" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#bosques-aleatiruis"><i class="fa fa-check"></i><b>31.11</b> Bosques aleatiruis</a></li>
<li class="chapter" data-level="31.12" data-path="ejemplos-de-algoritmos.html"><a href="ejemplos-de-algoritmos.html#ejercicios-54"><i class="fa fa-check"></i><b>31.12</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="machine-learning-en-la-práctica.html"><a href="machine-learning-en-la-práctica.html"><i class="fa fa-check"></i><b>32</b> Machine learning en la práctica</a><ul>
<li class="chapter" data-level="32.1" data-path="machine-learning-en-la-práctica.html"><a href="machine-learning-en-la-práctica.html#preprocesamiento"><i class="fa fa-check"></i><b>32.1</b> Preprocesamiento</a></li>
<li class="chapter" data-level="32.2" data-path="machine-learning-en-la-práctica.html"><a href="machine-learning-en-la-práctica.html#k-vecino-más-cercano-y-bosque-aleatorio"><i class="fa fa-check"></i><b>32.2</b> k-vecino más cercano y bosque aleatorio</a></li>
<li class="chapter" data-level="32.3" data-path="machine-learning-en-la-práctica.html"><a href="machine-learning-en-la-práctica.html#importancia-variable"><i class="fa fa-check"></i><b>32.3</b> Importancia variable</a></li>
<li class="chapter" data-level="32.4" data-path="machine-learning-en-la-práctica.html"><a href="machine-learning-en-la-práctica.html#evaluaciones-visuales"><i class="fa fa-check"></i><b>32.4</b> Evaluaciones visuales</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html"><i class="fa fa-check"></i><b>33</b> Grandes conjuntos de datos</a><ul>
<li class="chapter" data-level="33.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#matrix-algebra"><i class="fa fa-check"></i><b>33.1</b> Álgebra matricial</a><ul>
<li class="chapter" data-level="33.1.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#notación-2"><i class="fa fa-check"></i><b>33.1.1</b> Notación</a></li>
<li class="chapter" data-level="33.1.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#convertir-un-vector-en-una-matriz"><i class="fa fa-check"></i><b>33.1.2</b> Convertir un vector en una matriz</a></li>
<li class="chapter" data-level="33.1.3" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#resúmenes-de-filas-y-columnas"><i class="fa fa-check"></i><b>33.1.3</b> Resúmenes de filas y columnas</a></li>
<li class="chapter" data-level="33.1.4" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#apply"><i class="fa fa-check"></i><b>33.1.4</b> <code>apply</code></a></li>
<li class="chapter" data-level="33.1.5" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#filtrar-columnas-basadas-en-resúmenes"><i class="fa fa-check"></i><b>33.1.5</b> Filtrar columnas basadas en resúmenes</a></li>
<li class="chapter" data-level="33.1.6" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#indexación-con-matrices"><i class="fa fa-check"></i><b>33.1.6</b> Indexación con matrices</a></li>
<li class="chapter" data-level="33.1.7" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#binarizar-los-datos"><i class="fa fa-check"></i><b>33.1.7</b> Binarizar los datos</a></li>
<li class="chapter" data-level="33.1.8" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#vectorización-para-matrices"><i class="fa fa-check"></i><b>33.1.8</b> Vectorización para matrices</a></li>
<li class="chapter" data-level="33.1.9" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#operaciones-de-álgebra-matricial"><i class="fa fa-check"></i><b>33.1.9</b> Operaciones de álgebra matricial</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejercicios-55"><i class="fa fa-check"></i><b>33.2</b> Ejercicios</a></li>
<li class="chapter" data-level="33.3" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#distancia"><i class="fa fa-check"></i><b>33.3</b> Distancia</a><ul>
<li class="chapter" data-level="33.3.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#distancia-euclidiana"><i class="fa fa-check"></i><b>33.3.1</b> Distancia euclidiana</a></li>
<li class="chapter" data-level="33.3.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#distancia-en-dimensiones-superiores"><i class="fa fa-check"></i><b>33.3.2</b> Distancia en dimensiones superiores</a></li>
<li class="chapter" data-level="33.3.3" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejemplo-de-distancia-euclidiana"><i class="fa fa-check"></i><b>33.3.3</b> Ejemplo de distancia euclidiana</a></li>
<li class="chapter" data-level="33.3.4" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#predictor-space"><i class="fa fa-check"></i><b>33.3.4</b> Espacio predictor</a></li>
<li class="chapter" data-level="33.3.5" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#distancia-entre-predictores"><i class="fa fa-check"></i><b>33.3.5</b> Distancia entre predictores</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejercicios-56"><i class="fa fa-check"></i><b>33.4</b> Ejercicios</a></li>
<li class="chapter" data-level="33.5" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#reducción-de-dimensiones"><i class="fa fa-check"></i><b>33.5</b> Reducción de dimensiones</a><ul>
<li class="chapter" data-level="33.5.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#preservando-la-distancia"><i class="fa fa-check"></i><b>33.5.1</b> Preservando la distancia</a></li>
<li class="chapter" data-level="33.5.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#transformaciones-lineales-avanzado"><i class="fa fa-check"></i><b>33.5.2</b> Transformaciones lineales (avanzado)</a></li>
<li class="chapter" data-level="33.5.3" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#transformaciones-ortogonales-avanzado"><i class="fa fa-check"></i><b>33.5.3</b> Transformaciones ortogonales (avanzado)</a></li>
<li class="chapter" data-level="33.5.4" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#análisis-de-componentes-principales"><i class="fa fa-check"></i><b>33.5.4</b> Análisis de componentes principales</a></li>
<li class="chapter" data-level="33.5.5" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejemplo-de-iris"><i class="fa fa-check"></i><b>33.5.5</b> Ejemplo de Iris</a></li>
<li class="chapter" data-level="33.5.6" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejemplo-de-mnist"><i class="fa fa-check"></i><b>33.5.6</b> Ejemplo de MNIST</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejercicios-57"><i class="fa fa-check"></i><b>33.6</b> Ejercicios</a></li>
<li class="chapter" data-level="33.7" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#sistemas-de-recomendación"><i class="fa fa-check"></i><b>33.7</b> Sistemas de recomendación</a><ul>
<li class="chapter" data-level="33.7.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#datos-de-lente-de-película"><i class="fa fa-check"></i><b>33.7.1</b> Datos de lente de película</a></li>
<li class="chapter" data-level="33.7.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#sistemas-de-recomendación-como-un-desafío-de-aprendizaje-automático"><i class="fa fa-check"></i><b>33.7.2</b> Sistemas de recomendación como un desafío de aprendizaje automático</a></li>
<li class="chapter" data-level="33.7.3" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#netflix-loss-function"><i class="fa fa-check"></i><b>33.7.3</b> Función de pérdida</a></li>
<li class="chapter" data-level="33.7.4" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#un-primer-modelo"><i class="fa fa-check"></i><b>33.7.4</b> Un primer modelo</a></li>
<li class="chapter" data-level="33.7.5" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#modelado-de-efectos-de-películas"><i class="fa fa-check"></i><b>33.7.5</b> Modelado de efectos de películas</a></li>
<li class="chapter" data-level="33.7.6" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#efectos-de-usuario"><i class="fa fa-check"></i><b>33.7.6</b> Efectos de usuario</a></li>
</ul></li>
<li class="chapter" data-level="33.8" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejercicios-58"><i class="fa fa-check"></i><b>33.8</b> Ejercicios</a></li>
<li class="chapter" data-level="33.9" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#regularización"><i class="fa fa-check"></i><b>33.9</b> Regularización</a><ul>
<li class="chapter" data-level="33.9.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#motivación"><i class="fa fa-check"></i><b>33.9.1</b> Motivación</a></li>
<li class="chapter" data-level="33.9.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#mínimos-cuadrados-penalizados"><i class="fa fa-check"></i><b>33.9.2</b> Mínimos cuadrados penalizados</a></li>
<li class="chapter" data-level="33.9.3" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#elegir-los-términos-de-penalización"><i class="fa fa-check"></i><b>33.9.3</b> Elegir los términos de penalización</a></li>
</ul></li>
<li class="chapter" data-level="33.10" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejercicios-59"><i class="fa fa-check"></i><b>33.10</b> Ejercicios</a></li>
<li class="chapter" data-level="33.11" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#factorización-matricial"><i class="fa fa-check"></i><b>33.11</b> Factorización matricial</a><ul>
<li class="chapter" data-level="33.11.1" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#análisis-de-factores"><i class="fa fa-check"></i><b>33.11.1</b> Análisis de factores</a></li>
<li class="chapter" data-level="33.11.2" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#conexión-a-svd-y-pca"><i class="fa fa-check"></i><b>33.11.2</b> Conexión a SVD y PCA</a></li>
</ul></li>
<li class="chapter" data-level="33.12" data-path="grandes-conjuntos-de-datos.html"><a href="grandes-conjuntos-de-datos.html#ejercicios-60"><i class="fa fa-check"></i><b>33.12</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>34</b> Agrupación</a><ul>
<li class="chapter" data-level="34.1" data-path="clustering.html"><a href="clustering.html#agrupación-jerárquica"><i class="fa fa-check"></i><b>34.1</b> Agrupación jerárquica</a></li>
<li class="chapter" data-level="34.2" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>34.2</b> k-means</a></li>
<li class="chapter" data-level="34.3" data-path="clustering.html"><a href="clustering.html#mapas-de-calor"><i class="fa fa-check"></i><b>34.3</b> Mapas de calor</a></li>
<li class="chapter" data-level="34.4" data-path="clustering.html"><a href="clustering.html#características-de-filtrado"><i class="fa fa-check"></i><b>34.4</b> Características de filtrado</a></li>
<li class="chapter" data-level="34.5" data-path="clustering.html"><a href="clustering.html#ejercicios-61"><i class="fa fa-check"></i><b>34.5</b> Ejercicios</a></li>
</ul></li>
<li class="part"><span><b>VI Productivity Tools</b></span></li>
<li class="chapter" data-level="35" data-path="introduction-to-productivity-tools.html"><a href="introduction-to-productivity-tools.html"><i class="fa fa-check"></i><b>35</b> Introduction to productivity tools</a></li>
<li class="chapter" data-level="36" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html"><i class="fa fa-check"></i><b>36</b> Instalación de R y RStudio</a><ul>
<li class="chapter" data-level="36.1" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#instalando-r"><i class="fa fa-check"></i><b>36.1</b> Instalando R</a></li>
<li class="chapter" data-level="36.2" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#instalación-de-rstudio"><i class="fa fa-check"></i><b>36.2</b> Instalación de RStudio</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html"><i class="fa fa-check"></i><b>37</b> Accessing the terminal and installing Git</a><ul>
<li class="chapter" data-level="37.1" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#terminal-on-mac"><i class="fa fa-check"></i><b>37.1</b> Accessing the terminal on a Mac</a></li>
<li class="chapter" data-level="37.2" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>37.2</b> Installing Git on the Mac</a></li>
<li class="chapter" data-level="37.3" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>37.3</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="37.4" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#terminal-on-windows"><i class="fa fa-check"></i><b>37.4</b> Accessing the terminal on Windows</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="unix.html"><a href="unix.html"><i class="fa fa-check"></i><b>38</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="38.1" data-path="unix.html"><a href="unix.html#naming-convention"><i class="fa fa-check"></i><b>38.1</b> Naming convention</a></li>
<li class="chapter" data-level="38.2" data-path="unix.html"><a href="unix.html#the-terminal"><i class="fa fa-check"></i><b>38.2</b> The terminal</a></li>
<li class="chapter" data-level="38.3" data-path="unix.html"><a href="unix.html#filesystem"><i class="fa fa-check"></i><b>38.3</b> The filesystem</a><ul>
<li class="chapter" data-level="38.3.1" data-path="unix.html"><a href="unix.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>38.3.1</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="38.3.2" data-path="unix.html"><a href="unix.html#the-home-directory"><i class="fa fa-check"></i><b>38.3.2</b> The home directory</a></li>
<li class="chapter" data-level="38.3.3" data-path="unix.html"><a href="unix.html#working-directory"><i class="fa fa-check"></i><b>38.3.3</b> Working directory</a></li>
<li class="chapter" data-level="38.3.4" data-path="unix.html"><a href="unix.html#paths"><i class="fa fa-check"></i><b>38.3.4</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="unix.html"><a href="unix.html#unix-commands"><i class="fa fa-check"></i><b>38.4</b> Unix commands</a><ul>
<li class="chapter" data-level="38.4.1" data-path="unix.html"><a href="unix.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>38.4.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="38.4.2" data-path="unix.html"><a href="unix.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>38.4.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="38.4.3" data-path="unix.html"><a href="unix.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>38.4.3</b> <code>cd</code>: navigating the filesystem by changing directories</a></li>
</ul></li>
<li class="chapter" data-level="38.5" data-path="unix.html"><a href="unix.html#some-examples"><i class="fa fa-check"></i><b>38.5</b> Some examples</a></li>
<li class="chapter" data-level="38.6" data-path="unix.html"><a href="unix.html#more-unix-commands"><i class="fa fa-check"></i><b>38.6</b> More Unix commands</a><ul>
<li class="chapter" data-level="38.6.1" data-path="unix.html"><a href="unix.html#mv-moving-files"><i class="fa fa-check"></i><b>38.6.1</b> <code>mv</code>: moving files</a></li>
<li class="chapter" data-level="38.6.2" data-path="unix.html"><a href="unix.html#cp-copying-files"><i class="fa fa-check"></i><b>38.6.2</b> <code>cp</code>: copying files</a></li>
<li class="chapter" data-level="38.6.3" data-path="unix.html"><a href="unix.html#rm-removing-files"><i class="fa fa-check"></i><b>38.6.3</b> <code>rm</code>: removing files</a></li>
<li class="chapter" data-level="38.6.4" data-path="unix.html"><a href="unix.html#less-looking-at-a-file"><i class="fa fa-check"></i><b>38.6.4</b> <code>less</code>: looking at a file</a></li>
</ul></li>
<li class="chapter" data-level="38.7" data-path="unix.html"><a href="unix.html#prep-project"><i class="fa fa-check"></i><b>38.7</b> Preparing for a data science project</a></li>
<li class="chapter" data-level="38.8" data-path="unix.html"><a href="unix.html#advanced-unix"><i class="fa fa-check"></i><b>38.8</b> Advanced Unix</a><ul>
<li class="chapter" data-level="38.8.1" data-path="unix.html"><a href="unix.html#arguments"><i class="fa fa-check"></i><b>38.8.1</b> Arguments</a></li>
<li class="chapter" data-level="38.8.2" data-path="unix.html"><a href="unix.html#getting-help"><i class="fa fa-check"></i><b>38.8.2</b> Getting help</a></li>
<li class="chapter" data-level="38.8.3" data-path="unix.html"><a href="unix.html#pipes"><i class="fa fa-check"></i><b>38.8.3</b> Pipes</a></li>
<li class="chapter" data-level="38.8.4" data-path="unix.html"><a href="unix.html#wild-cards"><i class="fa fa-check"></i><b>38.8.4</b> Wild cards</a></li>
<li class="chapter" data-level="38.8.5" data-path="unix.html"><a href="unix.html#environment-variables"><i class="fa fa-check"></i><b>38.8.5</b> Environment variables</a></li>
<li class="chapter" data-level="38.8.6" data-path="unix.html"><a href="unix.html#shells"><i class="fa fa-check"></i><b>38.8.6</b> Shells</a></li>
<li class="chapter" data-level="38.8.7" data-path="unix.html"><a href="unix.html#executables"><i class="fa fa-check"></i><b>38.8.7</b> Executables</a></li>
<li class="chapter" data-level="38.8.8" data-path="unix.html"><a href="unix.html#permissions-and-file-types"><i class="fa fa-check"></i><b>38.8.8</b> Permissions and file types</a></li>
<li class="chapter" data-level="38.8.9" data-path="unix.html"><a href="unix.html#commands-you-should-learn"><i class="fa fa-check"></i><b>38.8.9</b> Commands you should learn</a></li>
<li class="chapter" data-level="38.8.10" data-path="unix.html"><a href="unix.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>38.8.10</b> File manipulation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>39</b> Git and GitHub</a><ul>
<li class="chapter" data-level="39.1" data-path="git.html"><a href="git.html#why-use-git-and-github"><i class="fa fa-check"></i><b>39.1</b> Why use Git and GitHub?</a></li>
<li class="chapter" data-level="39.2" data-path="git.html"><a href="git.html#github-accounts"><i class="fa fa-check"></i><b>39.2</b> GitHub accounts</a></li>
<li class="chapter" data-level="39.3" data-path="git.html"><a href="git.html#github-repos"><i class="fa fa-check"></i><b>39.3</b> GitHub repositories</a></li>
<li class="chapter" data-level="39.4" data-path="git.html"><a href="git.html#git-overview"><i class="fa fa-check"></i><b>39.4</b> Overview of Git</a><ul>
<li class="chapter" data-level="39.4.1" data-path="git.html"><a href="git.html#clone"><i class="fa fa-check"></i><b>39.4.1</b> Clone</a></li>
</ul></li>
<li class="chapter" data-level="39.5" data-path="git.html"><a href="git.html#init"><i class="fa fa-check"></i><b>39.5</b> Initializing a Git directory</a></li>
<li class="chapter" data-level="39.6" data-path="git.html"><a href="git.html#rstudio-git"><i class="fa fa-check"></i><b>39.6</b> Using Git and GitHub in RStudio</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html"><i class="fa fa-check"></i><b>40</b> Reproducible projects with RStudio and R markdown</a><ul>
<li class="chapter" data-level="40.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#rstudio-projects"><i class="fa fa-check"></i><b>40.1</b> RStudio projects</a></li>
<li class="chapter" data-level="40.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#r-markdown"><i class="fa fa-check"></i><b>40.2</b> R markdown</a><ul>
<li class="chapter" data-level="40.2.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#the-header"><i class="fa fa-check"></i><b>40.2.1</b> The header</a></li>
<li class="chapter" data-level="40.2.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#r-code-chunks"><i class="fa fa-check"></i><b>40.2.2</b> R code chunks</a></li>
<li class="chapter" data-level="40.2.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#global-options"><i class="fa fa-check"></i><b>40.2.3</b> Global options</a></li>
<li class="chapter" data-level="40.2.4" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#knitr"><i class="fa fa-check"></i><b>40.2.4</b> knitR</a></li>
<li class="chapter" data-level="40.2.5" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#more-on-r-markdown"><i class="fa fa-check"></i><b>40.2.5</b> More on R markdown</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#organizing"><i class="fa fa-check"></i><b>40.3</b> Organizing a data science project</a><ul>
<li class="chapter" data-level="40.3.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-directories-in-unix"><i class="fa fa-check"></i><b>40.3.1</b> Create directories in Unix</a></li>
<li class="chapter" data-level="40.3.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-an-rstudio-project"><i class="fa fa-check"></i><b>40.3.2</b> Create an RStudio project</a></li>
<li class="chapter" data-level="40.3.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#edit-some-r-scripts"><i class="fa fa-check"></i><b>40.3.3</b> Edit some R scripts</a></li>
<li class="chapter" data-level="40.3.4" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-some-more-directories-using-unix"><i class="fa fa-check"></i><b>40.3.4</b> Create some more directories using Unix</a></li>
<li class="chapter" data-level="40.3.5" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#add-a-readme-file"><i class="fa fa-check"></i><b>40.3.5</b> Add a README file</a></li>
<li class="chapter" data-level="40.3.6" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#initializing-a-git-directory"><i class="fa fa-check"></i><b>40.3.6</b> Initializing a Git directory</a></li>
<li class="chapter" data-level="40.3.7" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#add-commit-and-push-files-using-rstudio"><i class="fa fa-check"></i><b>40.3.7</b> Add, commit, and push files using RStudio</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="models" class="section level1">
<h1><span class="header-section-number">Capítulo 16</span> Modelos estadísticos</h1>
<blockquote>
<blockquote>
<p>“Todos los modelos están equivocados, pero algunos son útiles.” –George E. P. Box</p>
</blockquote>
</blockquote>
<p>El día antes de las elecciones presidenciales del 2008, FiveThirtyEight de Nate Silver declaró que “Barack Obama parece estar listo para una victoria electoral decisiva”. Fueron hasta más lejos y predijeron que Obama ganaría las elecciones con 349 votos electorales a 189, y el voto popular por un margen de 6.1%. FiveThirtyEight también añadió una declaración probabilística a su predicción declarando que Obama tenía una probablidad de 91% de ganar las elecciones. Las predicciones fueron bastante precisas y, en los resultados finales, Obama ganó el colegio electoral 365 a 173 y el voto popular por una diferencia de 7.2%. El desempeño de FiveThirtyEight en las elecciones del 2008 atrajo la atención de expertos políticos y personalidades de la televisión. Cuatro años después, la semana antes de las elecciones presidenciales del 2012, Nate Silver de FiveThirtyEight le estaba dando a Obama una probabilidad de 90% de ganar a pesar de que muchos de los expertos pensaban que los resultados finales estarían más cerca. El comentarista político Joe Scarborough dijo durante su show<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a>:</p>
<blockquote>
<blockquote>
<p>Cualquiera que piense que esta elección no está pareja en este momento es un tremendo ideólogo … son un chiste.</p>
</blockquote>
</blockquote>
<p>A lo que Nate Silver respondió a través de Twitter:</p>
<blockquote>
<blockquote>
<p>Si cree que la elección está pareja, apostemos. Si Obama gana, usted dona $1,000 a la Cruz Roja Americana. Si Romney gana, yo lo hago. ¿De acuerdo?</p>
</blockquote>
</blockquote>
<p>En 2016, Silver no estaba tan seguro y le dio a Hillary Clinton solo una probabilidad de 71% de ganar. En contraste, la mayoría de los otros pronosticadores estaban casi seguros de que ella ganaría. Ella perdió. Pero 71% sigue siendo más de 50%, ¿se equivocó el Sr. Silver? Además, ¿qué significa la probabilidad en este contexto? ¿Alguien está tirando dados?</p>
<p>En este capítulo demostraremos cómo los <em>agregadores de encuestas</em>, como FiveThirtyEight, recopilaron y combinaron datos informados por diferentes expertos para producir mejores predicciones. Introduciremos las ideas detrás de los <em>modelos estadísticos</em>, también conocidos como <em>modelos de probabilidad</em>, que utilizaron los agregadores de encuestas para mejorar los pronósticos electorales en comparación a las encuestas individuales. En este capítulo, motivamos los modelos, construyendo sobre los conceptos de inferencia estadística que aprendimos en el Capítulo <a href="inference.html#inference">15</a>. Comenzamos con modelos relativamente sencillos, tomando en cuenta que el ejercicio real de la ciencia de datos de pronosticar elecciones involucra algunos modelos bastante complejos, que presentamos al final del capítulo en la Sección <a href="models.html#election-forecasting">16.8</a>.</p>
<div id="agregadores-de-encuestas" class="section level2">
<h2><span class="header-section-number">16.1</span> Agregadores de encuestas</h2>
<p>Como describimos anteriormente, unas semanas antes de las elecciones del 2012, Nate Silver le estaba dando a Obama una probabilidad de 90% de ganar. ¿Por qué tenía tanta confianza el señor Silver? Utilizaremos una simulación Monte Carlo para ilustrar la idea que tuvo el Sr. Silver y que otros no vieron. Para hacer esto, generamos resultados para 12 encuestas realizadas la semana anterior a las elecciones. Imitaremos tamaños de muestra de encuestas reales y construiremos e informaremos intervalos de confianza de 95% para cada una de las 12 encuestas. Guardaremos los resultados de esta simulación en un set de datos y añadimos una columna de ID de encuesta.</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="models.html#cb587-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb587-2"><a href="models.html#cb587-2"></a><span class="kw">library</span>(dslabs)</span>
<span id="cb587-3"><a href="models.html#cb587-3"></a>d &lt;-<span class="st"> </span><span class="fl">0.039</span></span>
<span id="cb587-4"><a href="models.html#cb587-4"></a>Ns &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1298</span>, <span class="dv">533</span>, <span class="dv">1342</span>, <span class="dv">897</span>, <span class="dv">774</span>, <span class="dv">254</span>, <span class="dv">812</span>, <span class="dv">324</span>, <span class="dv">1291</span>, <span class="dv">1056</span>, <span class="dv">2172</span>, <span class="dv">516</span>)</span>
<span id="cb587-5"><a href="models.html#cb587-5"></a>p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb587-6"><a href="models.html#cb587-6"></a></span>
<span id="cb587-7"><a href="models.html#cb587-7"></a>polls &lt;-<span class="st"> </span><span class="kw">map_df</span>(Ns, <span class="cf">function</span>(N) {</span>
<span id="cb587-8"><a href="models.html#cb587-8"></a>  x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">size=</span>N, <span class="dt">replace=</span><span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p))</span>
<span id="cb587-9"><a href="models.html#cb587-9"></a>  x_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(x)</span>
<span id="cb587-10"><a href="models.html#cb587-10"></a>  se_hat &lt;-<span class="st"> </span><span class="kw">sqrt</span>(x_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>x_hat)<span class="op">/</span><span class="st"> </span>N)</span>
<span id="cb587-11"><a href="models.html#cb587-11"></a>  <span class="kw">list</span>(<span class="dt">estimate =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x_hat <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb587-12"><a href="models.html#cb587-12"></a>       <span class="dt">low =</span> <span class="dv">2</span><span class="op">*</span>(x_hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se_hat) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb587-13"><a href="models.html#cb587-13"></a>       <span class="dt">high =</span> <span class="dv">2</span><span class="op">*</span>(x_hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se_hat) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb587-14"><a href="models.html#cb587-14"></a>       <span class="dt">sample_size =</span> N)</span>
<span id="cb587-15"><a href="models.html#cb587-15"></a>}) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">poll =</span> <span class="kw">seq_along</span>(Ns))</span></code></pre></div>
<p>Aquí tenemos una visualización que muestra los intervalos que los encuestadores reportaron para la diferencia entre Obama y Romney:</p>
<p><img src="libro_files/figure-html/simulated-polls-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>No es sorprendente que las 12 encuestas informen intervalos de confianza que incluyen el resultado de la noche electoral (línea discontinua). Sin embargo, las 12 encuestas también incluyen 0 (línea negra sólida). Por lo tanto, si se les pide individualmente una predicción, los encuestadores tendrían que decir: las probabilidades están parejas. A continuación describimos una idea clave que no consideraron.</p>
<p>Los agregadores de encuestas, como Nate Silver, se dieron cuenta de que al combinar los resultados de diferentes encuestas, la precisión podría mejorar enormemente. Al hacer esto, estamos llevando a cabo una encuesta con un gran tamaño de muestra. Por lo tanto, podemos informar un intervalo de confianza menor de 95% y una predicción más precisa.</p>
<p>Aunque como agregadores no tenemos acceso a los datos sin procesar de la encuesta, podemos usar las matemáticas para reconstruir lo que habríamos obtenido si hubiéramos hecho una encuesta grande con:</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="models.html#cb588-1"></a><span class="kw">sum</span>(polls<span class="op">$</span>sample_size)</span>
<span id="cb588-2"><a href="models.html#cb588-2"></a><span class="co">#&gt; [1] 11269</span></span></code></pre></div>
<p>participantes. Básicamente, construimos una estimación de la diferencia, llamémosla <span class="math inline">\(d\)</span>, con un promedio ponderado de la siguiente manera:</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="models.html#cb589-1"></a>d_hat &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span></span>
<span id="cb589-2"><a href="models.html#cb589-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">sum</span>(estimate<span class="op">*</span>sample_size)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(sample_size)) <span class="op">%&gt;%</span></span>
<span id="cb589-3"><a href="models.html#cb589-3"></a><span class="st">  </span><span class="kw">pull</span>(avg)</span></code></pre></div>
<p>Una vez que tengamos una estimación de <span class="math inline">\(d\)</span>, podemos construir una estimación de la proporción votando por Obama, que luego podemos usar para estimar el error estándar. Tan pronto hacemos esto, vemos que nuestro margen de error es 0.018.</p>
<p>Por lo tanto, podemos predecir que la diferencia será 3.1 más o menos 1.8, que no solo incluye el resultado real que observamos en la noche de las elecciones, sino que está bastante lejos de incluir 0. Una vez que combinamos las 12 encuestas, estamos seguros de que Obama ganará el voto popular.</p>
<p><img src="libro_files/figure-html/confidence-coverage-2008-election-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Por supuesto, esto fue solo una simulación para ilustrar la idea. El ejercicio real de la ciencia de datos de pronosticar elecciones es mucho más complicado y requiere modelos estadísticos. A continuación explicamos cómo los encuestadores ajustan los modelos multinivel a los datos y los utilizan para pronosticar los resultados electorales. En las elecciones presidenciales estadounidensas del 2008 y 2012, Nate Silver utilizó este enfoque para hacer una predicción casi perfecta y callar a los expertos.</p>
<p>Desde las elecciones del 2008, otras organizaciones han establecido sus propios grupos de pronóstico de elecciones que, como el de Nate Silver, agrega datos de encuestas y utiliza modelos estadísticos para hacer predicciones. En 2016, los pronosticadores subestimaron por mucho las posibilidades de Trump de ganar. El día antes de las elecciones, el <em>New York Times</em> informó<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a> las siguientes probabilidades de que Hillary Clinton ganara la presidencia:</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
NYT
</th>
<th style="text-align:left;">
538
</th>
<th style="text-align:left;">
HuffPost
</th>
<th style="text-align:left;">
PW
</th>
<th style="text-align:left;">
PEC
</th>
<th style="text-align:left;">
DK
</th>
<th style="text-align:left;">
Cook
</th>
<th style="text-align:left;">
Roth
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Win Prob
</td>
<td style="text-align:left;">
85%
</td>
<td style="text-align:left;">
71%
</td>
<td style="text-align:left;">
98%
</td>
<td style="text-align:left;">
89%
</td>
<td style="text-align:left;">
&gt;99%
</td>
<td style="text-align:left;">
92%
</td>
<td style="text-align:left;">
Lean Dem
</td>
<td style="text-align:left;">
Lean Dem
</td>
</tr>
</tbody>
</table>
<!--(Source: [New York Times](https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html))-->
<p>Por ejemplo, el Consorcio Electoral de Princeton (<em>Princeton Election Consortium</em> en inglés) le dio a Trump menos de 1% de probabilidad de ganar, mientras que el <em>Huffington Post</em> le dio una probabilidad de 2%. Por el contrario, FiveThirtyEight le daba a Trump una probabilidad de ganar de 29%, más que la probabilidad de lanzar dos monedas y obtener dos caras. De hecho, cuatro días antes de las elecciones, FiveThirtyEight publicó un artículo titulado <em>Trump is Just A Normal Polling Error Behind Clinton</em><a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a>.
Al entender los modelos estadísticos y cómo los pronosticadores los usan, comenzaremos a entender cómo sucedió esto.</p>
<p>Aunque no tan interesante como predecir el colegio electoral, para fines ilustrativos comenzaremos analizando las predicciones para el voto popular. FiveThirtyEight predijo una ventaja de 3.6% para Clinton<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a> y su intervalo de confianza incluyó el resultado real de una diferencia de 2.1% (48.2% a 46.1%). Además, FiveThirtyEight estuvo mucho más seguro sobre la posibilidad de que Clinton ganara el voto popular, dándole una probabilidad de 81.4%. Su predicción se resumió con un gráfico como este:</p>
<p><img src="libro_files/figure-html/fivethirtyeight-densities-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Las áreas coloreadas representan valores con una probabilidad de 80% de incluir el resultado real, según el modelo de FiveThirtyEight.
<!--(Source: [FiveThirtyEight](https://projects.fivethirtyeight.com/2016-election-forecast/))--></p>
<p>Presentamos datos reales de las elecciones presidenciales de EE. UU. del 2016 para mostrar cómo se motivan y se contruyen los modelos para producir estas predicciones. Para comprender la declaración “81.4% de probabilidad”, necesitamos describir las estadísticas bayesianas, lo que hacemos en las Secciones <a href="models.html#bayesian-statistics">16.4</a> y <a href="models.html#bayesian-approach">16.8.1</a>.</p>
<div id="datos-de-encuesta" class="section level3">
<h3><span class="header-section-number">16.1.1</span> Datos de encuesta</h3>
<p>Utilizamos datos públicos de encuestas organizados por FiveThirtyEight para las elecciones presidenciales del 2016. Los datos se incluyen como parte del paquete <strong>dslabs</strong>:</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="models.html#cb590-1"></a><span class="kw">data</span>(polls_us_election_<span class="dv">2016</span>)</span></code></pre></div>
<p>La tabla incluye los resultados de las encuestas nacionales, así como las encuestas estatales, tomadas durante el año anterior a la elección. Para este primer ejemplo, filtraremos los datos para incluir encuestas nacionales realizadas durante la semana previa a las elecciones. También eliminamos las encuestas que FiveThirtyEight ha determinado que no son confiables y calificaron con una “B” o menos. Algunas encuestas no han sido calificadas e incluimos aquellas:</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="models.html#cb591-1"></a>polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb591-2"><a href="models.html#cb591-2"></a><span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span> <span class="op">&amp;</span></span>
<span id="cb591-3"><a href="models.html#cb591-3"></a><span class="st">           </span>(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade)))</span></code></pre></div>
<p>Agregamos la estimación de la diferencia:</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="models.html#cb592-1"></a>polls &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span></span>
<span id="cb592-2"><a href="models.html#cb592-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</span></code></pre></div>
<p>Para este ejemplo, suponemos que solo hay dos partes y llamaremos <span class="math inline">\(p\)</span> a la proporción de votos para Clinton y <span class="math inline">\(1-p\)</span> a la proporción votando por Trump. Estamos interesados en la diferencia <span class="math inline">\(2p-1\)</span>. Llamemos a la diferencia <span class="math inline">\(d\)</span>.</p>
<p>Tenemos 49 estimaciones de la diferencia. La teoría que aprendimos nos dice que estas estimaciones son una variable aleatoria con una distribución de probabilidad que es aproximadamente normal. El valor esperado es la diferencia de la noche electoral <span class="math inline">\(d\)</span> y el error estándar es <span class="math inline">\(2\sqrt{p (1 - p)/ N}\)</span>. Suponiendo que el modelo de urna que describimos anteriormente es bueno, podemos usar esta información para construir un intervalo de confianza basado en los datos agregados. La diferencia estimada es:</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="models.html#cb593-1"></a>d_hat &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span></span>
<span id="cb593-2"><a href="models.html#cb593-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">d_hat =</span> <span class="kw">sum</span>(spread <span class="op">*</span><span class="st"> </span>samplesize)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(samplesize)) <span class="op">%&gt;%</span></span>
<span id="cb593-3"><a href="models.html#cb593-3"></a><span class="st">  </span><span class="kw">pull</span>(d_hat)</span></code></pre></div>
<p>y el error estándar es:</p>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="models.html#cb594-1"></a>p_hat &lt;-<span class="st"> </span>(d_hat<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span></span>
<span id="cb594-2"><a href="models.html#cb594-2"></a>moe &lt;-<span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_hat)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(polls<span class="op">$</span>samplesize))</span>
<span id="cb594-3"><a href="models.html#cb594-3"></a>moe</span>
<span id="cb594-4"><a href="models.html#cb594-4"></a><span class="co">#&gt; [1] 0.00662</span></span></code></pre></div>
<p>Entonces informamos una diferencia de 1.43% con un margen de error de 0.66%. En la noche de las elecciones, descubrimos que el porcentaje real era 2.1%, que está fuera de un intervalo de confianza de 95%. ¿Que pasó?</p>
<p>Un histograma de las variabilidades reportadas muestra un problema:</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="models.html#cb595-1"></a>polls <span class="op">%&gt;%</span></span>
<span id="cb595-2"><a href="models.html#cb595-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(spread)) <span class="op">+</span></span>
<span id="cb595-3"><a href="models.html#cb595-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">.01</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/polls-2016-spread-histogram-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Los datos no parecen estar distribuidos normalmente y el error estándar parece ser mayor que 0.007. La teoría no está funcionando bien aquí.</p>
</div>
<div id="sesgo-de-los-encuestadores" class="section level3">
<h3><span class="header-section-number">16.1.2</span> Sesgo de los encuestadores</h3>
<p>Observen que varios encuestadores están involucrados y algunos toman varias encuestas por semana:</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="models.html#cb596-1"></a>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="kw">n</span>())</span>
<span id="cb596-2"><a href="models.html#cb596-2"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span>
<span id="cb596-3"><a href="models.html#cb596-3"></a><span class="co">#&gt; # A tibble: 15 x 2</span></span>
<span id="cb596-4"><a href="models.html#cb596-4"></a><span class="co">#&gt;   pollster                                                   `n()`</span></span>
<span id="cb596-5"><a href="models.html#cb596-5"></a><span class="co">#&gt;   &lt;fct&gt;                                                      &lt;int&gt;</span></span>
<span id="cb596-6"><a href="models.html#cb596-6"></a><span class="co">#&gt; 1 ABC News/Washington Post                                       7</span></span>
<span id="cb596-7"><a href="models.html#cb596-7"></a><span class="co">#&gt; 2 Angus Reid Global                                              1</span></span>
<span id="cb596-8"><a href="models.html#cb596-8"></a><span class="co">#&gt; 3 CBS News/New York Times                                        2</span></span>
<span id="cb596-9"><a href="models.html#cb596-9"></a><span class="co">#&gt; 4 Fox News/Anderson Robbins Research/Shaw &amp; Company Research     2</span></span>
<span id="cb596-10"><a href="models.html#cb596-10"></a><span class="co">#&gt; 5 IBD/TIPP                                                       8</span></span>
<span id="cb596-11"><a href="models.html#cb596-11"></a><span class="co">#&gt; # … with 10 more rows</span></span></code></pre></div>
<p>Visualicemos los datos de los encuestadores que sondean regularmente:</p>
<p><img src="libro_files/figure-html/pollster-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Este gráfico revela un resultado inesperado. Primero, consideren que el error estándar predicho por la teoría para cada encuesta:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="models.html#cb597-1"></a>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span></span>
<span id="cb597-2"><a href="models.html#cb597-2"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">6</span>) <span class="op">%&gt;%</span></span>
<span id="cb597-3"><a href="models.html#cb597-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p_hat)<span class="op">/</span><span class="st"> </span><span class="kw">median</span>(samplesize)))</span>
<span id="cb597-4"><a href="models.html#cb597-4"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span>
<span id="cb597-5"><a href="models.html#cb597-5"></a><span class="co">#&gt; # A tibble: 5 x 2</span></span>
<span id="cb597-6"><a href="models.html#cb597-6"></a><span class="co">#&gt;   pollster                     se</span></span>
<span id="cb597-7"><a href="models.html#cb597-7"></a><span class="co">#&gt;   &lt;fct&gt;                     &lt;dbl&gt;</span></span>
<span id="cb597-8"><a href="models.html#cb597-8"></a><span class="co">#&gt; 1 ABC News/Washington Post 0.0265</span></span>
<span id="cb597-9"><a href="models.html#cb597-9"></a><span class="co">#&gt; 2 IBD/TIPP                 0.0333</span></span>
<span id="cb597-10"><a href="models.html#cb597-10"></a><span class="co">#&gt; 3 Ipsos                    0.0225</span></span>
<span id="cb597-11"><a href="models.html#cb597-11"></a><span class="co">#&gt; 4 The Times-Picayune/Lucid 0.0196</span></span>
<span id="cb597-12"><a href="models.html#cb597-12"></a><span class="co">#&gt; 5 USC Dornsife/LA Times    0.0183</span></span></code></pre></div>
<p>está entre 0.018 y 0.033, que concuerda con la variación de encuesta a encuesta que vemos para cada encuestador. Sin embargo, parece haber diferencias <em>entre los encuestadores</em>. Observen, por ejemplo, cómo el encuestador USC Dornsife/LA Times predice una ventaja de 4% para Trump, mientras que Ipsos predice una ventaja mayor de 5% para Clinton. La teoría que aprendimos no dice nada acerca de diferentes encuestadores que producen encuestas con diferentes valores esperados. Todas las encuestas deben tener el mismo valor esperado. FiveThirtyEight se refiere a estas diferencias como “house effects”. También las llamamos <em>sesgo de encuestadores</em>.</p>
<p>En la siguiente sección, en lugar de utilizar la teoría del modelo de urna, desarrollaremos un modelo basado en datos.</p>
</div>
</div>
<div id="data-driven-model" class="section level2">
<h2><span class="header-section-number">16.2</span> Modelos basados en datos</h2>
<p>Para cada encuestador, recopilemos el último resultado que informan antes de las elecciones:</p>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="models.html#cb598-1"></a>one_poll_per_pollster &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span></span>
<span id="cb598-2"><a href="models.html#cb598-2"></a><span class="st">  </span><span class="kw">filter</span>(enddate <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(enddate)) <span class="op">%&gt;%</span></span>
<span id="cb598-3"><a href="models.html#cb598-3"></a><span class="st">  </span><span class="kw">ungroup</span>()</span></code></pre></div>
<p>Aquí hay un histograma de los datos para estos 15 encuestadores:</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="models.html#cb599-1"></a><span class="kw">qplot</span>(spread, <span class="dt">data =</span> one_poll_per_pollster, <span class="dt">binwidth =</span> <span class="fl">0.01</span>)</span></code></pre></div>
<p><img src="libro_files/figure-html/pollster-bias-histogram-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>En la sección anterior, vimos que usar la teoría del modelo de urna para combinar estos resultados a veces no es apropiado debido al efecto de encuestador. En cambio, modelaremos estos datos de las diferencias directamente.</p>
<p>El nuevo modelo también puede considerarse como un modelo de urna, aunque la conexión no es tan directa. En lugar de 0s (republicanos) y 1s (demócratas), nuestra urna ahora contiene los resultados de las encuestas de todos los posibles encuestadores. Suponemos que el valor esperado de nuestra urna es la diferencia real <span class="math inline">\(d=2p-1\)</span>.</p>
<p>Dado que en lugar de 0s y 1s, nuestra urna contiene números continuos entre -1 y 1, la desviación estándar de la urna ya no es <span class="math inline">\(\sqrt{p(1-p)}\)</span>. En vez de la variabilidad del muestreo de votantes, el error estándar ahora incluye la variabilidad entre encuestadores. Nuestra nueva urna también incluye la variabilidad de muestreo del sondeo. De cualquier manera, esta desviación estándar ahora es un parámetro desconocido. En los libros de texto de estadística, el símbolo griego <span class="math inline">\(\sigma\)</span> se usa para representar este parámetro.</p>
<p>En resumen, tenemos dos parámetros desconocidos: el valor esperado <span class="math inline">\(d\)</span> y la desviación estándar <span class="math inline">\(\sigma\)</span>.</p>
<p>Nuestra tarea es estimar <span class="math inline">\(d\)</span>. Como modelamos los valores observados <span class="math inline">\(X_1,\dots X_N\)</span> como una muestra aleatoria de la urna, el CLT aún podría funcionar en esta situación porque es un promedio de variables aleatorias independientes. Para un tamaño de muestra suficientemente grande <span class="math inline">\(N\)</span>, la distribución de probabilidad del promedio de la muestra <span class="math inline">\(\bar{X}\)</span> es aproximadamente normal con valor esperado <span class="math inline">\(\mu\)</span> y error estándar <span class="math inline">\(\sigma/\sqrt{N}\)</span>. Si estamos dispuestos a considerar <span class="math inline">\(N=15\)</span> como suficientemente grande, podemos usar esto para construir intervalos de confianza.</p>
<p>Un problema es que no sabemos <span class="math inline">\(\sigma\)</span>. Pero la teoría nos dice que podemos estimar el modelo de urna <span class="math inline">\(\sigma\)</span> con la <em>desviación estándar de la muestra</em> definida como
<span class="math inline">\(s = \sqrt{ \sum_{i=1}^N (X_i - \bar{X})^2/ (N-1)}\)</span>.</p>
<p>A diferencia de la definición de desviación estándar de la población, ahora dividimos por <span class="math inline">\(N-1\)</span>. Esto hace <span class="math inline">\(s\)</span> una mejor estimación de <span class="math inline">\(\sigma\)</span>. Hay una explicación matemática para esto, que se enseña en la mayoría de los libros de texto de estadística, pero no la cubrimos aquí.</p>
<p>En R, la función <code>sd</code> calcula la desviación estándar de la muestra:</p>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="models.html#cb600-1"></a><span class="kw">sd</span>(one_poll_per_pollster<span class="op">$</span>spread)</span>
<span id="cb600-2"><a href="models.html#cb600-2"></a><span class="co">#&gt; [1] 0.0242</span></span></code></pre></div>
<p>Ahora estamos listos para formar un nuevo intervalo de confianza basado en nuestro nuevo modelo y en datos:</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="models.html#cb601-1"></a>results &lt;-<span class="st"> </span>one_poll_per_pollster <span class="op">%&gt;%</span></span>
<span id="cb601-2"><a href="models.html#cb601-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread),</span>
<span id="cb601-3"><a href="models.html#cb601-3"></a>            <span class="dt">se =</span> <span class="kw">sd</span>(spread)<span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span></span>
<span id="cb601-4"><a href="models.html#cb601-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>se,</span>
<span id="cb601-5"><a href="models.html#cb601-5"></a>         <span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>se)</span>
<span id="cb601-6"><a href="models.html#cb601-6"></a><span class="kw">round</span>(results <span class="op">*</span><span class="st"> </span><span class="dv">100</span>, <span class="dv">1</span>)</span>
<span id="cb601-7"><a href="models.html#cb601-7"></a><span class="co">#&gt;   avg  se start end</span></span>
<span id="cb601-8"><a href="models.html#cb601-8"></a><span class="co">#&gt; 1 2.9 0.6   1.7 4.1</span></span></code></pre></div>
<p>Nuestro intervalo de confianza ahora es más amplio ya que incorpora la variabilidad de encuestador. Incluye el resultado de la noche electoral de 2.1%. Además, observen que era lo suficientemente pequeño como para no incluir 0, lo que significa que estábamos seguros de que Clinton ganaría el voto popular.</p>
<p>¿Estamos listos ahora para declarar una probabilidad de que Clinton gane el voto popular? Aún no. En nuestro modelo <span class="math inline">\(d\)</span> es un parámetro fijo, por lo que no podemos hablar de probabilidades. Para ofrecer probabilidades, necesitaremos aprender sobre las estadísticas bayesianas.</p>
</div>
<div id="ejercicios-30" class="section level2">
<h2><span class="header-section-number">16.3</span> Ejercicios</h2>
<p>Hemos estado utilizando modelos de urna para motivar el uso de modelos de probabilidad. La mayoría de las aplicaciones de ciencia de datos no están relacionadas con datos obtenidos de urnas. Más comunes son los datos que provienen de individuos. La razón por la que la probabilidad importa aquí es porque los datos provienen de una muestra aleatoria. La muestra aleatoria se toma de una población y la urna sirve como analogía para la población.</p>
<p>Volvamos al conjunto de datos de alturas. Supongamos que consideramos a los varones de nuestra clase como la población.</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb602-1"><a href="models.html#cb602-1"></a><span class="kw">library</span>(dslabs)</span>
<span id="cb602-2"><a href="models.html#cb602-2"></a><span class="kw">data</span>(heights)</span>
<span id="cb602-3"><a href="models.html#cb602-3"></a>x &lt;-<span class="st"> </span>heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(sex <span class="op">==</span><span class="st"> &quot;Male&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb602-4"><a href="models.html#cb602-4"></a><span class="st">  </span><span class="kw">pull</span>(height)</span></code></pre></div>
<p>1. Matemáticamente hablando, <code>x</code> es nuestra población. Usando la analogía de la urna, tenemos una urna con los valores de <code>x</code> dentro de ella. ¿Cuáles son el promedio y la desviación estándar de nuestra población?</p>
<p>2. Llame al promedio de población calculado arriba <span class="math inline">\(\mu\)</span> y la desviación estándar <span class="math inline">\(\sigma\)</span>. Ahora tome una muestra de tamaño 50, con reemplazo, y construya una estimación para <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>.</p>
<p>3. ¿Qué nos dice la teoría sobre el promedio de la muestra <span class="math inline">\(\bar{X}\)</span> y como se relaciona con <span class="math inline">\(\mu\)</span>?</p>
<ol style="list-style-type: lower-alpha">
<li>Es prácticamente idéntico a <span class="math inline">\(\mu\)</span>.</li>
<li>Es una variable aleatoria con valor esperado <span class="math inline">\(\mu\)</span> y error estándar <span class="math inline">\(\sigma/\sqrt{N}\)</span>.</li>
<li>Es una variable aleatoria con valor esperado <span class="math inline">\(\mu\)</span> y error estándar <span class="math inline">\(\sigma\)</span>.</li>
<li>No contiene información.</li>
</ol>
<p>4. Entonces, ¿cómo es esto útil? Vamos a utilizar un ejemplo simplificado pero ilustrativo. Supongamos que queremos saber la altura promedio de nuestros estudiantes varones, pero solo llegamos a medir 50 de los 708. Usaremos <span class="math inline">\(\bar{X}\)</span> como nuestra estimación. Sabemos por la respuesta al ejercicio 3 que la estimación estándar de nuestro error <span class="math inline">\(\bar{X}-\mu\)</span> es <span class="math inline">\(\sigma/\sqrt{N}\)</span>. Queremos calcular esto, pero no sabemos <span class="math inline">\(\sigma\)</span>. Según lo que se describe en esta sección, indique su estimación de <span class="math inline">\(\sigma\)</span>.</p>
<p>5. Ahora que tenemos una estimación de <span class="math inline">\(\sigma\)</span>, llamemos a nuestra estimación <span class="math inline">\(s\)</span>. Construya un intervalo de confianza de 95% para <span class="math inline">\(\mu\)</span>.</p>
<p>6. Ahora ejecute una simulación Monte Carlo en la que calcula 10,000 intervalos de confianza como acaba de hacer. ¿Qué proporción de estos intervalos incluye <span class="math inline">\(\mu\)</span>?</p>
<p>7. En esta sección, discutimos el sesgo de encuestador. Utilizamos la visualización para motivar la presencia de tal sesgo. Aquí le daremos un tratamiento más riguroso. Consideraremos dos encuestadores que realizaron encuestas diarias. Examinaremos las encuestas nacionales del mes anterior a las elecciones.</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="models.html#cb603-1"></a><span class="kw">data</span>(polls_us_election_<span class="dv">2016</span>)</span>
<span id="cb603-2"><a href="models.html#cb603-2"></a>polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb603-3"><a href="models.html#cb603-3"></a><span class="st">  </span><span class="kw">filter</span>(pollster <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Rasmussen Reports/Pulse Opinion Research&quot;</span>,</span>
<span id="cb603-4"><a href="models.html#cb603-4"></a>                         <span class="st">&quot;The Times-Picayune/Lucid&quot;</span>) <span class="op">&amp;</span></span>
<span id="cb603-5"><a href="models.html#cb603-5"></a><span class="st">           </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-15&quot;</span> <span class="op">&amp;</span></span>
<span id="cb603-6"><a href="models.html#cb603-6"></a><span class="st">           </span>state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb603-7"><a href="models.html#cb603-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</span></code></pre></div>
<p>Queremos contestar la pregunta: ¿hay un sesgo en la encuesta? Haga un gráfico que muestre la diferencia para cada encuesta.</p>
<p>8. Los datos parecen sugerir que hay una diferencia. Sin embargo, estos datos están sujetos a variabilidad. Quizás las diferencias que observamos se deben al azar.</p>
<p>La teoría del modelo de urna no dice nada sobre el efecto del encuestador. Bajo el modelo de urna, ambos encuestadores tienen el mismo valor esperado: la diferencia del día de las elecciones, que llamamos <span class="math inline">\(d\)</span>.</p>
<p>Para responder a la pregunta “¿hay un modelo de urna?”, modelaremos los datos observados <span class="math inline">\(Y_{i,j}\)</span> de la siguiente manera:</p>
<p><span class="math display">\[
Y_{i,j} = d + b_i + \varepsilon_{i,j}
\]</span></p>
<p>con <span class="math inline">\(i=1,2\)</span> indexando los dos encuestadores, <span class="math inline">\(b_i\)</span> el sesgo para el encuestador <span class="math inline">\(i\)</span> y <span class="math inline">\(\varepsilon_{ij}\)</span> representando la variabilidad aleatoria de las encuestas. Suponemos que los <span class="math inline">\(\varepsilon\)</span> son independientes entre sí, tienen valor esperado <span class="math inline">\(0\)</span> y desviación estándar <span class="math inline">\(\sigma_i\)</span> independientemente de <span class="math inline">\(j\)</span>.</p>
<p>¿Cuál de las siguientes mejor representa nuestra pregunta?</p>
<ol style="list-style-type: lower-alpha">
<li>¿Es <span class="math inline">\(\varepsilon_{i,j}\)</span> = 0?</li>
<li>¿Cuán cerca están los <span class="math inline">\(Y_{i,j}\)</span> a <span class="math inline">\(d\)</span>?</li>
<li>¿Es <span class="math inline">\(b_1 \neq b_2\)</span>?</li>
<li>¿Son <span class="math inline">\(b_1 = 0\)</span> y <span class="math inline">\(b_2 = 0\)</span>?</li>
</ol>
<p>9. En el lado derecho de este modelo solo <span class="math inline">\(\varepsilon_{i,j}\)</span> es una variable aleatoria. Los otros dos son constantes. ¿Cuál es el valor esperado de <span class="math inline">\(Y_{1,j}\)</span>?</p>
<p>10. Supongamos que definimos <span class="math inline">\(\bar{Y}_1\)</span> como el promedio de los resultados de la encuesta del primer encuestador, <span class="math inline">\(Y_{1,1},\dots,Y_{1,N_1}\)</span> con <span class="math inline">\(N_1\)</span> el número de encuestas realizadas por el primer encuestador:</p>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="models.html#cb604-1"></a>polls <span class="op">%&gt;%</span></span>
<span id="cb604-2"><a href="models.html#cb604-2"></a><span class="st">  </span><span class="kw">filter</span>(pollster<span class="op">==</span><span class="st">&quot;Rasmussen Reports/Pulse Opinion Research&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb604-3"><a href="models.html#cb604-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">N_1 =</span> <span class="kw">n</span>())</span></code></pre></div>
<p>¿Cuál es el valor esperado de <span class="math inline">\(\bar{Y}_1\)</span>?</p>
<p>11. ¿Cuál es el error estándar de <span class="math inline">\(\bar{Y}_1\)</span> ?</p>
<p>12. Supongamos que definimos <span class="math inline">\(\bar{Y}_2\)</span> como el promedio de los resultados de la encuesta de la primera encuesta, <span class="math inline">\(Y_{2,1},\dots,Y_{2,N_2}\)</span> con <span class="math inline">\(N_2\)</span> el número de encuestas realizadas por el primer encuestador. ¿Cuál es el valor esperado <span class="math inline">\(\bar{Y}_2\)</span>?</p>
<p>13. ¿Cuál es el error estándar de <span class="math inline">\(\bar{Y}_2\)</span> ?</p>
<p>14. Usando lo que aprendimos al responder a las preguntas anteriores, ¿cuál es el valor esperado de <span class="math inline">\(\bar{Y}_{2} - \bar{Y}_1\)</span>?</p>
<p>15. Usando lo que aprendimos al responder a las preguntas anteriores, ¿cuál es el error estándar de <span class="math inline">\(\bar{Y}_{2} - \bar{Y}_1\)</span>?</p>
<p>16. La respuesta a la pregunta anterior depende de <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span>, que no sabemos. Aprendimos que podemos estimarlos con la desviación estándar de la muestra. Escriba un código que calcule estas dos estimaciones.</p>
<p>17. ¿Qué nos dice el CLT sobre la distribución de <span class="math inline">\(\bar{Y}_2 - \bar{Y}_1\)</span>?</p>
<ol style="list-style-type: lower-alpha">
<li>Nada porque este no es el promedio de una muestra.</li>
<li>Como el <span class="math inline">\(Y_{ij}\)</span> son aproximadamente normales, también lo son los promedios.</li>
<li>Como <span class="math inline">\(\bar{Y}_2\)</span> y <span class="math inline">\(\bar{Y}_1\)</span> son promedios de muestras, si suponemos que <span class="math inline">\(N_2\)</span> y <span class="math inline">\(N_1\)</span> son lo suficientemente grandes, cada uno es aproximadamente normal. La diferencia de normales también es normal.</li>
<li>Los datos no son 0 o 1, por lo que el CLT no se aplica.</li>
</ol>
<p>18. Hemos construido una variable aleatoria que tiene un valor esperado <span class="math inline">\(b_2 - b_1\)</span>, la diferencia de sesgo del encuestador. Si nuestro modelo funciona, entonces esta variable aleatoria tiene una distribución aproximadamente normal y sabemos su error estándar. El error estándar depende de <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span>, pero podemos usar las desviaciones estándar de muestra que calculamos anteriormente. Comenzamos preguntando: ¿<span class="math inline">\(b_2 - b_1\)</span> es diferente de 0? Use toda la información que hemos aprendido anteriormente para construir un intervalo de confianza de 95% para la diferencia <span class="math inline">\(b_2\)</span> y <span class="math inline">\(b_1\)</span>.</p>
<p>19. El intervalo de confianza nos dice que hay un efecto encuestador relativamente fuerte que resulta en una diferencia de aproximadamente 5%. La variabilidad aleatoria no parece explicarlo. Podemos calcular un valor p para explicar el hecho de que el azar no lo explica. ¿Cuál es el valor p?</p>
<p>20. La estadística formada al dividir nuestra estimación de <span class="math inline">\(b_2-b_1\)</span> por su error estándar estimado:</p>
<p><span class="math display">\[
\frac{\bar{Y}_2 - \bar{Y}_1}{\sqrt{s_2^2/N_2 + s_1^2/N_1}}
\]</span></p>
<p>se llama la estadística t. Ahora observe que tenemos más de dos encuestadores. También podemos probar para el efecto de encuestador utilizando todos los encuestadores, no solo dos. La idea es comparar la variabilidad entre encuestas con la variabilidad dentro de las encuestas. De hecho, podemos construir estadísticas para probar los efectos y aproximar su distribución. El área de estadísticas que hace esto se llama Análisis de la varianza o ANOVA por sus siglas en inglés. No lo cubrimos aquí, pero ANOVA provee un set muy útil de herramientas para responder a preguntas como: ¿hay un efecto encuestador?</p>
<p>Para este ejercicio, cree una nueva tabla:</p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="models.html#cb605-1"></a>polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb605-2"><a href="models.html#cb605-2"></a><span class="st">  </span><span class="kw">filter</span>(enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-15&quot;</span> <span class="op">&amp;</span></span>
<span id="cb605-3"><a href="models.html#cb605-3"></a><span class="st">           </span>state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb605-4"><a href="models.html#cb605-4"></a><span class="st">  </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span></span>
<span id="cb605-5"><a href="models.html#cb605-5"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">5</span>) <span class="op">%&gt;%</span></span>
<span id="cb605-6"><a href="models.html#cb605-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb605-7"><a href="models.html#cb605-7"></a><span class="st">  </span><span class="kw">ungroup</span>()</span></code></pre></div>
<p>Calcule el promedio y la desviación estándar para cada encuestador y examine la variabilidad entre los promedios y cómo se compara con la variabilidad dentro de los encuestadores, resumida por la desviación estándar.</p>

</div>
<div id="bayesian-statistics" class="section level2">
<h2><span class="header-section-number">16.4</span> Estadísticas bayesianas</h2>
<p>¿Qué significa que un pronosticador electoral nos diga que un candidato tiene un 90% probabilidad de ganar? En el contexto del modelo de urna, esto sería equivalente a afirmar que la probabilidad <span class="math inline">\(p&gt;0.5\)</span> es 90%. Sin embargo, como discutimos anteriormente, en el modelo de urna <span class="math inline">\(p\)</span> es un parámetro fijo y no tiene sentido hablar de probabilidad. Con estadísticas bayesianas, modelamos <span class="math inline">\(p\)</span> como variable aleatoria y, por lo tanto, una declaración como “90% probabilidad de ganar” es coherente.</p>
<p>Los pronosticadores también usan modelos para describir la variabilidad en diferentes niveles. Por ejemplo, la variabilidad de muestreo, la variabilidad de encuestador a encuestador, la variabilidad diaria y la variabilidad de elección a elección. Uno de los enfoques más exitosos utilizados para esto son los modelos jerárquicos, que pueden explicarse en el contexto de las estadísticas bayesianas.</p>
<p>En este capítulo describimos brevemente las estadísticas bayesianas. Para una exploración más profunda de este tema, recomendamos uno de los siguientes libros de texto:</p>
<ul>
<li><p>Berger JO (1985). Statistical Decision Theory and Bayesian Analysis, 2nd edition. Springer-Verlag.</p></li>
<li><p>Lee PM (1989). Bayesian Statistics: An Introduction. Oxford.</p></li>
</ul>
<div id="teorema-de-bayes" class="section level3">
<h3><span class="header-section-number">16.4.1</span> Teorema de Bayes</h3>
<p>Comenzamos describiendo el teorema de Bayes. Hacemos esto usando una hipotética prueba de fibrosis quística como ejemplo.
Supongamos que una prueba de fibrosis quística tiene una precisión de 99%. Vamos a utilizar la siguiente notación:</p>
<p><span class="math display">\[
\mbox{Prob}(+ \mid D=1)=0.99, \mbox{Prob}(- \mid D=0)=0.99
\]</span></p>
<p>con <span class="math inline">\(+\)</span> significando una prueba positiva y <span class="math inline">\(D\)</span> representando si realmente tiene la enfermedad (1) o no (0).</p>
<p>Supongamos que seleccionamos una persona al azar y dan positivo. ¿Cuál es la probabilidad de que tengan la enfermedad? Escribimos esto como <span class="math inline">\(\mbox{Prob}(D=1 \mid +)\)</span>. La tasa de fibrosis quística es de 1 en 3,900, lo que implica que <span class="math inline">\(\mbox{Prob}(D=1)=0.00025\)</span>. Para responder a esta pregunta, utilizaremos el teorema de Bayes, que por lo general nos dice que:</p>
<p><span class="math display">\[
\mbox{Pr}(A \mid B) = \frac{\mbox{Pr}(B \mid A)\mbox{Pr}(A)}{\mbox{Pr}(B)}
\]</span></p>
<p>Esta ecuación aplicada a nuestro problema se convierte en:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{Pr}(D=1 \mid +) &amp; = \frac{ P(+ \mid D=1) \cdot P(D=1)} {\mbox{Pr}(+)} \\
&amp; = \frac{\mbox{Pr}(+ \mid D=1)\cdot P(D=1)} {\mbox{Pr}(+ \mid D=1) \cdot P(D=1) + \mbox{Pr}(+ \mid D=0) \mbox{Pr}( D=0)}
\end{aligned}
\]</span></p>
<p>usando estos números obtenemos:</p>
<p><span class="math display">\[
\frac{0.99 \cdot 0.00025}{0.99 \cdot 0.00025 + 0.01 \cdot (.99975)} = 0.02
\]</span></p>
<p>Esto dice que a pesar de que la prueba tiene una precisión de 0.99, la probabilidad de tener la enfermedad dado una prueba positiva es solo 0.02. Aunque parezca contrario al sentido común, la razón de esto es porque tenemos que considerar la muy rara probabilidad de que una persona, elegida al azar, tenga la enfermedad. Para ilustrar esto, ejecutamos una simulación Monte Carlo.</p>
</div>
</div>
<div id="simulación-del-teorema-de-bayes" class="section level2">
<h2><span class="header-section-number">16.5</span> Simulación del teorema de Bayes</h2>
<p>La siguiente simulación está destinada a ayudarles visualizar el teorema de Bayes. Comenzamos seleccionando aleatoriamente 100,000 personas de una población en la cual la enfermedad en cuestión tiene una prevalencia de 1 en 4,000.</p>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb606-1"><a href="models.html#cb606-1"></a>prev &lt;-<span class="st"> </span><span class="fl">0.00025</span></span>
<span id="cb606-2"><a href="models.html#cb606-2"></a>N &lt;-<span class="st"> </span><span class="dv">100000</span></span>
<span id="cb606-3"><a href="models.html#cb606-3"></a>outcome &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;Disease&quot;</span>,<span class="st">&quot;Healthy&quot;</span>), N, <span class="dt">replace =</span> <span class="ot">TRUE</span>,</span>
<span id="cb606-4"><a href="models.html#cb606-4"></a>                  <span class="dt">prob =</span> <span class="kw">c</span>(prev, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prev))</span></code></pre></div>
<p>Recuerden que hay muy pocas personas con la enfermedad:</p>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb607-1"><a href="models.html#cb607-1"></a>N_D &lt;-<span class="st"> </span><span class="kw">sum</span>(outcome <span class="op">==</span><span class="st"> &quot;Disease&quot;</span>)</span>
<span id="cb607-2"><a href="models.html#cb607-2"></a>N_D</span>
<span id="cb607-3"><a href="models.html#cb607-3"></a><span class="co">#&gt; [1] 23</span></span>
<span id="cb607-4"><a href="models.html#cb607-4"></a>N_H &lt;-<span class="st"> </span><span class="kw">sum</span>(outcome <span class="op">==</span><span class="st"> &quot;Healthy&quot;</span>)</span>
<span id="cb607-5"><a href="models.html#cb607-5"></a>N_H</span>
<span id="cb607-6"><a href="models.html#cb607-6"></a><span class="co">#&gt; [1] 99977</span></span></code></pre></div>
<p>Además, hay muchos sin la enfermedad, lo que hace más probable que veamos algunos falsos positivos dado que la prueba no es perfecta. Ahora cada persona se hace la prueba, que acierta 99% del tiempo:</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="models.html#cb608-1"></a>accuracy &lt;-<span class="st"> </span><span class="fl">0.99</span></span>
<span id="cb608-2"><a href="models.html#cb608-2"></a>test &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;character&quot;</span>, N)</span>
<span id="cb608-3"><a href="models.html#cb608-3"></a>test[outcome <span class="op">==</span><span class="st"> &quot;Disease&quot;</span>] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;+&quot;</span>, <span class="st">&quot;-&quot;</span>), N_D, <span class="dt">replace =</span> <span class="ot">TRUE</span>,</span>
<span id="cb608-4"><a href="models.html#cb608-4"></a>                                     <span class="dt">prob =</span> <span class="kw">c</span>(accuracy, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>accuracy))</span>
<span id="cb608-5"><a href="models.html#cb608-5"></a>test[outcome <span class="op">==</span><span class="st"> &quot;Healthy&quot;</span>] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;-&quot;</span>, <span class="st">&quot;+&quot;</span>), N_H, <span class="dt">replace =</span> <span class="ot">TRUE</span>,</span>
<span id="cb608-6"><a href="models.html#cb608-6"></a>                                     <span class="dt">prob =</span> <span class="kw">c</span>(accuracy, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>accuracy))</span></code></pre></div>
<p>Debido a que hay muchos más controles que casos, incluso con una tasa baja de falsos positivos obtenemos más controles que los casos en el grupo que dio positivo:</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="models.html#cb609-1"></a><span class="kw">table</span>(outcome, test)</span>
<span id="cb609-2"><a href="models.html#cb609-2"></a><span class="co">#&gt;          test</span></span>
<span id="cb609-3"><a href="models.html#cb609-3"></a><span class="co">#&gt; outcome       -     +</span></span>
<span id="cb609-4"><a href="models.html#cb609-4"></a><span class="co">#&gt;   Disease     0    23</span></span>
<span id="cb609-5"><a href="models.html#cb609-5"></a><span class="co">#&gt;   Healthy 99012   965</span></span></code></pre></div>
<p>De esta tabla, vemos que la proporción de pruebas positivas que tienen la enfermedad es 23 de 988. Podemos ejecutar esto una y otra vez para ver que, de hecho, la probabilidad converge a aproximadamente 0.022.</p>
<div id="bayes-en-la-práctica" class="section level3">
<h3><span class="header-section-number">16.5.1</span> Bayes en la práctica</h3>
<p>José Iglesias es un jugador de béisbol profesional. En abril de 2013, cuando comenzaba su carrera, se desempeñaba bastante bien:</p>
<table>
<thead>
<tr class="header">
<th>Mes</th>
<th>At Bats</th>
<th>H</th>
<th>AVG</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>abril</td>
<td>20</td>
<td>9</td>
<td>.450</td>
</tr>
</tbody>
</table>
<p>La estadística del promedio de bateo (<code>AVG</code>) es una forma de medir éxito. En términos generales, nos dice la tasa de éxito al batear. Un <code>AVG</code> de .450 significa que José ha tenido éxito el 45% de las veces que ha bateado (<code>At Bats</code>) que es bastante alto, históricamente hablando. Tengan en cuenta que nadie ha terminado una temporada con un <code>AVG</code> de .400 o más desde que Ted Williams lo hizo en 1941. Para ilustrar la forma en que los modelos jerárquicos son eficaces, intentaremos predecir el promedio de bateo de José al final de la temporada. Recuerden que en una temporada típica, los jugadores tienen alrededor de 500 turnos al bate.</p>
<p>Con las técnicas que hemos aprendido hasta ahora, denominadas <em>técnicas frecuentistas</em>, lo mejor que podemos hacer es ofrecer un intervalo de confianza. Podemos pensar en los resultados de batear como un binomio con una tasa de éxito de <span class="math inline">\(p\)</span>. Entonces, si la tasa de éxito es .450, el error estándar de solo 20 turnos al bate:</p>
<p><span class="math display">\[
\sqrt{\frac{.450 (1-.450)}{20}}=.111
\]</span></p>
<p>Esto significa que nuestro intervalo de confianza es <span class="math inline">\(.450 - .222\)</span> a <span class="math inline">\(.450 + .222\)</span> o <span class="math inline">\(.228\)</span> a <span class="math inline">\(.672\)</span>.</p>
<p>Esta predicción tiene dos problemas. Primero, es muy grande, por lo que no es muy útil. Segundo, está centrada en .450, lo que implica que nuestra mejor conjetura es que este nuevo jugador romperá el récord de Ted Williams.</p>
<p>Sin embargo, para los fanáticos del béisbol, esta última afirmación no tiene sentido. Los fanáticos implícitamente emplean un modelo jerárquico que toma en cuenta la información de años de seguir el béisbol. Aquí mostramos cómo podemos cuantificar esta intuición.</p>
<p>Primero, exploremos la distribución de los promedios de bateo para todos los jugadores con más de 500 turnos al bate durante las tres temporadas anteriores:</p>
<p><img src="libro_files/figure-html/batting-averages-histogram-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El jugador promedio tuvo un <code>AVG</code> de .275 y la desviación estándar de la población de jugadores fue 0.027. Entonces podemos ver que .450 sería una anomalía, ya que está a más de seis desviaciones estándar de la media.</p>
<p>Entonces, ¿tiene suerte José o es el mejor bateador de los últimos 50 años? Quizás sea una combinación de suerte y talento. ¿Pero cuánto de cada uno? Si nos convencemos de que tiene suerte, deberíamos cambiarlo a otro equipo que confíe en la observación de .450 y tal vez sobreestime su potencial.</p>
</div>
</div>
<div id="modelos-jerárquicos" class="section level2">
<h2><span class="header-section-number">16.6</span> Modelos jerárquicos</h2>
<p>El modelo jerárquico ofrece una descripción matemática de cómo llegamos a ver la observación de .450. Primero, elegimos un jugador al azar con una habilidad intrínseca resumida por, por ejemplo, <span class="math inline">\(p\)</span>. Luego vemos 20 resultados aleatorios con probabilidad de éxito <span class="math inline">\(p\)</span>.</p>
<p>Utilizamos un modelo para representar dos niveles de variabilidad en nuestros datos. Primero, a cada jugador se le asigna una habilidad natural para batear. Usaremos el símbolo <span class="math inline">\(p\)</span> para representar esta habilidad. Pueden pensar en <span class="math inline">\(p\)</span> como el promedio de bateo al que convergería si este jugador en particular bateara repetidas veces.</p>
<p>De acuerdo con los gráficos que mostramos anteriormente, asumimos que <span class="math inline">\(p\)</span> tiene una distribución normal, con valor esperado .270 y error estándar 0.027.</p>
<p>Ahora el segundo nivel de variabilidad tiene que ver con la suerte al batear. Independientemente de lo bueno que sea el jugador, a veces tiene mala suerte y a veces tiene buena suerte. En cada turno al bate, este jugador tiene una probabilidad de éxito <span class="math inline">\(p\)</span>. Si sumamos estos éxitos y fracasos, entonces el CLT nos dice que el promedio observado, llámelo <span class="math inline">\(Y\)</span>, tiene una distribución normal con el valor esperado <span class="math inline">\(p\)</span> y error estándar <span class="math inline">\(\sqrt{p(1-p)/N}\)</span> con <span class="math inline">\(N\)</span> el número de turnos al bate.</p>
<p>Los libros de texto estadísticos escribirán el modelo así:
<span class="math display">\[
\begin{aligned}
p &amp;\sim N(\mu, \tau^2) \\
Y \mid p &amp;\sim N(p, \sigma^2)
\end{aligned}
\]</span>
Aquí el símbolo <span class="math inline">\(\sim\)</span> nos dice que la variable aleatoria a la izquierda del símbolo sigue la distribución a la derecha y <span class="math inline">\(N(a,b^2)\)</span> representa la distribución normal con media <span class="math inline">\(a\)</span> y desviación estándar <span class="math inline">\(b\)</span>. El <span class="math inline">\(\mid\)</span> significa que estamos <em>condicionando en</em> la variable aleatoria a la derecha del símbolo como si se conociera su valor. Nos referimos al modelo como jerárquico porque necesitamos saber <span class="math inline">\(p\)</span>, el primer nivel, para modelar <span class="math inline">\(Y\)</span>, el segundo nivel. En nuestro ejemplo, el primer nivel describe la aleatoriedad en la asignación de talento a un jugador y en el segundo se describe la aleatoriedad en el desempeño de este jugador una vez fijemos el parámetro de talento. En un marco bayesiano, el primer nivel se llama <em>distribución a priori</em> y el segundo la <em>distribución muestral</em>. El análisis de datos que hemos realizado aquí sugiere que establezcamos <span class="math inline">\(\mu = .270\)</span>, <span class="math inline">\(\tau = 0.027\)</span> y <span class="math inline">\(\sigma^2 = p(1-p)/N\)</span>.</p>
<p>Ahora, usemos este modelo para los datos de José. Supongamos que queremos predecir su habilidad innata en la forma de su verdadero promedio de bateo <span class="math inline">\(p\)</span>. Este sería el modelo jerárquico para nuestros datos:</p>
<p><span class="math display">\[
\begin{aligned}
p &amp;\sim N(.275, .027^2) \\
Y \mid p &amp;\sim N(p, .111^2)
\end{aligned}
\]</span></p>
<p>Ahora estamos listos para calcular una distribución a posteriori para resumir nuestra predicción de <span class="math inline">\(p\)</span>. La versión continua de la regla de Bayes se puede usar aquí para derivar la <em>función de probabilidad a posteriori</em>, que es la distribución de <span class="math inline">\(p\)</span> suponiendo que observemos <span class="math inline">\(Y=y\)</span>. En nuestro caso, podemos demostrar que cuando fijamos <span class="math inline">\(Y=y\)</span>, <span class="math inline">\(p\)</span> sigue una distribución normal con el valor esperado:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{E}(p \mid Y=y) &amp;= B \mu + (1-B) y\\
&amp;= \mu + (1-B)(y-\mu)\\
\mbox{with } B &amp;= \frac{\sigma^2}{\sigma^2+\tau^2}
\end{aligned}
\]</span></p>
<p>Este es un promedio ponderado del promedio de la población <span class="math inline">\(\mu\)</span> y los datos observados <span class="math inline">\(y\)</span>. El peso depende de la SD de la población <span class="math inline">\(\tau\)</span> y de la SD de nuestros datos observados <span class="math inline">\(\sigma\)</span>. Este promedio ponderado a veces se denomina <em>contracción</em> (<em>shrinking</em> en inglés) porque <em>contrae</em> las estimaciones hacia la media de la distribución a priori. En el caso de José Iglesias tenemos:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{E}(p \mid Y=.450) &amp;= B \times .275 + (1 - B) \times .450 \\
&amp;= .275 + (1 - B)(.450 - .275) \\
B &amp;=\frac{.111^2}{.111^2 + .027^2} = 0.944\\
\mbox{E}(p \mid Y=450) &amp;\approx .285
\end{aligned}
\]</span></p>
<p>No mostramos la derivación aquí, pero el error estándar se puede demostrar que es:</p>
<p><span class="math display">\[
\mbox{SE}(p\mid y)^2 = \frac{1}{1/\sigma^2+1/\tau^2}
= \frac{1}{1/.111^2 + 1/.027^2} = 0.00069
\]</span>
y, por lo tanto, la desviación estándar es <span class="math inline">\(0.026\)</span>. Entonces comenzamos con un intervalo de confianza frecuentista de 95% que ignoraba los datos de otros jugadores y resumía solo los datos de José: .450 <span class="math inline">\(\pm\)</span> 0.220. Luego usamos un enfoque bayesiano que incorporaba datos de otros jugadores y otros años para obtener una probabilidad a posteriori. De hecho, esto se conoce como un enfoque empírico bayesiano porque utilizamos datos para construir la distribución a priori. Desde la distribución a posteriori, podemos calcular lo que se llama un <em>intervalo de confianza de Bayes</em> o <em>intervalo de Bayes</em> (<em>credible interval</em> en inglés) de 95%. Para hacer esto, construimos una región, centrada en la media, con una probabilidad de 95% de ocurrir. En nuestro caso, esto resulta ser: .285 <span class="math inline">\(\pm\)</span> 0.052.</p>
<p>El intervalo de Bayes sugiere que si otro equipo está impresionado por el promedio observado de .450, deberíamos considerar cambiar a José, ya que pronosticamos que estará ligeramente por encima del promedio. Curiosamente, los Red Sox cambiaron a José a los Detroit Tigers en julio. Estos son los promedios de bateo de José Iglesias para los próximos cinco meses:</p>
<table>
<thead>
<tr class="header">
<th>Mes</th>
<th>At Bat</th>
<th>Hits</th>
<th>AVG</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>abril</td>
<td>20</td>
<td>9</td>
<td>.450</td>
</tr>
<tr class="even">
<td>mayo</td>
<td>26</td>
<td>11</td>
<td>.423</td>
</tr>
<tr class="odd">
<td>junio</td>
<td>86</td>
<td>34</td>
<td>.395</td>
</tr>
<tr class="even">
<td>julio</td>
<td>83</td>
<td>17</td>
<td>.205</td>
</tr>
<tr class="odd">
<td>agosto</td>
<td>85</td>
<td>25</td>
<td>.294</td>
</tr>
<tr class="even">
<td>septiembre</td>
<td>50</td>
<td>10</td>
<td>.200</td>
</tr>
<tr class="odd">
<td>Total sin abril</td>
<td>330</td>
<td>97</td>
<td>.293</td>
</tr>
</tbody>
</table>
<p>Aunque ambos intervalos incluyeron el promedio final de bateo, el intervalo de Bayes ofreció una predicción mucho más precisa. En particular, predijo que no sería tan bueno durante el resto de la temporada.</p>
</div>
<div id="ejercicios-31" class="section level2">
<h2><span class="header-section-number">16.7</span> Ejercicios</h2>
<p>1. En 1999, en Inglaterra, Sally Clark<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a> fue declarada culpable del asesinato de dos de sus hijos. Ambos bebés fueron encontrados muertos por la mañana, uno en 1996 y otro en 1998. En ambos casos, Clark afirmó que la causa de la muerte fue el Síndrome de muerte súbita del lactante (SIDS o <em>Sudden Infant Death Syndrome</em> en inglés). A ninguno de los niños le encontraron lesiones físicas, por lo que la principal evidencia en su contra fue el testimonio del profesor Sir Roy Meadow, quien testificó que las probabilidades de que dos niños de la misma madre murieran de SIDS eran de 1 en 73 millones. Llegó a esta cifra al encontrar que la tasa de SIDS era de 1 en 8,500 y luego calcular que la posibilidad de dos casos de SIDS era 8,500 <span class="math inline">\(\times\)</span> 8,500 <span class="math inline">\(\approx\)</span> 73 millones. ¿Con cuál de las siguientes declaraciones está de acuerdo?</p>
<ol style="list-style-type: lower-alpha">
<li>Sir Meadow supuso que la probabilidad de que el segundo hijo fuera afectado por el SIDS era independiente de la del primer hijo afectado, ignorando así posibles causas genéticas. Si la genética juega un papel, entonces: <span class="math inline">\(\mbox{Pr}(\mbox{second case of SIDS} \mid \mbox{first case of SIDS}) &lt; \mbox{P}r(\mbox{first case of SIDS})\)</span>.</li>
<li>Nada. La regla de multiplicación siempre se aplica de esta manera: <span class="math inline">\(\mbox{Pr}(A \mbox{ and } B) =\mbox{Pr}(A)\mbox{Pr}(B)\)</span></li>
<li>Sir Meadow es un experto y debemos confiar en sus cálculos.</li>
<li>Los números no mienten.</li>
</ol>
<p>2. Supongamos que definitivamente hay un componente genético para el SIDS y la probabilidad de <span class="math inline">\(\mbox{Pr}(\mbox{second case of SIDS} \mid \mbox{first case of SIDS}) = 1/100\)</span>, es mucho mayor que 1 en 8,500. ¿Cuál es la probabilidad de que sus dos hijos mueran de SIDS?</p>
<p>3. Muchos informes de prensa declararon que el experto afirmó que la probabilidad de que Sally Clark fuera inocente era 1 en 73 millones. Quizás el jurado y el juez también interpretaron el testimonio de esta manera. Esta probabilidad se puede escribir como la probabilidad de que <em>una madre sea una psicópata asesina de hijos, dado que encuentran a dos de sus hijos muertos sin lesiones físicas.</em> Según la regla de Bayes, ¿cuánta es esta probabilidad?</p>
<p>4. Suponga que la probabilidad de que una psicópata asesina de hijos encuentre la manera de matar a sus hijos, sin dejar evidencia física, es:</p>
<p><span class="math display">\[
\mbox{Pr}(A \mid B) = 0.50
\]</span></p>
<p>con <span class="math inline">\(A =\)</span> dos de sus hijos los encuentran muertos sin lesiones físicas y <span class="math inline">\(B =\)</span> una madre es una psicópata asesina de hijos = 0.50. Suponga que la tasa de madres psicópatas que asesinan hijos es 1 en 1,000,000. Según el teorema de Bayes, ¿cuál es la probabilidad de <span class="math inline">\(\mbox{Pr}(B \mid A)\)</span>?</p>
<p>5. Después de que Sally Clark fue declarada culpable, la Royal Statistical Society emitió un comunicado diciendo que “no había base estadística” para el reclamo del experto. Expresaron preocupación por el “mal uso de las estadísticas en los tribunales”. Sally Clark fue absuelta en junio de 2003. ¿Qué no consideró el experto Sir Roy Meadow?</p>
<ol style="list-style-type: lower-alpha">
<li>Cometió un error aritmético.</li>
<li>Cometió dos errores. Primero, hizo un mal uso de la regla de multiplicación y, segundo, no tomó en cuenta lo raro que es que una madre asesine a sus hijos. Después de usar la regla de Bayes, encontramos una probabilidad más cercana a 0.5 que a 1 en 73 millones.</li>
<li>Confundió el numerador y el denominador de la regla de Bayes.</li>
<li>No usó R.</li>
</ol>
<p>6. Florida es uno de los estados más vigilados en las elecciones de EE. UU. porque tiene muchos votos electorales, y las elecciones generalmente son cerradas. Además, Florida tiende a ser un estado decisivo que puede votar por cualquiera de los dos partidos. Cree la siguiente tabla con las encuestas realizadas durante las últimas dos semanas:</p>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="models.html#cb610-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb610-2"><a href="models.html#cb610-2"></a><span class="kw">library</span>(dslabs)</span>
<span id="cb610-3"><a href="models.html#cb610-3"></a><span class="kw">data</span>(polls_us_election_<span class="dv">2016</span>)</span>
<span id="cb610-4"><a href="models.html#cb610-4"></a>polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb610-5"><a href="models.html#cb610-5"></a><span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;Florida&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-11-04&quot;</span> ) <span class="op">%&gt;%</span></span>
<span id="cb610-6"><a href="models.html#cb610-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</span></code></pre></div>
<p>Tome la diferencia promedio de estas encuestas. El CLT nos dice que este promedio es aproximadamente normal. Calcule un promedio y provea una estimación del error estándar. Guarde sus resultados en un objeto llamado <code>results</code>.</p>
<p>7. Ahora suponga un modelo bayesiano con distribución a priori normal para la diferencia de la noche electoral de Florida <span class="math inline">\(d\)</span> con valor esperado <span class="math inline">\(\mu\)</span> y desviación estándar <span class="math inline">\(\tau\)</span>. ¿Cuáles son las interpretaciones de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span>?</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span> son números arbitrarios que nos permiten hacer declaraciones de probabilidad sobre <span class="math inline">\(d\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span> resumen lo que predeciríamos para Florida antes de ver las encuestas. Basado en elecciones pasadas, fijaríamos <span class="math inline">\(\mu\)</span> cerca de 0 porque tanto republicanos como demócratas han ganado, y <span class="math inline">\(\tau\)</span> en aproximadamente <span class="math inline">\(0.02\)</span>, porque estas elecciones tienden a ser cerradas.</li>
<li><span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span> resumen lo que queremos que sea verdad. Por lo tanto, fijamos <span class="math inline">\(\mu\)</span> en <span class="math inline">\(0.10\)</span> y <span class="math inline">\(\tau\)</span> en <span class="math inline">\(0.01\)</span>.</li>
<li>La decisión de que distribución a priori usar no tiene ningún efecto en el análisis bayesiano.</li>
</ol>
<p>8. El CLT nos dice que nuestra estimación de la diferencia, <span class="math inline">\(\hat{d}\)</span>, tiene distribución normal con valor esperado <span class="math inline">\(d\)</span> y desviación estándar <span class="math inline">\(\sigma\)</span> calculada en el problema 6. Use las fórmulas que mostramos para la distribución a posteriori para calcular el valor esperado de la distribución a posteriori si fijamos <span class="math inline">\(\mu = 0\)</span> y <span class="math inline">\(\tau = 0.01\)</span>.</p>
<p>9. Ahora calcule la desviación estándar de la distribución a posteriori.</p>
<p>10. Usando el hecho de que la distribución a posteriori es normal, cree un intervalo que tenga un 95% de probabilidad de ocurrir centrado en el valor esperado a posteriori. Recuerden que estos los llamamos intervalos de Bayes.</p>
<p>11. Según este análisis, ¿cuál fue la probabilidad de que Trump ganara Florida?</p>
<p>12. Ahora use la función <code>sapply</code> para cambiar la varianza de la probabilidad a priori de <code>seq(0.05, 0.05, len = 100)</code> y observe cómo cambia la probabilidad haciendo un gráfico.</p>

</div>
<div id="election-forecasting" class="section level2">
<h2><span class="header-section-number">16.8</span> Estudio de caso: pronóstico de elecciones</h2>
<p>En una sección anterior, generamos las siguientes tablas de datos:</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="models.html#cb611-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb611-2"><a href="models.html#cb611-2"></a><span class="kw">library</span>(dslabs)</span>
<span id="cb611-3"><a href="models.html#cb611-3"></a>polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb611-4"><a href="models.html#cb611-4"></a><span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span> <span class="op">&amp;</span></span>
<span id="cb611-5"><a href="models.html#cb611-5"></a><span class="st">           </span>(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span></span>
<span id="cb611-6"><a href="models.html#cb611-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</span>
<span id="cb611-7"><a href="models.html#cb611-7"></a></span>
<span id="cb611-8"><a href="models.html#cb611-8"></a>one_poll_per_pollster &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span></span>
<span id="cb611-9"><a href="models.html#cb611-9"></a><span class="st">  </span><span class="kw">filter</span>(enddate <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(enddate)) <span class="op">%&gt;%</span></span>
<span id="cb611-10"><a href="models.html#cb611-10"></a><span class="st">  </span><span class="kw">ungroup</span>()</span>
<span id="cb611-11"><a href="models.html#cb611-11"></a></span>
<span id="cb611-12"><a href="models.html#cb611-12"></a>results &lt;-<span class="st"> </span>one_poll_per_pollster <span class="op">%&gt;%</span></span>
<span id="cb611-13"><a href="models.html#cb611-13"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">se =</span> <span class="kw">sd</span>(spread)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span></span>
<span id="cb611-14"><a href="models.html#cb611-14"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se, <span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se)</span></code></pre></div>
<p>A continuación, las utilizaremos para nuestro pronóstico.</p>
<div id="bayesian-approach" class="section level3">
<h3><span class="header-section-number">16.8.1</span> Enfoque bayesiano</h3>
<p>Los encuestadores tienden a hacer declaraciones probabilísticas sobre los resultados de las elecciones. Por ejemplo, “La probabilidad de que Obama gane el colegio electoral es 91%” es una declaración probabilística sobre un parámetro que en secciones anteriores hemos denotado con <span class="math inline">\(d\)</span>. Mostramos que para las elecciones del 2016, FiveThirtyEight le dio a Clinton una probabilidad de 81.4% de ganar el voto popular. Para hacer esto, utilizaron el enfoque bayesiano que describimos anteriormente.</p>
<p>Suponemos un modelo jerárquico similar al que hicimos para predecir el desempeño de un jugador de béisbol. Los libros de texto estadísticos escribirán el modelo así:</p>
<p><span class="math display">\[
\begin{aligned}
d &amp;\sim N(\mu, \tau^2) \mbox{ describes our best guess had we not seen any polling data}\\
\bar{X} \mid d &amp;\sim N(d, \sigma^2) \mbox{ describes randomness due to sampling and the pollster effect}
\end{aligned}
\]</span></p>
<p>Para hacer nuestro mejor pronóstico, notamos que antes de que haya datos de encuestas disponibles, podemos usar fuentes de datos que no son datos de encuestas. Un enfoque popular es utilizar lo que los encuestadores llaman <em>fundamentals</em>, que se basan en características que históricamente parecen tener un efecto a favor o en contra del partido en poder como, por ejemplo, el estado de la economía. No usaremos estos aquí. En cambio, usaremos <span class="math inline">\(\mu = 0\)</span>, que se interpreta como un modelo que no ofrece información sobre quién ganará. Para la desviación estándar, usaremos datos históricos recientes que muestran que el ganador del voto popular tiene una variabilidad promedio de aproximadamente 3.5%. Por lo tanto, fijamos <span class="math inline">\(\tau = 0.035\)</span>.</p>
<p>Ahora podemos usar las fórmulas para la distribución a posteriori del parámetro <span class="math inline">\(d\)</span>: la probabilidad de que <span class="math inline">\(d&gt;0\)</span> dado los datos de la encuesta observada:</p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="models.html#cb612-1"></a>mu &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb612-2"><a href="models.html#cb612-2"></a>tau &lt;-<span class="st"> </span><span class="fl">0.035</span></span>
<span id="cb612-3"><a href="models.html#cb612-3"></a>sigma &lt;-<span class="st"> </span>results<span class="op">$</span>se</span>
<span id="cb612-4"><a href="models.html#cb612-4"></a>Y &lt;-<span class="st"> </span>results<span class="op">$</span>avg</span>
<span id="cb612-5"><a href="models.html#cb612-5"></a>B &lt;-<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb612-6"><a href="models.html#cb612-6"></a></span>
<span id="cb612-7"><a href="models.html#cb612-7"></a>posterior_mean &lt;-<span class="st"> </span>B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>Y</span>
<span id="cb612-8"><a href="models.html#cb612-8"></a>posterior_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb612-9"><a href="models.html#cb612-9"></a></span>
<span id="cb612-10"><a href="models.html#cb612-10"></a>posterior_mean</span>
<span id="cb612-11"><a href="models.html#cb612-11"></a><span class="co">#&gt; [1] 0.0281</span></span>
<span id="cb612-12"><a href="models.html#cb612-12"></a>posterior_se</span>
<span id="cb612-13"><a href="models.html#cb612-13"></a><span class="co">#&gt; [1] 0.00615</span></span></code></pre></div>
<p>Para hacer una declaración de probabilidad, usamos el hecho de que la distribución a posteriori también es normal. Y tenemos un intervalo de confianza de Bayes de:</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb613-1"><a href="models.html#cb613-1"></a>posterior_mean <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">1.96</span>, <span class="fl">1.96</span>)<span class="op">*</span>posterior_se</span>
<span id="cb613-2"><a href="models.html#cb613-2"></a><span class="co">#&gt; [1] 0.0160 0.0401</span></span></code></pre></div>
<p>La probabilidad a posteriori <span class="math inline">\(\mbox{Pr}(d&gt;0 \mid \bar{X})\)</span> se puede calcular así:</p>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="models.html#cb614-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, posterior_mean, posterior_se)</span>
<span id="cb614-2"><a href="models.html#cb614-2"></a><span class="co">#&gt; [1] 1</span></span></code></pre></div>
<p>Esto dice que estamos 100% seguros de que Clinton ganará el voto popular, lo que parece demasiado confiado. Además, no está de acuerdo con el 81.4% de FiveThirtyEight. ¿Qué explica esta diferencia?</p>
</div>
<div id="el-sesgo-general" class="section level3">
<h3><span class="header-section-number">16.8.2</span> El sesgo general</h3>
<p>Una vez finalizadas las elecciones, se puede observar la diferencia entre las predicciones de los encuestadores y el resultado real. Una observación importante que nuestro modelo no considera es que es común ver un sesgo general que afecta a muchos encuestadores de la misma manera, que entonces conduce a que los datos observados estén correlacionados. No hay una buena explicación para esto, pero se observa en datos históricos: en una elección, el promedio de las encuestas favorece a los demócratas por 2%, luego en las siguientes elecciones favorece a los republicanos por 1%, entonces en las próximas elecciones no hay sesgo, luego en la siguiente los republicanos son los favoritos por 3%, y así sucesivamente. En 2016, las encuestas favorecieron a los demócratas por 1-2%.</p>
<p>Aunque sabemos que este sesgo afecta a nuestras encuestas, no tenemos forma de saber cuán grande es este sesgo hasta la noche de las elecciones. Como consecuencia, no podemos corregir nuestras encuestas para tomar este sesgo en cuenta. Lo que podemos hacer es incluir un término en nuestro modelo que explique esta variabilidad.</p>
</div>
<div id="representaciones-matemáticas-de-modelos" class="section level3">
<h3><span class="header-section-number">16.8.3</span> Representaciones matemáticas de modelos</h3>
<p>Imagínese que estamos recopilando datos de un encuestador y suponemos que no hay sesgo general. El encuestador recoge varias encuestas con un tamaño de muestra de <span class="math inline">\(N\)</span>, por lo que observamos varias mediciones de la variabilidad <span class="math inline">\(X_1, \dots, X_J\)</span>. La teoría nos dice que estas variables aleatorias tienen un valor esperado <span class="math inline">\(d\)</span> y un error estándar <span class="math inline">\(2 \sqrt{p(1-p)/N}\)</span>. Comencemos usando el siguiente modelo para describir la variabilidad observada:</p>
<p><span class="math display">\[
X_j = d + \varepsilon_j.
\]</span>
Usamos el índice <span class="math inline">\(j\)</span> para representar las diferentes encuestas y definimos <span class="math inline">\(\varepsilon_j\)</span> para ser una variable aleatoria que explica la variabilidad entre encuestas individuales introducida por el error de muestreo. Para hacer esto, suponemos que su promedio es 0 y su error estándar es <span class="math inline">\(2 \sqrt{p(1-p)/N}\)</span>. Si <span class="math inline">\(d\)</span> es 2.1 y el tamaño de la muestra para estas encuestas es de 2,000, podemos simular <span class="math inline">\(J=6\)</span> puntos de datos de este modelo así:</p>
<div class="sourceCode" id="cb615"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb615-1"><a href="models.html#cb615-1"></a><span class="kw">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb615-2"><a href="models.html#cb615-2"></a>J &lt;-<span class="st"> </span><span class="dv">6</span></span>
<span id="cb615-3"><a href="models.html#cb615-3"></a>N &lt;-<span class="st"> </span><span class="dv">2000</span></span>
<span id="cb615-4"><a href="models.html#cb615-4"></a>d &lt;-<span class="st"> </span><span class="fl">.021</span></span>
<span id="cb615-5"><a href="models.html#cb615-5"></a>p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span></span>
<span id="cb615-6"><a href="models.html#cb615-6"></a>X &lt;-<span class="st"> </span>d <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J, <span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">/</span><span class="st"> </span>N))</span></code></pre></div>
<p>Ahora supongamos que tenemos <span class="math inline">\(J=6\)</span> puntos de datos de <span class="math inline">\(I=5\)</span> diferentes encuestadores. Para representar esto, necesitamos dos índices, uno para el encuestador y otro para las encuestas que cada encuestador toma. Usamos <span class="math inline">\(X_{ij}\)</span> con <span class="math inline">\(i\)</span> representando al encuestador y <span class="math inline">\(j\)</span> representando la encuesta número <span class="math inline">\(j\)</span> de ese encuestador. Si aplicamos el mismo modelo, escribimos:</p>
<p><span class="math display">\[
X_{i,j} = d + \varepsilon_{i,j}
\]</span></p>
<p>Para simular datos, ahora tenemos que usar un bucle para simular los datos de cada encuestador:</p>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="models.html#cb616-1"></a>I &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb616-2"><a href="models.html#cb616-2"></a>J &lt;-<span class="st"> </span><span class="dv">6</span></span>
<span id="cb616-3"><a href="models.html#cb616-3"></a>N &lt;-<span class="st"> </span><span class="dv">2000</span></span>
<span id="cb616-4"><a href="models.html#cb616-4"></a>X &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>I, <span class="cf">function</span>(i){</span>
<span id="cb616-5"><a href="models.html#cb616-5"></a>  d <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J, <span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">/</span><span class="st"> </span>N))</span>
<span id="cb616-6"><a href="models.html#cb616-6"></a>})</span></code></pre></div>
<p>Los datos simulados realmente no parecen capturar las características de los datos reales:</p>
<p><img src="libro_files/figure-html/simulated-data-without-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El modelo anterior no toma en cuenta la variabilidad entre encuestadores. Para arreglar esto, añadimos un nuevo término para el efecto de los encuestadores. Usaremos <span class="math inline">\(h_i\)</span> para representar el sesgo del encuestador número <span class="math inline">\(i\)</span>. Le añadimos este nuevo término al modelo:</p>
<p><span class="math display">\[
X_{i,j} = d + h_i + \varepsilon_{i,j}
\]</span></p>
<p>Para simular datos de un encuestador específico, ahora necesitamos escojer un <span class="math inline">\(h_i\)</span> y luego añadir los <span class="math inline">\(\varepsilon\)</span>s. Entonces, para un encuestador específico, suponemos que <span class="math inline">\(\sigma_h\)</span> es 0.025:</p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="models.html#cb617-1"></a>I &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb617-2"><a href="models.html#cb617-2"></a>J &lt;-<span class="st"> </span><span class="dv">6</span></span>
<span id="cb617-3"><a href="models.html#cb617-3"></a>N &lt;-<span class="st"> </span><span class="dv">2000</span></span>
<span id="cb617-4"><a href="models.html#cb617-4"></a>d &lt;-<span class="st"> </span><span class="fl">.021</span></span>
<span id="cb617-5"><a href="models.html#cb617-5"></a>p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb617-6"><a href="models.html#cb617-6"></a>h &lt;-<span class="st"> </span><span class="kw">rnorm</span>(I, <span class="dv">0</span>, <span class="fl">0.025</span>)</span>
<span id="cb617-7"><a href="models.html#cb617-7"></a>X &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>I, <span class="cf">function</span>(i){</span>
<span id="cb617-8"><a href="models.html#cb617-8"></a>  d <span class="op">+</span><span class="st"> </span>h[i] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J, <span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">/</span><span class="st"> </span>N))</span>
<span id="cb617-9"><a href="models.html#cb617-9"></a>})</span></code></pre></div>
<p>Los datos simulados ahora se parecen más a los datos reales:</p>
<p><img src="libro_files/figure-html/simulated-pollster-data-1.png" width="35%" style="display: block; margin: auto;" /></p>
<p>Noten que <span class="math inline">\(h_i\)</span> es común a todas las variabilidades observadas de un encuestador específico. Diferentes encuestadores tienen una <span class="math inline">\(h_i\)</span> diferente, lo que explica por qué cuando vemos los datos de los distintos encuestadores, podemos ver los diferentes grupos de puntos desplazarse hacia arriba y hacia abajo.</p>
<p>Ahora, en el modelo anterior, suponemos que el promedio de los sesgos de los encuestadores es 0. Creemos que para cada encuestador sesgado a favor de nuestro partido, hay otro a favor del otro partido y suponemos que la desviación estándar es <span class="math inline">\(\sigma_h\)</span>. Pero históricamente vemos que cada elección tiene un sesgo general que afecta a todas las encuestas. Podemos observar esto con los datos del 2016, pero si recopilamos datos históricos, vemos que el promedio de las encuestas falla por más de lo que predicen modelos como el anterior. Para ver esto, tomaríamos el promedio de las encuestas para cada año electoral y lo compararíamos con el valor real. Si hiciéramos esto, veríamos una diferencia con una desviación estándar de entre 2-3%. Para incorporar esto en el modelo, podemos añadir otro término para explicar esta variabilidad:
<span class="math display">\[
X_{i,j} = d + b + h_i + \varepsilon_{i,j}.
\]</span></p>
<p>Aquí <span class="math inline">\(b\)</span> es una variable aleatoria que explica la variabilidad de elección a elección. Esta variable aleatoria cambia de elección a elección, pero para cualquier elección dada, es la misma para todos los encuestadores y las encuestas dentro de la elección. Por eso no tiene índices. Esto implica que todas las variables aleatorias <span class="math inline">\(X_{i,j}\)</span> para un año electoral están correlacionadas ya que todas tienen <span class="math inline">\(b\)</span> en común.</p>
<p>Una forma de interpretar <span class="math inline">\(b\)</span> es como la diferencia entre el promedio de todas las encuestas de todos los encuestadores y el resultado real de la elección. Como no conocemos el resultado real hasta después de las elecciones, no podemos estimar <span class="math inline">\(b\)</span> hasta entonces. Sin embargo, podemos estimar <span class="math inline">\(b\)</span> de las elecciones anteriores y estudiar la distribución de estos valores. Conforme a este enfoque, suponemos que, a lo largo de los años electorales, <span class="math inline">\(b\)</span> tiene el valor esperado 0 y el error estándar es aproximadamente <span class="math inline">\(\sigma_b = 0.025\)</span>.</p>
<p>Una implicación de añadir este término al modelo es que la desviación estándar de <span class="math inline">\(X_{i,j}\)</span> es mayor que lo que llamamos anteriormente <span class="math inline">\(\sigma\)</span>, que combina la variabilidad del encuestador y la variabilidad de la muestra, y que se estimó con:</p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="models.html#cb618-1"></a><span class="kw">sd</span>(one_poll_per_pollster<span class="op">$</span>spread)</span>
<span id="cb618-2"><a href="models.html#cb618-2"></a><span class="co">#&gt; [1] 0.0242</span></span></code></pre></div>
<p>Esta estimación no incluye la variabilidad introducida por <span class="math inline">\(b\)</span>. Tengan en cuenta que como:</p>
<p><span class="math display">\[
\bar{X} = d + b + \frac{1}{N}\sum_{i=1}^N X_i,
\]</span></p>
<p>la desviación estándar de <span class="math inline">\(\bar{X}\)</span> es:</p>
<p><span class="math display">\[
\sqrt{\sigma^2/N + \sigma_b^2}.
\]</span>
Ya que la misma <span class="math inline">\(b\)</span> está en cada medición, el promedio no reduce la variabilidad introducida por este término. Este es un punto importante: no importa cuántas encuestas realicen, este sesgo no se reduce.</p>
<p>Si rehacemos el cálculo bayesiano tomando en cuenta esta variabilidad, obtenemos un resultado mucho más cercano al de FiveThirtyEight:</p>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb619-1"><a href="models.html#cb619-1"></a>mu &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb619-2"><a href="models.html#cb619-2"></a>tau &lt;-<span class="st"> </span><span class="fl">0.035</span></span>
<span id="cb619-3"><a href="models.html#cb619-3"></a>sigma &lt;-<span class="st"> </span><span class="kw">sqrt</span>(results<span class="op">$</span>se<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="fl">.025</span><span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb619-4"><a href="models.html#cb619-4"></a>Y &lt;-<span class="st"> </span>results<span class="op">$</span>avg</span>
<span id="cb619-5"><a href="models.html#cb619-5"></a>B &lt;-<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb619-6"><a href="models.html#cb619-6"></a></span>
<span id="cb619-7"><a href="models.html#cb619-7"></a>posterior_mean &lt;-<span class="st"> </span>B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>Y</span>
<span id="cb619-8"><a href="models.html#cb619-8"></a>posterior_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb619-9"><a href="models.html#cb619-9"></a></span>
<span id="cb619-10"><a href="models.html#cb619-10"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, posterior_mean, posterior_se)</span>
<span id="cb619-11"><a href="models.html#cb619-11"></a><span class="co">#&gt; [1] 0.817</span></span></code></pre></div>
</div>
<div id="prediciendo-el-colegio-electoral" class="section level3">
<h3><span class="header-section-number">16.8.4</span> Prediciendo el colegio electoral</h3>
<p>Hasta ahora nos hemos enfocado en el voto popular. Pero en Estados Unidos, las elecciones no se deciden por el voto popular, sino por lo que se conoce como el colegio electoral. Cada estado obtiene una cantidad de votos electorales que dependen, de una manera algo compleja, del tamaño de la población del estado. Aquí están los 5 principales estados clasificados por votos electorales en 2016.</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="models.html#cb620-1"></a>results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">5</span>, electoral_votes)</span>
<span id="cb620-2"><a href="models.html#cb620-2"></a><span class="co">#&gt;          state electoral_votes clinton trump others</span></span>
<span id="cb620-3"><a href="models.html#cb620-3"></a><span class="co">#&gt; 1   California              55    61.7  31.6    6.7</span></span>
<span id="cb620-4"><a href="models.html#cb620-4"></a><span class="co">#&gt; 2        Texas              38    43.2  52.2    4.5</span></span>
<span id="cb620-5"><a href="models.html#cb620-5"></a><span class="co">#&gt; 3      Florida              29    47.8  49.0    3.2</span></span>
<span id="cb620-6"><a href="models.html#cb620-6"></a><span class="co">#&gt; 4     New York              29    59.0  36.5    4.5</span></span>
<span id="cb620-7"><a href="models.html#cb620-7"></a><span class="co">#&gt; 5     Illinois              20    55.8  38.8    5.4</span></span>
<span id="cb620-8"><a href="models.html#cb620-8"></a><span class="co">#&gt; 6 Pennsylvania              20    47.9  48.6    3.6</span></span></code></pre></div>
<p>Con algunas excepciones que no discutimos, los votos electorales se ganan todo o nada. Por ejemplo, si un candidato gana California con solo 1 voto, aún obtiene los 55 votos electorales. Esto significa que al ganar algunos estados grandes por un amplio margen, pero al perder muchos estados pequeños por pequeños márgenes, se puede ganar el voto popular, pero perder el colegio electoral que es lo que decide el ganador. Esto sucedió en 1876, 1888, 2000 y 2016. La idea detrás de esto es evitar que algunos estados grandes tengan el poder de dominar las elecciones presidenciales. Sin embargo, muchas personas en Estados Unidos consideran que el colegio electoral es injusto y les gustaría abolirlo.</p>
<p>Ahora estamos listos para predecir el resultado del colegio electoral para 2016. Comenzamos agregando los resultados de una encuesta realizada durante la última semana antes de las elecciones. Utilizamos <code>str_detect</code>, una función que discutiremos más adelante en la Sección <a href="procesamiento-de-cadenas.html#stringr">24.1</a>, para eliminar encuestas que cubren solo parte de un estado.</p>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="models.html#cb621-1"></a>results &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb621-2"><a href="models.html#cb621-2"></a><span class="st">  </span><span class="kw">filter</span>(state<span class="op">!=</span><span class="st">&quot;U.S.&quot;</span> <span class="op">&amp;</span></span>
<span id="cb621-3"><a href="models.html#cb621-3"></a><span class="st">           </span><span class="op">!</span><span class="kw">str_detect</span>(state, <span class="st">&quot;CD&quot;</span>) <span class="op">&amp;</span></span>
<span id="cb621-4"><a href="models.html#cb621-4"></a><span class="st">           </span>enddate <span class="op">&gt;=</span><span class="st">&quot;2016-10-31&quot;</span> <span class="op">&amp;</span></span>
<span id="cb621-5"><a href="models.html#cb621-5"></a><span class="st">           </span>(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span></span>
<span id="cb621-6"><a href="models.html#cb621-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb621-7"><a href="models.html#cb621-7"></a><span class="st">  </span><span class="kw">group_by</span>(state) <span class="op">%&gt;%</span></span>
<span id="cb621-8"><a href="models.html#cb621-8"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">sd =</span> <span class="kw">sd</span>(spread), <span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span></span>
<span id="cb621-9"><a href="models.html#cb621-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state))</span>
<span id="cb621-10"><a href="models.html#cb621-10"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span></code></pre></div>
<p>Aquí están los cinco estados con los resultados más cerrados según las encuestas:</p>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="models.html#cb622-1"></a>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">abs</span>(avg))</span>
<span id="cb622-2"><a href="models.html#cb622-2"></a><span class="co">#&gt; # A tibble: 47 x 4</span></span>
<span id="cb622-3"><a href="models.html#cb622-3"></a><span class="co">#&gt;   state               avg     sd     n</span></span>
<span id="cb622-4"><a href="models.html#cb622-4"></a><span class="co">#&gt;   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;</span></span>
<span id="cb622-5"><a href="models.html#cb622-5"></a><span class="co">#&gt; 1 Florida         0.00356 0.0163     7</span></span>
<span id="cb622-6"><a href="models.html#cb622-6"></a><span class="co">#&gt; 2 North Carolina -0.00730 0.0306     9</span></span>
<span id="cb622-7"><a href="models.html#cb622-7"></a><span class="co">#&gt; 3 Ohio           -0.0104  0.0252     6</span></span>
<span id="cb622-8"><a href="models.html#cb622-8"></a><span class="co">#&gt; 4 Nevada          0.0169  0.0441     7</span></span>
<span id="cb622-9"><a href="models.html#cb622-9"></a><span class="co">#&gt; 5 Iowa           -0.0197  0.0437     3</span></span>
<span id="cb622-10"><a href="models.html#cb622-10"></a><span class="co">#&gt; # … with 42 more rows</span></span></code></pre></div>
<p>Ahora utilizaremos el comando <code>left_join</code> que nos permitirá añadir fácilmente el número de votos electorales para cada estado del conjunto de datos <code>us_electoral_votes_2016</code>. Describiremos esta función en detalle en el capítulo sobre <em>data wrangling</em>. Aquí, simplemente observaremos que la función combina los dos conjuntos de datos para que la información del segundo argumento se agregue a la información del primero:</p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb623-1"><a href="models.html#cb623-1"></a>results &lt;-<span class="st"> </span><span class="kw">left_join</span>(results, results_us_election_<span class="dv">2016</span>, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>)</span></code></pre></div>
<p>Observen que algunos estados no tienen encuestas porque prácticamente se conoce el ganador:</p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="models.html#cb624-1"></a>results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="op">!</span>state <span class="op">%in%</span><span class="st"> </span>results<span class="op">$</span>state) <span class="op">%&gt;%</span></span>
<span id="cb624-2"><a href="models.html#cb624-2"></a><span class="st">  </span><span class="kw">pull</span>(state)</span>
<span id="cb624-3"><a href="models.html#cb624-3"></a><span class="co">#&gt; [1] &quot;Rhode Island&quot;         &quot;Alaska&quot;               &quot;Wyoming&quot;             </span></span>
<span id="cb624-4"><a href="models.html#cb624-4"></a><span class="co">#&gt; [4] &quot;District of Columbia&quot;</span></span></code></pre></div>
<p>No se realizaron encuestas en DC, Rhode Island, Alaska y Wyoming porque los demócratas seguramente ganarán en los primeros dos y los republicanos en los últimos dos.</p>
<p>Debido a que no podemos estimar la desviación estándar para los estados con una sola encuesta, la calcularemos como la mediana de las desviaciones estándar estimadas para los estados con más de una encuesta:</p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="models.html#cb625-1"></a>results &lt;-<span class="st"> </span>results <span class="op">%&gt;%</span></span>
<span id="cb625-2"><a href="models.html#cb625-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sd =</span> <span class="kw">ifelse</span>(<span class="kw">is.na</span>(sd), <span class="kw">median</span>(results<span class="op">$</span>sd, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), sd))</span></code></pre></div>
<p>Para hacer argumentos probabilísticos, utilizaremos una simulación Monte Carlo. Para cada estado, aplicamos el enfoque bayesiano para generar una <span class="math inline">\(d\)</span> para el día de elecciones. Podríamos construir las probabilidades a priori de cada estado basado en la historia reciente. Sin embargo, para simplificar, asignamos una probabilidad a priori a cada estado que supone que no sabemos nada sobre lo que sucederá. Dado que de un año electoral a otro, los resultados de un estado específico no cambian tanto, asignaremos una desviación estándar de 2% o <span class="math inline">\(\tau=0.02\)</span>. Por ahora, vamos a suponer, incorrectamente, que los resultados de la encuesta de cada estado son independientes. El código para el cálculo bayesiano bajo estos supuestos se ve así:</p>
<pre><code>#&gt; # A tibble: 47 x 12
#&gt;   state     avg      sd     n electoral_votes clinton trump others
#&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;           &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 Alab… -0.149  2.53e-2     3               9    34.4  62.1    3.6
#&gt; 2 Ariz… -0.0326 2.70e-2     9              11    45.1  48.7    6.2
#&gt; 3 Arka… -0.151  9.90e-4     2               6    33.7  60.6    5.8
#&gt; 4 Cali…  0.260  3.87e-2     5              55    61.7  31.6    6.7
#&gt; 5 Colo…  0.0452 2.95e-2     7               9    48.2  43.3    8.6
#&gt; # … with 42 more rows, and 4 more variables: sigma &lt;dbl&gt;, B &lt;dbl&gt;,
#&gt; #   posterior_mean &lt;dbl&gt;, posterior_se &lt;dbl&gt;</code></pre>
<p>Las estimaciones basadas en las probabilidades a posteriori mueven las estimaciones hacia 0, aunque los estados con muchas encuestas están menos influenciados. Esto se espera ya que mientras más datos de encuestas recolectamos, más confiamos en esos resultados:</p>
<p><img src="libro_files/figure-html/posterior-versus-original-estimates-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Ahora repetimos esto 10,000 veces y generamos un resultado de la probabilidad a posteriori. En cada iteración, hacemos un seguimiento del número total de votos electorales para Clinton. Recuerden que Trump obtiene 270 votos electorales menos los votos para Clinton. También noten que la razón por la que añadimos 7 en el código es para tomar en cuenta Rhode Island y DC:</p>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb627-1"><a href="models.html#cb627-1"></a>B &lt;-<span class="st"> </span><span class="dv">10000</span></span>
<span id="cb627-2"><a href="models.html#cb627-2"></a>mu &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb627-3"><a href="models.html#cb627-3"></a>tau &lt;-<span class="st"> </span><span class="fl">0.02</span></span>
<span id="cb627-4"><a href="models.html#cb627-4"></a>clinton_EV &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {</span>
<span id="cb627-5"><a href="models.html#cb627-5"></a>  results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> sd<span class="op">/</span><span class="kw">sqrt</span>(n),</span>
<span id="cb627-6"><a href="models.html#cb627-6"></a>                     <span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),</span>
<span id="cb627-7"><a href="models.html#cb627-7"></a>                     <span class="dt">posterior_mean =</span> B <span class="op">*</span><span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>B) <span class="op">*</span><span class="st"> </span>avg,</span>
<span id="cb627-8"><a href="models.html#cb627-8"></a>                     <span class="dt">posterior_se =</span> <span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>)),</span>
<span id="cb627-9"><a href="models.html#cb627-9"></a>                     <span class="dt">result =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(posterior_mean),</span>
<span id="cb627-10"><a href="models.html#cb627-10"></a>                                    posterior_mean, posterior_se),</span>
<span id="cb627-11"><a href="models.html#cb627-11"></a>                     <span class="dt">clinton =</span> <span class="kw">ifelse</span>(result <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, electoral_votes, <span class="dv">0</span>)) <span class="op">%&gt;%</span></span>
<span id="cb627-12"><a href="models.html#cb627-12"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">clinton =</span> <span class="kw">sum</span>(clinton)) <span class="op">%&gt;%</span></span>
<span id="cb627-13"><a href="models.html#cb627-13"></a><span class="st">    </span><span class="kw">pull</span>(clinton) <span class="op">+</span><span class="st"> </span><span class="dv">7</span></span>
<span id="cb627-14"><a href="models.html#cb627-14"></a>})</span>
<span id="cb627-15"><a href="models.html#cb627-15"></a></span>
<span id="cb627-16"><a href="models.html#cb627-16"></a><span class="kw">mean</span>(clinton_EV <span class="op">&gt;</span><span class="st"> </span><span class="dv">269</span>)</span>
<span id="cb627-17"><a href="models.html#cb627-17"></a><span class="co">#&gt; [1] 0.998</span></span></code></pre></div>
<p>Este modelo le da a Clinton una probabilidad de ganar mayor que 99%.
<!--Here is a histogram of the Monte Carlo outcomes:

<img src="libro_files/figure-html/election-forecast-posterior-no-bias-1.png" width="70%" style="display: block; margin: auto;" />
-->
El Consorcio Electoral de Princeton hizo una predicción similar. Ahora sabemos que fallaron por mucho. ¿Que pasó?</p>
<p>El modelo anterior ignora el sesgo general y supone que los resultados de diferentes estados son independientes. Después de las elecciones, nos dimos cuenta de que el sesgo general en 2016 no era tan grande: estaba entre 1 y 2%. Pero debido a que la elección estuvo cerrada en varios estados grandes y estos estados tenían una gran cantidad de encuestas, los encuestadores que ignoraron el sesgo general subestimaron considerablemente el error estándar. Utilizando la notación que introducimos, suponieron que el error estándar era <span class="math inline">\(\sqrt{\sigma^2/N}\)</span> que con N grande es bastante más pequeño que la estimación más precisa
<span class="math inline">\(\sqrt{\sigma^2/N + \sigma_b^2}\)</span>. FiveThirtyEight, que modela el sesgo general de una manera bastante sofisticada, informó un resultado más cercano. Podemos simular los resultados ahora con un término de sesgo. Para el nivel de estado, el sesgo general puede ser mayor, por lo que lo establecemos en <span class="math inline">\(\sigma_b = 0.03\)</span>:</p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="models.html#cb628-1"></a>tau &lt;-<span class="st"> </span><span class="fl">0.02</span></span>
<span id="cb628-2"><a href="models.html#cb628-2"></a>bias_sd &lt;-<span class="st"> </span><span class="fl">0.03</span></span>
<span id="cb628-3"><a href="models.html#cb628-3"></a>clinton_EV_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, {</span>
<span id="cb628-4"><a href="models.html#cb628-4"></a>  results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> <span class="kw">sqrt</span>(sd<span class="op">^</span><span class="dv">2</span><span class="op">/</span>n <span class="op">+</span><span class="st"> </span>bias_sd<span class="op">^</span><span class="dv">2</span>),</span>
<span id="cb628-5"><a href="models.html#cb628-5"></a>                     <span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),</span>
<span id="cb628-6"><a href="models.html#cb628-6"></a>                     <span class="dt">posterior_mean =</span> B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>avg,</span>
<span id="cb628-7"><a href="models.html#cb628-7"></a>                     <span class="dt">posterior_se =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>)),</span>
<span id="cb628-8"><a href="models.html#cb628-8"></a>                     <span class="dt">result =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(posterior_mean),</span>
<span id="cb628-9"><a href="models.html#cb628-9"></a>                                    posterior_mean, posterior_se),</span>
<span id="cb628-10"><a href="models.html#cb628-10"></a>                     <span class="dt">clinton =</span> <span class="kw">ifelse</span>(result<span class="op">&gt;</span><span class="dv">0</span>, electoral_votes, <span class="dv">0</span>)) <span class="op">%&gt;%</span></span>
<span id="cb628-11"><a href="models.html#cb628-11"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">clinton =</span> <span class="kw">sum</span>(clinton) <span class="op">+</span><span class="st"> </span><span class="dv">7</span>) <span class="op">%&gt;%</span></span>
<span id="cb628-12"><a href="models.html#cb628-12"></a><span class="st">    </span><span class="kw">pull</span>(clinton)</span>
<span id="cb628-13"><a href="models.html#cb628-13"></a>})</span>
<span id="cb628-14"><a href="models.html#cb628-14"></a><span class="kw">mean</span>(clinton_EV_<span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">269</span>)</span>
<span id="cb628-15"><a href="models.html#cb628-15"></a><span class="co">#&gt; [1] 0.848</span></span></code></pre></div>
<p>Esto nos da una estimación mucho más sensata. Al observar los resultados de la simulación, vemos cómo el término de sesgo agrega variabilidad a los resultados finales.</p>
<p><img src="libro_files/figure-html/comparison-forecast-with-and-without-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El modelo de FiveThirtyEight incluye muchas otras características que no describimos aquí. Una es que modelan la variabilidad con distribuciones que tienen altas probabilidades para eventos extremos en comparación con la distribución normal. Una forma que nosotros podemos hacerlo es cambiando la distribución utilizada en la simulación de una distribución normal a una distribución t. FiveThirtyEight predijo una probabilidad de 71%.</p>
</div>
<div id="pronósticos" class="section level3">
<h3><span class="header-section-number">16.8.5</span> Pronósticos</h3>
<p>A los pronosticadores les gusta hacer predicciones mucho antes de las elecciones. Las predicciones se adaptan a medida que salen nuevas encuestas. Sin embargo, una pregunta importante que deben hacer los pronosticadores es: ¿cuán informativas son las encuestas que se hacen varias semanas antes de las elecciones sobre la elección real? Aquí estudiamos la variabilidad de los resultados de las encuestas a lo largo del tiempo.</p>
<p>Para asegurarnos de que la variabilidad que observamos no se debe a efectos del encuestador, estudiemos los datos de un encuestador:</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="models.html#cb629-1"></a>one_pollster &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb629-2"><a href="models.html#cb629-2"></a><span class="st">  </span><span class="kw">filter</span>(pollster <span class="op">==</span><span class="st"> &quot;Ipsos&quot;</span> <span class="op">&amp;</span><span class="st"> </span>state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb629-3"><a href="models.html#cb629-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</span></code></pre></div>
<p>Como no hay efecto de encuestador, quizás el error estándar teórico coincide con la desviación estándar derivada de los datos. Calculamos ambos aquí:</p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="models.html#cb630-1"></a>se &lt;-<span class="st"> </span>one_pollster <span class="op">%&gt;%</span></span>
<span id="cb630-2"><a href="models.html#cb630-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">empirical =</span> <span class="kw">sd</span>(spread),</span>
<span id="cb630-3"><a href="models.html#cb630-3"></a>            <span class="dt">theoretical =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>(spread) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(spread))<span class="op">/</span></span>
<span id="cb630-4"><a href="models.html#cb630-4"></a><span class="st">                                     </span><span class="kw">min</span>(samplesize)))</span>
<span id="cb630-5"><a href="models.html#cb630-5"></a>se</span>
<span id="cb630-6"><a href="models.html#cb630-6"></a><span class="co">#&gt;   empirical theoretical</span></span>
<span id="cb630-7"><a href="models.html#cb630-7"></a><span class="co">#&gt; 1    0.0403      0.0326</span></span></code></pre></div>
<p>Pero la desviación estándar empírica es más alta que la estimación teórica más alta posible. Además, los datos de la variabilidad no se ven normales como la teoría predeciría:</p>
<p><img src="libro_files/figure-html/time-trend-variability-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Los modelos que hemos descrito incluyen la variabilidad entre encuestadores y el error de muestreo. Pero este gráfico es para un encuestador y la variabilidad que vemos ciertamente no la explica el error de muestreo. ¿De dónde viene la variabilidad extra? Los siguientes gráficos muestran un fuerte argumento de que esta variabilidad proviene de fluctuaciones de tiempo no explicadas por la teoría que supone que <span class="math inline">\(p\)</span> es fijo:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="libro_files/figure-html/time-trend-estimate-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Algunos de los picos y valles que vemos coinciden con eventos como las convenciones de los partidos, que tienden a dar un impulso a los candidatos. Vemos consistencia entre los distintos encuestadores en cuanto a la localización de los picos y valles.</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="libro_files/figure-html/time-trend-estimate-several-pollsters-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Esto implica que, si vamos a pronosticar, nuestro modelo debe incluir un término que toma en cuenta el efecto temporal. Necesitamos escribir un modelo que incluya un término de sesgo para el tiempo:</p>
<p><span class="math display">\[
Y_{i,j,t} = d + b + h_j + b_t + \varepsilon_{i,j,t}
\]</span></p>
<p>La desviación estándar de <span class="math inline">\(b_t\)</span> va a depender de <span class="math inline">\(t\)</span> ya que en cuanto más nos acercamos al día de las elecciones, más cerca de 0 debería estar este término de sesgo.</p>
<p>Los encuestadores también intentan estimar las tendencias de estos datos e incorporarlos en sus predicciones. Podemos modelar la tendencia temporal con una función <span class="math inline">\(f(t)\)</span> y reescribir el modelo así:</p>
<p><span class="math display">\[
Y_{i,j,t} = d + b + h_j + b_t + f(t) + \varepsilon_{i,jt,}
\]</span></p>
<p>Usualmente vemos el estimado <span class="math inline">\(f(t)\)</span> no para la diferencia, sino para los porcentajes reales para cada candidato así:</p>
<p><img src="libro_files/figure-html/trend-estimate-for-all-pollsters-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Una vez que se seleccione un modelo como el anterior, podemos usar datos históricos y actuales para estimar todos los parámetros necesarios para hacer predicciones. Existe una variedad de métodos para estimar tendencias <span class="math inline">\(f(t)\)</span> que discutimos en la parte de <em>machine learning</em>.</p>
</div>
</div>
<div id="ejercicios-32" class="section level2">
<h2><span class="header-section-number">16.9</span> Ejercicios</h2>
<p>1. Crea esta tabla:</p>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb633-1"><a href="models.html#cb633-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb633-2"><a href="models.html#cb633-2"></a><span class="kw">library</span>(dslabs)</span>
<span id="cb633-3"><a href="models.html#cb633-3"></a><span class="kw">data</span>(<span class="st">&quot;polls_us_election_2016&quot;</span>)</span>
<span id="cb633-4"><a href="models.html#cb633-4"></a>polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb633-5"><a href="models.html#cb633-5"></a><span class="st">  </span><span class="kw">filter</span>(state <span class="op">!=</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb633-6"><a href="models.html#cb633-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</span></code></pre></div>
<p>Ahora, para cada encuesta, use el CLT para crear un intervalo de confianza de 95% para la diferencia informada por cada encuesta. Llame al objeto resultante <code>cis</code> con columnas inferior y superior para los límites de los intervalos de confianza. Utilice la función <code>select</code> para mantener las columnas <code>state, startdate, end date, pollster, grade, spread, lower, upper</code>.</p>
<p>2. Puede añadir el resultado final a la tabla <code>cis</code> que acaba de crear utilizando la función <code>right_join</code> así:</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="models.html#cb634-1"></a>add &lt;-<span class="st"> </span>results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb634-2"><a href="models.html#cb634-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">actual_spread =</span> clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb634-3"><a href="models.html#cb634-3"></a><span class="st">  </span><span class="kw">select</span>(state, actual_spread)</span>
<span id="cb634-4"><a href="models.html#cb634-4"></a>cis &lt;-<span class="st"> </span>cis <span class="op">%&gt;%</span></span>
<span id="cb634-5"><a href="models.html#cb634-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state)) <span class="op">%&gt;%</span></span>
<span id="cb634-6"><a href="models.html#cb634-6"></a><span class="st">  </span><span class="kw">left_join</span>(add, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>)</span></code></pre></div>
<p>Ahora determine con qué frecuencia el intervalo de confianza de 95% incluye el resultado real.</p>
<p>3. Repita esto, pero muestre la proporción de veces que cada encuestador acierta. Muestre solo encuestadores con más de 5 encuestas y póngalos en orden de mejor a peor. Muestre el número de encuestas realizadas por cada encuestador y la calificación de FiveThirtyEight para cada encuestador. Sugerencia: use <code>n=n(), grade = grade[1]</code> en la llamada a <code>summarize</code>.</p>
<p>4. Repita el ejercicio 3, pero en lugar de estratificar por encuestador, estratifique por estado. Recuerden que aquí no podemos mostrar calificaciones.</p>
<p>5. Haga un diagrama de barras basado en el resultado del ejercicio 4. Use <code>coord_flip</code>.</p>
<p>6. Para cada encuesta, calcule la diferencia entre la diferencia que predijimos y la diferencia observada. Añada una columna a la tabla <code>cis</code>. Entonces, añada otra columna llamada <code>hit</code> que es <code>TRUE</code> cuando los signos son los mismos. Sugerencia: use la función <code>sign</code>. Llame al objeto <code>resids</code>.</p>
<p>7. Cree un gráfico como en el ejercicio 5, pero para la proporción de veces que los signos de la diferencia fueron iguales.</p>
<p>8. En el ejercicio 7, vemos que para la mayoría de los estados las encuestas acertaron el 100% de las veces. En solo 9 estados las encuestas fallaron más de 25% de las veces. En particular, observe que en Wisconsin todas las encuestas se equivocaron. En Pennsylvania y Michigan, más de 90% de las encuestas tenían los signos incorrectos. Haga un histograma de los errores. ¿Cuál es la mediana de estos errores?</p>
<p>9. Vemos que a nivel estatal, el error medio fue 3% a favor de Clinton. La distribución no está centrada en 0, sino en 0.03. Este es el sesgo general que describimos en la sección anterior. Cree un diagrama de caja para ver si el sesgo fue general para todos los estados o si afectó a algunos estados de manera diferente. Utilice <code>filter(grade %in% c("A+","A","A-","B+") | is.na(grade)))</code> para incluir solo encuestadores con altas calificaciones.</p>
<p>10. Algunos de estos estados solo tienen unas pocas encuestas. Repita el ejercicio 9, pero solo incluya estados con 5 o más encuestas buenas. Sugerencia: use <code>group_by</code>, <code>filter</code> y luego <code>ungroup</code>. Verá que el Oeste (Washington, Nuevo México, California) subestimó el desempeño de Hillary, mientras que el Medio Oeste (Michigan, Pennsylvania, Wisconsin, Ohio, Missouri) lo sobrestimó. En nuestra simulación, no modelamos este comportamiento ya que añadimos un sesgo general, en lugar de un sesgo regional. Tenga en cuenta que algunos encuestadores ahora pueden modelar la correlación entre estados similares y estimar esta correlación a partir de datos históricos. Para obtener más información sobre esto, puede aprender sobre efectos aleatorios y modelos mixtos.</p>

</div>
<div id="t-dist" class="section level2">
<h2><span class="header-section-number">16.10</span> La distribución t</h2>
<p>Arriba utilizamos el CLT con un tamaño de muestra de 15. Como estamos estimando un segundo parámetro <span class="math inline">\(\sigma\)</span>, se introduce más variabilidad a nuestro intervalo de confianza, lo que da como resultado intervalos muy pequeños. Para tamaños de muestra muy grandes, esta variabilidad adicional es insignificante, pero, en general, para valores menores de 30 debemos ser cautelosos al usar el CLT.</p>
<p>Sin embargo, si se sabe que los datos en la urna siguen una distribución normal, entonces tenemos una teoría matemática que nos dice cuánto más grande necesitamos hacer los intervalos para tomar en cuenta la estimación de <span class="math inline">\(\sigma\)</span>. Usando esta teoría, podemos construir intervalos de confianza para cualquier <span class="math inline">\(N\)</span>. Pero, de nuevo, esto funciona solo si <strong>sabemos que los datos en la urna siguen una distribución normal</strong>. Entonces, para los datos 0, 1 de nuestro modelo de urna anterior, esta teoría definitivamente no aplica.</p>
<p>La estadística en la que se basan los intervalos de confianza para <span class="math inline">\(d\)</span> es:</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - d}{\sigma/\sqrt{N}}
\]</span></p>
<p>El CLT nos dice que la distribución de Z es aproximadamente normal con valor esperado 0 y error estándar 1. Pero en la práctica no sabemos <span class="math inline">\(\sigma\)</span>, entonces usamos:</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - d}{s/\sqrt{N}}
\]</span></p>
<p>Al sustituir <span class="math inline">\(\sigma\)</span> con <span class="math inline">\(s\)</span>, introducimos cierta variabilidad. La teoría nos dice que <span class="math inline">\(Z\)</span> sigue una distribución t con <span class="math inline">\(N-1\)</span> <em>grados de libertad</em>. Los grados de libertad son un parámetro que controla la variabilidad a través de colas más pesadas:</p>
<p><img src="libro_files/figure-html/t-distribution-examples-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Si estamos dispuestos a suponer que los datos del efecto del encuestador siguen una distribución normal, según la muestra de datos <span class="math inline">\(X_1, \dots, X_N\)</span>,</p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb635-1"><a href="models.html#cb635-1"></a>one_poll_per_pollster <span class="op">%&gt;%</span></span>
<span id="cb635-2"><a href="models.html#cb635-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample=</span>spread)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>()</span></code></pre></div>
<p><img src="libro_files/figure-html/poll-spread-qq-1.png" width="70%" style="display: block; margin: auto;" />
entonces <span class="math inline">\(Z\)</span> sigue una distribución t con <span class="math inline">\(N-1\)</span> grados de libertad. Por eso, quizás un mejor intervalo de confianza para <span class="math inline">\(d\)</span> es:</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="models.html#cb636-1"></a>z &lt;-<span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="kw">nrow</span>(one_poll_per_pollster)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb636-2"><a href="models.html#cb636-2"></a>one_poll_per_pollster <span class="op">%&gt;%</span></span>
<span id="cb636-3"><a href="models.html#cb636-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">moe =</span> z<span class="op">*</span><span class="kw">sd</span>(spread)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span></span>
<span id="cb636-4"><a href="models.html#cb636-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span>moe, <span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span>moe)</span>
<span id="cb636-5"><a href="models.html#cb636-5"></a><span class="co">#&gt; # A tibble: 1 x 4</span></span>
<span id="cb636-6"><a href="models.html#cb636-6"></a><span class="co">#&gt;      avg    moe  start    end</span></span>
<span id="cb636-7"><a href="models.html#cb636-7"></a><span class="co">#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb636-8"><a href="models.html#cb636-8"></a><span class="co">#&gt; 1 0.0290 0.0134 0.0156 0.0424</span></span></code></pre></div>
<p>que es un poco más grande que cuando usamos la distribución normal. Esto es porque:</p>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb637-1"><a href="models.html#cb637-1"></a><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">14</span>)</span>
<span id="cb637-2"><a href="models.html#cb637-2"></a><span class="co">#&gt; [1] 2.14</span></span></code></pre></div>
<p>es más grande que:</p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="models.html#cb638-1"></a><span class="kw">qnorm</span>(<span class="fl">0.975</span>)</span>
<span id="cb638-2"><a href="models.html#cb638-2"></a><span class="co">#&gt; [1] 1.96</span></span></code></pre></div>
<p>La distribución t también se puede usar para modelar errores cuando esperamos que la probabilidad de grandes desviaciones de la media sea mayor de lo que dicta la distribución normal. FiveThirtyEight utiliza la distribución t para generar errores que modelan mejor las desviaciones que vemos en los datos electorales. Por ejemplo, en Wisconsin, el promedio de seis encuestas fue 7% a favor de Clinton con una desviación estándar de 1%, pero Trump ganó por 0.7%. Incluso después de tomar en cuenta el sesgo general, este residuo de 7.7% está más en línea con datos que siguen la distribución t, que con datos que siguen la distribución normal.</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="models.html#cb639-1"></a><span class="kw">data</span>(<span class="st">&quot;polls_us_election_2016&quot;</span>)</span>
<span id="cb639-2"><a href="models.html#cb639-2"></a>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb639-3"><a href="models.html#cb639-3"></a><span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st">&quot;Wisconsin&quot;</span> <span class="op">&amp;</span></span>
<span id="cb639-4"><a href="models.html#cb639-4"></a><span class="st">           </span>enddate <span class="op">&gt;=</span><span class="st">&quot;2016-10-31&quot;</span> <span class="op">&amp;</span></span>
<span id="cb639-5"><a href="models.html#cb639-5"></a><span class="st">           </span>(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span></span>
<span id="cb639-6"><a href="models.html#cb639-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb639-7"><a href="models.html#cb639-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state)) <span class="op">%&gt;%</span></span>
<span id="cb639-8"><a href="models.html#cb639-8"></a><span class="st">  </span><span class="kw">left_join</span>(results_us_election_<span class="dv">2016</span>, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb639-9"><a href="models.html#cb639-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">actual =</span> clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb639-10"><a href="models.html#cb639-10"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">actual =</span> <span class="kw">first</span>(actual), <span class="dt">avg =</span> <span class="kw">mean</span>(spread),</span>
<span id="cb639-11"><a href="models.html#cb639-11"></a>            <span class="dt">sd =</span> <span class="kw">sd</span>(spread), <span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span></span>
<span id="cb639-12"><a href="models.html#cb639-12"></a><span class="st">  </span><span class="kw">select</span>(actual, avg, sd, n)</span>
<span id="cb639-13"><a href="models.html#cb639-13"></a><span class="co">#&gt;   actual    avg     sd n</span></span>
<span id="cb639-14"><a href="models.html#cb639-14"></a><span class="co">#&gt; 1 -0.007 0.0711 0.0104 6</span></span></code></pre></div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="56">
<li id="fn56"><p><a href="https://www.youtube.com/watch?v=TbKkjm-gheY" class="uri">https://www.youtube.com/watch?v=TbKkjm-gheY</a><a href="models.html#fnref56" class="footnote-back">↩︎</a></p></li>
<li id="fn57"><p><a href="https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html" class="uri">https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html</a><a href="models.html#fnref57" class="footnote-back">↩︎</a></p></li>
<li id="fn58"><p><a href="https://fivethirtyeight.com/features/trump-is-just-a-normal-polling-error-behind-" class="uri">https://fivethirtyeight.com/features/trump-is-just-a-normal-polling-error-behind-</a> Clinton/<a href="models.html#fnref58" class="footnote-back">↩︎</a></p></li>
<li id="fn59"><p><a href="https://projects.fivethirtyeight.com/2016-election-forecast/" class="uri">https://projects.fivethirtyeight.com/2016-election-forecast/</a><a href="models.html#fnref59" class="footnote-back">↩︎</a></p></li>
<li id="fn60"><p><a href="https://en.wikipedia.org/wiki/Sally_Clark" class="uri">https://en.wikipedia.org/wiki/Sally_Clark</a><a href="models.html#fnref60" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rafalab/dslibro/edit/master/inference/models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
